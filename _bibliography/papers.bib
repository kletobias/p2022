<<<<<<< HEAD
@misc{9783319514697GoogleDrive,
  title = {978-3-319-51469-7 - {{Google Drive}}},
  howpublished = {https://drive.google.com/drive/folders/1Zv4SU5XUVW3i3y\_-8w22woErhMKLwZXJ},
  file = {/Users/tobias/Zotero/storage/5P2YR27W/1Zv4SU5XUVW3i3y_-8w22woErhMKLwZXJ.html}
}

@misc{adamAnswerHowWould2011,
  title = {Answer to "{{How}} Would You Explain Covariance to Someone Who Understands Only the Mean?"},
  shorttitle = {Answer to "{{How}} Would You Explain Covariance to Someone Who Understands Only the Mean?},
  author = {Adam},
  year = {2011},
  month = nov,
  journal = {Cross Validated},
  file = {/Users/tobias/Zotero/storage/NZL4CG2D/how-would-you-explain-covariance-to-someone-who-understands-only-the-mean.html}
}

=======
>>>>>>> master
@article{afyouniDeepEwareSpatiotemporalSocial2022,
  title = {Deep-{{Eware}}: Spatio-Temporal Social Event Detection Using a Hybrid Learning Model},
  shorttitle = {Deep-{{Eware}}},
  author = {Afyouni, Imad and Khan, Aamir and Aghbari, Zaher Al},
  year = {2022},
  month = jun,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {86},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00636-w},
  abstract = {Event detection from social media aims at extracting specific or generic unusual happenings, such as, family reunions, earthquakes, and disease outbreaks, among others. This paper introduces a new perspective for the hybrid extraction and clustering of social events from big social data streams. We rely on a hybrid learning model, where supervised deep learning is used for feature extraction and topic classification, whereas unsupervised spatial clustering is employed to determine the event whereabouts. We present `Deep-Eware', a scalable and efficient event-aware big data platform that integrates data stream and geospatial processing tools for the hybrid extraction and dissemination of spatio-temporal events. We introduce a pure incremental approach for event discovery, by developing unsupervised machine learning and NLP algorithms and by computing events' lifetime and spatial spanning. The system integrates a semantic keyword generation tool using KeyBERT for dataset preparation. Event classification is performed using CNN and bidirectional LSTM, while hierarchical density-based spatial clustering was used for location-inference of events. We conduct experiments over Twitter datasets to measure the effectiveness and efficiency of our system. The results demonstrate that this hybrid approach for spatio-temporal event extraction has a major advantage for real-time spatio-temporal event detection and tracking from social media. This leads to the development of unparalleled smart city applications, such as event-enriched trip planning, epidemic disease evolution, and proactive emergency management services.},
  keywords = {Deep Learning,Event Classification,NLP,Social Data Mining,Spatio-Temporal Scope,Stream Data Management},
  file = {/Users/tobias/Zotero/storage/MTSXUMSL/Afyouni et al. - 2022 - Deep-Eware spatio-temporal social event detection.pdf}
<<<<<<< HEAD
}

@article{ahmedRuntimePredictionBig2022,
  title = {Runtime Prediction of Big Data Jobs: Performance Comparison of Machine Learning Algorithms and Analytical Models},
  shorttitle = {Runtime Prediction of Big Data Jobs},
  author = {Ahmed, Nasim and Barczak, Andre L. C. and Rashid, Mohammad A. and Susnjak, Teo},
  year = {2022},
  month = may,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {67},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00623-1},
  abstract = {Due to the rapid growth of available data, various platforms offer parallel infrastructure that efficiently processes big data. One of the critical issues is how to use these platforms to optimise resources, and for this reason, performance prediction has been an important topic in the last few years. There are two main approaches to the problem of predicting performance. One is to fit data into an equation based on a analytical models. The other is to use machine learning (ML) in the form of regression algorithms. In this paper, we have investigated the difference in accuracy for these two approaches. While our experiments used an open-source platform called Apache Spark, the results obtained by this research are applicable to any parallel platform and are not constrained to this technology. We found that gradient boost, an ML regressor, is more accurate than any of the existing analytical models as long as the range of the prediction follows that of the training. We have investigated analytical and ML models based on interpolation and extrapolation methods with k-fold cross-validation techniques. Using the interpolation method, two analytical models, namely 2D-plate and fully-connected models, outperform older analytical models and kernel ridge regression algorithm but not the gradient boost regression algorithm. We found the average accuracy of 2D-plate and fully-connected models using interpolation are 0.962 and 0.961. However, when using the extrapolation method, the analytical models are much more accurate than the ML regressors, particularly two of the most recently proposed models (2D-plate and fully-connected). Both models are based on the communication patterns between the nodes. We found that using extrapolation, kernel ridge, gradient boost and two proposed analytical models average accuracy is 0.466, 0.677, 0.975, and 0.981, respectively. This study shows that practitioners can benefit from analytical models by being able to accurately predict the runtime outside of the range of the training data using only a few experimental operations.},
  keywords = {Apache Spark,Big data,Extrapolation and interpolation,HiBench,Machine learning,Performance prediction,System configuration},
  file = {/Users/tobias/Zotero/storage/8JMNSGYB/Ahmed et al. - 2022 - Runtime prediction of big data jobs performance c.pdf}
}

@misc{AIMLNews,
  title = {{{AI}} + {{ML News}} \textbullet{} {{The Register}}},
  howpublished = {https://www.theregister.com/software/ai\_ml/earlier/2/},
  file = {/Users/tobias/Zotero/storage/YCXHBEFI/2.html}
}

@article{al-dmourRamificationsIncorrectImage2022,
  title = {Ramifications of Incorrect Image Segmentations; Emphasizing on the Potential Effects on Deep Learning Methods Failure},
  author = {{Al-Dmour}, Hayat},
  year = {2022},
  month = may,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {71},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00624-0},
  abstract = {Detecting failure cases is critical to ensure a secure self-driving system. Any flaw in the system directly results in an accident. In genuine class, the model's probability reflects better-reflected model confidence. As a result, the confidence distributions of failed predictions were changed to lower values. In contrast, accurate predictions were remained associated with high values, allowing for considerably more excellent separability between such prediction types. The study investigates the association of ramifications with computational color constancy that can negatively influence CNN's image classification and semantic segmentation.},
  keywords = {Deep learning model,Failure detection,Image classification,Image segmentation,Neural network,Ramifications},
  file = {/Users/tobias/Zotero/storage/QKLY5QNR/Al-Dmour - 2022 - Ramifications of incorrect image segmentations\; em.pdf}
}

@article{al-mallaImageCaptioningModel2022,
  title = {Image Captioning Model Using Attention and Object Features to Mimic Human Image Understanding},
  author = {{Al-Malla}, Muhammad Abdelhadie and Jafar, Assef and Ghneim, Nada},
  year = {2022},
  month = feb,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {20},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00571-w},
  abstract = {Image captioning spans the fields of computer vision and natural language processing. The image captioning task generalizes object detection where the descriptions are a single word. Recently, most research on image captioning has focused on deep learning techniques, especially Encoder-Decoder models with Convolutional Neural Network (CNN) feature extraction. However, few works have tried using object detection features to increase the quality of the generated captions. This paper presents an attention-based, Encoder-Decoder deep architecture that makes use of convolutional features extracted from a CNN model pre-trained on ImageNet (Xception), together with object features extracted from the YOLOv4 model, pre-trained on MS COCO. This paper also introduces a new positional encoding scheme for object features, the ``importance factor''. Our model was tested on the MS COCO and Flickr30k datasets, and the performance is compared to performance in similar works. Our new feature extraction scheme raises the CIDEr score by 15.04\%. The code is available at: https://github.com/abdelhadie-almalla/image\_captioning},
  keywords = {Convolutional neural network,Deep learning,Image captioning,Object features},
  file = {/Users/tobias/Zotero/storage/JLYXIWK5/Al-Malla et al. - 2022 - Image captioning model using attention and object .pdf;/Users/tobias/Zotero/storage/R5NRX9P7/articles.html}
}

@article{alduailejAraXLNetPretrainedLanguage2022,
  title = {{{AraXLNet}}: Pre-Trained Language Model for Sentiment Analysis of {{Arabic}}},
  shorttitle = {{{AraXLNet}}},
  author = {Alduailej, Alhanouf and Alothaim, Abdulrahman},
  year = {2022},
  month = may,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {72},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00625-z},
  abstract = {The Arabic language is a complex language with little resources; therefore, its limitations create a challenge to produce accurate text classification tasks such as sentiment analysis. The main goal of sentiment analysis is to determine the overall orientation of a given text in terms of whether it is positive, negative, or neutral. Recently, language models have shown great results in promoting the accuracy of text classification in English. The models are pre-trained on a large dataset and then fine-tuned on the downstream tasks. Particularly, XLNet has achieved state-of-the-art results for diverse natural language processing (NLP) tasks in English. In this paper, we hypothesize that such parallel success can be achieved in Arabic. The paper aims to support this hypothesis by producing the first XLNet-based language model in Arabic called AraXLNet, demonstrating its use in Arabic sentiment analysis in order to improve the prediction accuracy of such tasks. The results showed that the proposed model, AraXLNet, with Farasa segmenter achieved an accuracy results of 94.78\%, 93.01\%, and 85.77\% in sentiment analysis task for Arabic using multiple benchmark datasets. This result outperformed AraBERT that obtained 84.65\%, 92.13\%, and 85.05\% on the same datasets, respectively. The improved accuracy of the proposed model was evident using multiple benchmark datasets, thus offering promising advancement in the Arabic text classification tasks.},
  keywords = {AraXLNet,Language models,NLP,Sentiment analysis,Text mining,XLNet},
  file = {/Users/tobias/Zotero/storage/H524IJXB/Alduailej and Alothaim - 2022 - AraXLNet pre-trained language model for sentiment.pdf}
}

@inproceedings{algherairyImpactFeatureSelection2022,
  title = {The {{Impact}} of {{Feature Selection}} on {{Different Machine Learning Models}} for {{Breast Cancer Classification}}},
  booktitle = {2022 7th {{International Conference}} on {{Data Science}} and {{Machine Learning Applications}} ({{CDMA}})},
  author = {Algherairy, Atheer and Almattar, Wadha and Bakri, Eman and Albelali, Salma},
  year = {2022},
  month = mar,
  pages = {91--96},
  doi = {10.1109/CDMA54072.2022.00020},
  abstract = {Breast cancer appears to be a common type of cancer suffered by women globally, with considered high death rates. The survival rate of breast cancer patients decreases considerably for patients diagnosed at an advanced stage compared to those diagnosed at an early stage. The objective of this study is to investigate breast cancer classification and diagnosis task using the data from WBCD dataset. In our methodology, first, the breast cancer data was scaled. Then, four features selection methods were used to analyze the features. Pearson's Correlation method, Forward Selection method, Mutual Information and Univariate ROC-AUC were the used feature selectors. Next, different Machine Leaning models were applied including Support Vector Machine, Logistic Regression and XGBoost. Finally, the three models were cross-validated by 5-fold method. The ML models with different classifiers were evaluated based on several performance measures including accuracy, precision, recall, and F1-score. results show that Logistic Regression (LR) model with Forward Selection appeared to be the most successful classifier. The obtained classification accuracy, precision, and F1-score were 0.982, 0.983, 0.986; respectively. However, the highest recall score was 0.992 achieved by SVM model with Correlation feature selection. The developed model could potentially help the medical experts for the early diagnosis of breast cancer to decrease potential risk.},
  keywords = {Breast cancer,Breast Cancer,Correlation,Feature extraction,Feature Selection,Machine learning,Machine Learning,Multiaccess communication,Support vector machines,Task analysis},
  file = {/Users/tobias/Zotero/storage/5YQHHSVF/Algherairy et al. - 2022 - The Impact of Feature Selection on Different Machi.pdf;/Users/tobias/Zotero/storage/NQVD7536/9736358.html}
}

@article{alibasicEvaluationTrendsJobs2022,
  title = {Evaluation of the Trends in Jobs and Skill-Sets Using Data Analytics: A Case Study},
  shorttitle = {Evaluation of the Trends in Jobs and Skill-Sets Using Data Analytics},
  author = {Alibasic, Armin and Upadhyay, Himanshu and Simsekler, Mecit Can Emre and Kurfess, Thomas and Woon, Wei Lee and Omar, Mohammed Atif},
  year = {2022},
  month = mar,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {32},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00576-5},
  abstract = {Fast-emerging technologies are making the job market dynamic, causing desirable skills to evolve continuously. It is therefore important to understand the transitions in the job market to proactively identify skill sets required.},
  keywords = {Data analytics,Data mining,Future of work,Jobs and skills analysis,Natural language processing},
  file = {/Users/tobias/Zotero/storage/CPEXLUCT/Alibasic et al. - 2022 - Evaluation of the trends in jobs and skill-sets us.pdf;/Users/tobias/Zotero/storage/ARCWEKYB/articles.html}
}

@article{aliBigSocialData2022,
  title = {Big Social Data as a Service ({{BSDaaS}}): A Service Composition Framework for Social Media Analysis},
  shorttitle = {Big Social Data as a Service ({{BSDaaS}})},
  author = {Ali, Kashif and Hamilton, Margaret and Thevathayan, Charles and Zhang, Xiuzhen},
  year = {2022},
  month = may,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {64},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00620-4},
  abstract = {Social media provides an infrastructure where users can share their data at an unprecedented speed without worrying about storage and processing. Social media data has grown exponentially and now there is major interest in extracting any useful information from the social media data to apply in various domains. Currently, there are various tools available to analyze the large amounts of social media data. However, these tools do not consider the diversity of the social media data, and treat social media as a uniform data source with similar features. Thus, these tools lack the flexibility to dynamically process and analyze the social media data according to its diverse features. In this paper, we develop a `Big Social Data as a Service' (BSDaaS) composition framework that extracts the data from various social media platforms, and transforms it into useful information. The framework provides a quality model to capture the dynamic features of social media data. In addition, our framework dynamically assesses the quality features of the social media data and composes appropriate services required for various information analyses. We present a social media based sentiment analysis system as a motivating scenario and conduct experiments using real-world datasets to show the efficiency of our approach.},
  keywords = {Big data analysis,Sentiment analysis,Service composition,Service orientation,Service quality,Social information services},
  file = {/Users/tobias/Zotero/storage/9ZNDR9HJ/Ali et al. - 2022 - Big social data as a service (BSDaaS) a service c.pdf}
}

@article{aliLargescaleSentimentAnalysis2022,
  title = {A Large-Scale Sentiment Analysis of Tweets Pertaining to the 2020 {{US}} Presidential Election},
  author = {Ali, Rao Hamza and Pinto, Gabriela and Lawrie, Evelyn and Linstead, Erik J.},
  year = {2022},
  month = jun,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {79},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00633-z},
  abstract = {We capture the public sentiment towards candidates in the 2020 US Presidential Elections, by analyzing 7.6 million tweets sent out between October 31st and November 9th, 2020. We apply a novel approach to first identify tweets and user accounts in our database that were later deleted or suspended from Twitter. This approach allows us to observe the sentiment held for each presidential candidate across various groups of users and tweets: accessible tweets and accounts, deleted tweets and accounts, and suspended or inaccessible tweets and accounts. We compare the sentiment scores calculated for these groups and provide key insights into the differences. Most notably, we show that deleted tweets, posted after the Election Day, were more favorable to Joe Biden, and the ones posted leading to the Election Day, were more positive about Donald Trump. Also, the older a Twitter account was, the more positive tweets it would post about Joe Biden. The aim of this study is to highlight the importance of conducting sentiment analysis on all posts captured in real time, including those that are now inaccessible, in determining the true sentiments of the opinions around the time of an event.},
  keywords = {Natural Language Processing,Sentiment analysis,Twitter analysis,US Elections 2020},
  file = {/Users/tobias/Zotero/storage/LCTA3GCG/Ali et al. - 2022 - A large-scale sentiment analysis of tweets pertain.pdf}
}

@article{alnaimyExpandedGraphEmbedding2022,
  title = {Expanded Graph Embedding for Joint Network Alignment and Link Prediction},
  author = {Alnaimy, MHD Samy and Desouki, Mohammad Said},
  year = {2022},
  month = apr,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {41},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00595-2},
  abstract = {Link prediction in social networks has been an active field of study in recent years fueled by the rapid growth of many social networks. Many link prediction methods are harmed by users' intention of avoiding being traced across networks. They may provide inaccurate information or overlook a great deal of information in multiple networks. This problem was overcome by developing methods for predicting links in a network based on known links in another network. Node alignment between the two networks significantly improves the efficiency of those methods. This research proposes a new embedding method to improve link prediction and node alignment results. The proposed embedding method is based on the Expanded Graph, which is our new novel network that has edges from both networks in addition to edges across the networks. Matrix factorization on the Finite Step Transition and Laplacian similarity matrices of the Expanded Graph has been used to obtain the embeddings for the nodes. Using the proposed embedding techniques, we jointly run network alignment and link prediction tasks iteratively to let them optimize each other's results. We performed extensive experiments on many datasets to examine the proposed method. We achieved significant improvements in link prediction precision, which was 50\% better than the peer's method, and in recall, which was 500\% better in some datasets. We also scale down the processing time of the solution to be more applicable to big social networks. We conclude that computed embedding in this type of problem is more suitable than learning the embedding since it shortens the processing time and gives better results.},
  keywords = {Cross-graph embedding,Expanded graph,Finite step transition,Laplacian,Link prediction,Network alignment,Singular value decomposition,Social network analysis},
  file = {/Users/tobias/Zotero/storage/CMLQVHF6/Alnaimy and Desouki - 2022 - Expanded graph embedding for joint network alignme.pdf;/Users/tobias/Zotero/storage/74CLZ4MB/articles.html}
}

@article{alsariSentimentAnalysisCruises2022,
  title = {Sentiment Analysis for Cruises in {{Saudi Arabia}} on Social Media Platforms Using Machine Learning Algorithms},
  author = {{Al sari}, Bador and Alkhaldi, Rawan and Alsaffar, Dalia and Alkhaldi, Tahani and Almaymuni, Hanan and Alnaim, Norah and Alghamdi, Najwa and Olatunji, Sunday O.},
  year = {2022},
  month = feb,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {21},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00568-5},
  abstract = {Social media has great importance in the community for discussing many events and sharing them with others. The primary goal of this research is to study the quality of the sentiment analysis (SA) of impressions about Saudi cruises, as a first event, by creating datasets from three selected social media platforms (Instagram, Snapchat, and Twitter). The outcome of this study will help in understanding opinions of passengers and viewers about their first Saudi cruise experiences by analyzing their feelings from social media posts. After cleaning, this experiment contains 1200 samples. The data was classified into positive or negative classes using the choice of machine learning algorithms, such as multilayer perceptron (MLP), na\i ve bayes (NB), random forest (RF), support vector machine (SVM), and voting. The results show the highest classification accuracy for the RF algorithm, as it achieved 100\% accuracy with over-sampled data from Snapchat using both test options. The algorithms were compared among the three different datasets. All algorithms achieved a high level of accuracy. Hence, the results show that 80\% of the sentiments were positive while 20\% were negative.},
  keywords = {Artificial intelligence,Cruise,Machine learning,Sentiment analysis,Social media,Tourism},
  file = {/Users/tobias/Zotero/storage/7WQH9WV4/Al sari et al. - 2022 - Sentiment analysis for cruises in Saudi Arabia on .pdf;/Users/tobias/Zotero/storage/9NW7QMFR/articles.html}
}

@article{alweshahVehicleRoutingProblems2022,
  title = {Vehicle Routing Problems Based on {{Harris Hawks}} Optimization},
  author = {Alweshah, Mohammed and Almiani, Muder and Almansour, Nedaa and Al Khalaileh, Saleh and Aldabbas, Hamza and Alomoush, Waleed and Alshareef, Almahdi},
  year = {2022},
  month = apr,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {42},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00593-4},
  abstract = {The vehicle routing problem (VRP) is one of the challenging problems in optimization and can be described as combinatorial optimization and NP-hard problem. Researchers have used many artificial intelligence techniques in order to try to solve this problem. Among these techniques, metaheuristic algorithms that can perform random search are the most promising because they can be used to find the right solution in the shortest possible time. Therefore, in this paper, the Harris hawks optimization (HHO) algorithm was used to attempt to solve the VRP. The algorithm was applied to 10 scenarios and the experimental results revealed that the HHO had a strong ability to check for and find the best route as compared to other metaheuristic algorithms, namely, simulated annealing and artificial bee colony optimization. The comparison was based on three criteria: minimum objective function obtained, minimum number of iterations required and satisfaction of capacity constraints. In all scenarios, the HHO showed clear superiority over the other methods.},
  keywords = {Harris Hawks Optimization,Metaheuristic,Optimization,Vehicle routing problem},
  file = {/Users/tobias/Zotero/storage/C8INEFCR/Alweshah et al. - 2022 - Vehicle routing problems based on Harris Hawks opt.pdf;/Users/tobias/Zotero/storage/J5A2RUVK/articles.html}
}

@misc{andrejCombinationsElementsTwo2015,
  type = {Forum Post},
  title = {Combinations between Elements in Two Tuples in {{Python}}},
  author = {Andrej},
  year = {2015},
  month = jun,
  journal = {Stack Overflow},
  keywords = {combinations,combinatorics,itertools,itertools.product},
  file = {/Users/tobias/Zotero/storage/FPZ75EC3/combinations-between-elements-in-two-tuples-in-python.html}
}

@article{angskunBigDataAnalytics2022,
  title = {Big Data Analytics on Social Networks for Real-Time Depression Detection},
  author = {Angskun, Jitimon and Tipprasert, Suda and Angskun, Thara},
  year = {2022},
  month = may,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {69},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00622-2},
  abstract = {During the coronavirus pandemic, the number of depression cases has dramatically increased. Several depression sufferers disclose their actual feeling via social media. Thus, big data analytics on social networks for real-time depression detection is proposed. This research work detected the depression by analyzing both demographic characteristics and opinions of Twitter users during a two-month period after having answered the Patient Health Questionnaire-9 used as an outcome measure. Machine learning techniques were applied as the detection model construction. There are five machine learning techniques explored in this research which are Support Vector Machine, Decision Tree, Na\"ive Bayes, Random Forest, and Deep Learning. The experimental results revealed that the Random Forest technique achieved higher accuracy than other techniques to detect the depression. This research contributes to the literature by introducing a novel model based on analyzing demographic characteristics and text sentiment of Twitter users. The model can capture depressive moods of depression sufferers. Thus, this work is a step towards reducing depression-induced suicide rates.},
  keywords = {Big data analytics,Depression detection,Social networks},
  file = {/Users/tobias/Zotero/storage/4N84KFFE/Angskun et al. - 2022 - Big data analytics on social networks for real-tim.pdf}
}

@article{aragawPoissonLogitHurdle2022,
  title = {Poisson Logit Hurdle Model with Associated Factors of Perinatal Mortality in {{Ethiopia}}},
  author = {Aragaw, Abiba Mihret and Azene, Abebaw Gedef and Workie, Mekuanint Simeneh},
  year = {2022},
  month = feb,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {16},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00567-6},
  abstract = {Perinatal mortality is the total number of fetal death and early neonatal death. Perinatal mortality is a major public health problem, particularly in developing countries, and is used as an implication of the economic, social, and health status of the country. The analysis of count data with hurdle and zero-inflated count models are the most applicable methods to accommodate with excessive zero counts. Therefore, this study aimed to apply the Poisson logit hurdle model to identify the associated factors of perinatal mortality in Ethiopia. A cross-sectional study design was conducted in Ethiopia using EDHS 2016. The sample was multistage stratified and units selected in a two-stage cluster sampling design. The association between the outcome and the independent variables was determined using the Poisson logit hurdle model. A total of 7230 mothers were obtained from EDHS 2016 survey. Of these mothers, 95.27\% of them never, 4.47\% of them once, 0.26\% twice, and 0.04\% three times experienced perinatal mortality preceding 5~years of the survey. The main protective associated factors were 40\textendash 49~years age of mother, having long preceding birth interval, and secondary\,+\,husband education. Parity is greater than four, rural residence, Caesarean section delivery, multiple pregnancies, institutional delivery, having a history of abortion were increased perinatal mortality per mother. This study implies that intervention is needed on family planning and mode of delivery to minimize perinatal mortality in the country.},
  keywords = {Associated factors,Ethiopia,Perinatal mortality,Poisson logistics hurdle model},
  file = {/Users/tobias/Zotero/storage/BLTTAUES/Aragaw et al. - 2022 - Poisson logit hurdle model with associated factors.pdf;/Users/tobias/Zotero/storage/IY9R4WRG/articles.html}
}

@article{arhabSocialMediaAnalysis2022,
  title = {Social Media Analysis of Car Parking Behavior Using Similarity Based Clustering},
  author = {Arhab, Nabil and Oussalah, Mourad and Jahan, Md Saroar},
  year = {2022},
  month = may,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {74},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00627-x},
  abstract = {This paper investigates car parking users' behaviors from social media perspective using social network based analysis of online communities revealed by mining the associated hashtags in Twitter. We propose a new interpretable community detection approach for mapping user's car parking behavior by combining Clique, K-core and Girvan\textendash Newman community detection algorithms together with a content-based analysis that exploits polarity, relative frequency and dominant topics. Twitter API was used to collect relevant data by tracking popular car-parking hashtags. A social network graph is constructed using a similarity-based analysis. Finally, interpretable communities are inferred by monitoring the outcomes of clique, K-core and Girvan\textendash Newman community detection algorithms. This interpretability is linked to the aggregation of keywords, hashtags and/or location attributes of the tweet messages as well as a visualization module that enables interaction with users. In parallel, a global trend analysis investigates parking types and Twitter influence with respect to both sentiment polarity and dominant trends (extracted using KeyBERT based approach) is performed. The implementation of this social media analytics has uncovered several aspects associated to car-parking behaviors. A comparison with some state-of-the-art community detection methods has also been carried out and revealed some similarities with our developed approach.},
  keywords = {Natural language processing (NLP),Parking,Social media,Social networks,Twitter},
  file = {/Users/tobias/Zotero/storage/T3R5D2VI/Arhab et al. - 2022 - Social media analysis of car parking behavior usin.pdf}
}

@article{arnoldDeepLearningCIVICA,
  title = {Deep {{Learning}}\textemdash{{CIVICA Workshop}}},
  author = {Arnold, Dr Christian},
  pages = {2},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/FBWL89YQ/Arnold - Deep Learning—CIVICA Workshop.pdf}
}

@misc{arthur.00AnswerHowWould2014,
  title = {Answer to "{{How}} Would You Explain Covariance to Someone Who Understands Only the Mean?"},
  shorttitle = {Answer to "{{How}} Would You Explain Covariance to Someone Who Understands Only the Mean?},
  author = {{arthur.00}},
  year = {2014},
  month = aug,
  journal = {Cross Validated},
  file = {/Users/tobias/Zotero/storage/HBFA7RMK/how-would-you-explain-covariance-to-someone-who-understands-only-the-mean.html}
}

@article{asemiIntegratedModelEvaluation2022,
  title = {An Integrated Model for Evaluation of Big Data Challenges and Analytical Methods in Recommender Systems},
  author = {Asemi, Adeleh and Asemi, Asefeh and Ko, Andrea and Alibeigi, Ali},
  year = {2022},
  month = jan,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {13},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00560-z},
  abstract = {The study aimed to present an integrated model for evaluation of big data (BD) challenges and analytical methods in recommender systems (RSs). The proposed model used fuzzy multi-criteria decision making (MCDM) which is a human judgment-based method for weighting of RSs' properties. Human judgment is associated with uncertainty and gray information. We used fuzzy techniques to integrate, summarize, and calculate quality value judgment distances. Then, two fuzzy inference systems (FIS) are implemented for scoring BD challenges and data analytical methods in different RSs. In experimental testing of the proposed model, A correlation coefficient (CC) analysis is conducted to test the relationship between a BD challenge evaluation for a collaborative filtering-based RS and the results of fuzzy inference systems. The result shows the ability of the proposed model to evaluate the BD properties in RSs. Future studies may improve FIS by providing rules for evaluating BD tools.},
  keywords = {Analytical methods,Big Data properties,Dig Data challenges,Fuzzy AHP,Fuzzy inference system,Fuzzy multi-criteria decision making,Privacy,Recommender system properties},
  file = {/Users/tobias/Zotero/storage/4DJGZC5J/Asemi et al. - 2022 - An integrated model for evaluation of big data cha.pdf;/Users/tobias/Zotero/storage/5I8ZWUR9/articles.html}
}

@article{asilerHyGraphSubgraphIsomorphism2022,
  title = {{{HyGraph}}: A Subgraph Isomorphism Algorithm for Efficiently Querying Big Graph Databases},
  shorttitle = {{{HyGraph}}},
  author = {Asiler, Merve and Yaz{\i}c{\i}, Adnan and George, Roy},
  year = {2022},
  month = apr,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {40},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00589-0},
  abstract = {The big graph database provides strong modeling capabilities and efficient querying for complex applications. Subgraph isomorphism which finds exact matches of a query graph in the database efficiently, is a challenging problem. Current subgraph isomorphism approaches mostly are based on the pruning strategy proposed by Ullmann. These techniques have two significant drawbacks- first, they are unable to efficiently handle complex queries, and second, their implementations need the large indexes that require large memory resources. In this paper, we describe a new subgraph isomorphism approach, the HyGraph algorithm, that is efficient both in querying and with memory requirements for index creation. We compare the HyGraph algorithm with two popular existing approaches, GraphQL and Cypher using complexity measures and experimentally using three big graph data sets\textemdash (1) a country-level population database, (2) a simulated bank database, and (3) a publicly available World Cup big graph database. It is shown that the HyGraph solution performs significantly better (or equally) than competing algorithms for the query operations on these big databases, making it an excellent candidate for subgraph isomorphism queries in real scenarios.},
  keywords = {Exact matching algorithm,Graph database,Neo4j databases,Query graph search,Subgraph isomorphism problem},
  file = {/Users/tobias/Zotero/storage/IYUEBXCU/Asiler et al. - 2022 - HyGraph a subgraph isomorphism algorithm for effi.pdf;/Users/tobias/Zotero/storage/ZS24USXJ/articles.html}
}

@misc{AuthorTomDrabas,
  title = {Author: {{Tom Drabas}}},
  shorttitle = {Author},
  journal = {NVIDIA Technical Blog},
  abstract = {Tom is a data science geek and nerd: when he is not building new machine learning models, he helps to improve the experience of Blazing Notebooks or researches new technologies. He is obsessed with\ldots},
  howpublished = {https://developer.nvidia.com/blog/author/tomd/},
  langid = {american},
  file = {/Users/tobias/Zotero/storage/6MDXK3X2/tomd.html}
}

@article{azbegDiabetesEmergencyCases2022,
  title = {Diabetes Emergency Cases Identification Based on a Statistical Predictive Model},
  author = {Azbeg, Kebira and Boudhane, Mohcine and Ouchetto, Ouail and Jai Andaloussi, Said},
  year = {2022},
  month = mar,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {31},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00582-7},
  abstract = {Diabetes is a chronic metabolic disease which is characterized by a permanently high blood sugar level. A distinction is made between two forms: Type 1 diabetes and Type 2 diabetes. It is believed that there are around 415 million people between the ages of 20 and 79 worldwide who have some form of diabetes illness today. In Europe, over 60 million people are diabetic, a diabetes incidence of 10.3\% of men and 9.6\% of women is estimated. The prevalence of diabetes is increasing among all ages in the European Region, mainly due to increases in overweight and obesity, unhealthy diet, and physical inactivity. A huge people in this population have type 2 diabetes, and the numbers will continue to rise over the next few years. So one can speak of a real widespread disease. The problem is not only the increased blood sugar, but also complications and accompanying diseases such as heart attack, stroke, or diabetic foot. However, as a type 2 diabetic, we can significantly influence the course of the disease and the success of therapy. To do this, it is important that we early detect the person that have (or likely have) a serious problem or an emergent case, and know about it as fast as possible. Early detection and treatment of this disease are very important to help diabetics live a healthy and near normal life. It can also help to avoid several serious complications. In addition, the evolution of wearable and Internet of Things medical devices can help to collect various health data for diagnosis using machine learning algorithms. In this paper, we present an IoT-based system architecture which ensures the collection of patient data in order to predict serious cases of diabetes. To secure data, Blockchain and IPFS are used, and to analyze data, we propose a statistical-based method for predictions. The process is as follows. First, data were collected from IoT devices, and a dataset was constructed and stored using IPFS. Then, the data will be scaled and filtered using noise-invariant data expansion. Next, an adaptive random forest algorithm is made in order to train data on the training dataset, and people with diabetes were classified using the proposed model. Three datasets were used, namely, the Pima Indian diabetes dataset, the Frankfurt Hospital diabetes dataset, and the last is the fusion of these two datasets. Finally, the performance of the method was evaluated and compared with other recent prediction methods. Based on the experiment result, an accuracy of 85.9\%, 99.5\%, and 99.8\% has been achieved based on the three datasets, respectively. Thus, the model can be used to predict and alert physicians or hospitals serious cases that need urgent reactions.},
  keywords = {Artificial intelligence,Diabetes disease,Internet of things (IoT),Machine learning,Medical treatment},
  file = {/Users/tobias/Zotero/storage/DI3LY995/Azbeg et al. - 2022 - Diabetes emergency cases identification based on a.pdf;/Users/tobias/Zotero/storage/QYH4RK5J/articles.html}
}

@incollection{bartoAdaptiveRealTimeDynamic2017,
  title = {Adaptive {{Real-Time Dynamic Programming}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Barto, Andrew G.},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {20--23},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_10},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@misc{bartonAnswerCmmCall2014,
  title = {Answer to "Cmm Call Format for Foreign Primop (Integer-Gmp Example)"},
  author = {Barton, Reid},
  year = {2014},
  month = sep,
  journal = {Stack Overflow},
  keywords = {16-bit,32-bit,advantages of FP16 over FP32,binary representation,deep learning,drawbacks of FP16 compared to FP32,floating point numbers,fp16,fp32,half precision,memory allocated,mixed precision,single precision,theory,training a model faster},
  file = {/Users/tobias/Zotero/storage/MMIZ645G/cmm-call-format-for-foreign-primop-integer-gmp-example.html}
}

@article{besharatiDDKARBDatadrivenCompliance2022,
  title = {{{DD-KARB}}: Data-Driven Compliance to Quality by Rule Based Benchmarking},
  shorttitle = {{{DD-KARB}}},
  author = {Besharati, Mohammad Reza and Izadi, Mohammad},
  year = {2022},
  month = nov,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {103},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00654-8},
  abstract = {The problem of compliance checking and assessment is to ensure that the design or implementation of a system meets some desired properties and complies with some rules or regularities. This problem is a key issue in several human and engineering application domains such as organizational management and e-governance, software and IT industries, and software and systems quality engineering. To deal with this problem, some different approaches and methods have been proposed. In addition to the approaches such as formal methods, mathematical proofs, and logical evaluations, benchmarking can be used for compliance assessment. Naturally, a set of benchmarks can shape an applied solution to compliance assessment. In this paper we propose KARB solution system, i.e. keeping away compliance Anomalies through Rule-based Benchmarking. In fact, in our proposed method the rule-based benchmarking means evaluating the conformity of an under-compliance system to a set of rules. In this solution approach, the under-compliance system is specified symbolically (using formal and logical descriptions). Also, the desired rules are specified formally as the semantic logic in the evaluation process. After reviewing the proposed method, a case study was conducted to demonstrate and analyze the KARB solution. The IR-QUMA study (Iranian Survey on Quality in Messenger Apps) was then conducted to evaluate the quality of some messenger applications. According to the evaluation results, the hybrid DD-KARB method (with a combination of semantics-awareness and data-drivenness) is more effective than solo methods and can compute a good estimation for the messenger application user quality scores. Therefore, DD-KARB can be considered as a method for quality benchmarking in this technical context.},
  keywords = {Benchmarking,Big data,Compliance checking of systems,Messenger applications,Semantic logic,Software quality},
  file = {/Users/tobias/Zotero/storage/4XXYCZD8/Besharati and Izadi - 2022 - DD-KARB data-driven compliance to quality by rule.pdf}
}

@misc{BetterDeepLearning,
  title = {Better\_deep\_learning.Pdf},
  file = {/Users/tobias/Zotero/storage/67F5VIFI/better_deep_learning.pdf}
}

@article{Bfloat16FloatingpointFormat2021,
  title = {Bfloat16 Floating-Point Format},
  year = {2021},
  month = aug,
  journal = {Wikipedia},
  abstract = {The bfloat16 (Brain Floating Point) floating-point format is a computer number format occupying 16 bits in computer memory; it represents a wide dynamic range of numeric values by using a floating radix point. This format is a truncated (16-bit) version of the 32-bit IEEE 754 single-precision floating-point format (binary32) with the intent of accelerating machine learning and near-sensor computing. It preserves the approximate dynamic range of 32-bit floating-point numbers by retaining 8 exponent bits, but supports only an 8-bit precision rather than the 24-bit significand of the binary32 format. More so than single-precision 32-bit floating-point numbers, bfloat16 numbers are unsuitable for integer calculations, but this is not their intended use. Bfloat16 is used to reduce the storage requirements and increase the calculation speed of machine learning algorithms.The bfloat16 format was developed by Google Brain, an artificial intelligence research group at Google.   The bfloat16 format is utilized in Intel AI processors, such as Nervana NNP-L1000, Xeon processors (AVX-512 BF16 extensions), and Intel FPGAs, Google Cloud TPUs, and TensorFlow. ARMv8.6-A, AMD ROCm, and CUDA also support the bfloat16 format. On these platforms, bfloat16 may also be used in mixed-precision arithmetic, where bfloat16 numbers may be operated on and expanded to wider data types.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  keywords = {bfp16,binary,float,fp16,fp32,half precision,machine readable floating point number,single precision},
  annotation = {Page Version ID: 1041556217},
  file = {/Users/tobias/Zotero/storage/5H99BGS7/Bfloat16_floating-point_format.html}
}

@book{bishopPatternRecognitionMachine2006,
  title = {Pattern Recognition and Machine Learning},
  author = {Bishop, Christopher M.},
  year = {2006},
  series = {Information Science and Statistics},
  publisher = {{Springer}},
  address = {{New York}},
  isbn = {978-0-387-31073-2},
  langid = {english},
  lccn = {Q327 .B52 2006},
  keywords = {Machine learning,Pattern perception},
  file = {/Users/tobias/Zotero/storage/Q537F8Q8/Bishop - 2006 - Pattern recognition and machine learning.pdf}
}

@incollection{blockeelBiasSpecificationLanguage2017,
  title = {Bias {{Specification Language}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Blockeel, Hendrik},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {125--128},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_73},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@article{bonifaziDefiningUserSpectra2022,
  title = {Defining User Spectra to Classify {{Ethereum}} Users Based on Their Behavior},
  author = {Bonifazi, Gianluca and Corradini, Enrico and Ursino, Domenico and Virgili, Luca},
  year = {2022},
  month = apr,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {37},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00586-3},
  abstract = {In this paper, we define the concept of user spectrum and adopt it to classify Ethereum users based on their behavior.},
  keywords = {Blockchain,Classification algorithm,Eros distance,Ethereum,Etherscan,Extended Frobenius Norm,Multivariate Time Series,User spectrum},
  file = {/Users/tobias/Zotero/storage/KPSBUUMB/Bonifazi et al. - 2022 - Defining user spectra to classify Ethereum users b.pdf;/Users/tobias/Zotero/storage/T6VCVX48/articles.html}
}

@misc{bosko500BestCompanies2022,
  title = {500 {{Best Companies}} to {{Work For}}},
  author = {Bosko, Katerina},
  year = {2022},
  month = aug,
  abstract = {An exploratory data analysis project that showcases the differences and similarities in attributes regarding the top 500 companies to work for according to Forbes.com},
  keywords = {best_companies_to_work_for,github,python-project,repository,webscrapping}
}

@misc{boskoPortfolio2022,
  title = {Portfolio},
  author = {Bosko, Katerina},
  year = {2022},
  month = feb,
  journal = {Cross-Validated},
  abstract = {Blogging about my transition into Data Engineering + HOWTOs on Minimal Mistakes Jekyll personal website},
  howpublished = {https://www.cross-validated.com/portfolio/},
  langid = {english},
  keywords = {500,best_employer,data_science_portfolio,example,inspiration,website},
  file = {/Users/tobias/Zotero/storage/DLHL49EQ/portfolio.html}
}

@incollection{brankeArtificialSocieties2017,
  title = {Artificial {{Societies}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Branke, J{\"u}rgen},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {66--70},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_922},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@article{brownleeBasicsLinearAlgebra,
  title = {Basics of {{Linear Algebra}} for {{Machine Learning}}},
  author = {Brownlee, Jason},
  pages = {264},
  langid = {english},
  keywords = {⛔ No DOI found},
  file = {/Users/tobias/Zotero/storage/KLYUGQYC/Brownlee - Basics of Linear Algebra for Machine Learning.pdf}
}

@article{brownleeOptimizationMachineLearning,
  title = {Optimization for {{Machine Learning}}},
  author = {Brownlee, Jason},
  pages = {402},
  langid = {english},
  keywords = {⛔ No DOI found},
  file = {/Users/tobias/Zotero/storage/X6VYKF8Z/Brownlee - Optimization for Machine Learning.pdf}
}

@article{brownleeProbabilityMachineLearning,
  title = {Probability for {{Machine Learning}}},
  author = {Brownlee, Jason},
  pages = {319},
  langid = {english},
  keywords = {⛔ No DOI found},
  file = {/Users/tobias/Zotero/storage/PLMQ8AUD/Brownlee - Probability for Machine Learning.pdf}
}

@article{budumaFundamentalsDeepLearning,
  title = {Fundamentals of {{Deep Learning}}},
  author = {Buduma, Nikhil},
  pages = {288},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/HE9BRPTV/Buduma - Fundamentals of Deep Learning.pdf}
}

@incollection{buntineBayesianMethods2017,
  title = {Bayesian {{Methods}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Buntine, Wray L.},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {100--106},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_63},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@misc{capohugoAnswerHowWould2019,
  title = {Answer to "{{How}} Would You Explain Covariance to Someone Who Understands Only the Mean?"},
  shorttitle = {Answer to "{{How}} Would You Explain Covariance to Someone Who Understands Only the Mean?},
  author = {{capohugo}},
  year = {2019},
  month = jan,
  journal = {Cross Validated},
  file = {/Users/tobias/Zotero/storage/VS8U4PCS/how-would-you-explain-covariance-to-someone-who-understands-only-the-mean.html}
}

@article{carakaAlbatrossAnalyticsHandson2022,
  title = {Albatross Analytics a Hands-on into Practice: Statistical and Data Science Application},
  shorttitle = {Albatross Analytics a Hands-on into Practice},
  author = {Caraka, Rezzy Eko and Lee, Youngjo and Han, Jeongseop and Lee, Hangbin and Noh, Maengseok and Do Ha, Il and Gio, Prana Ugiana and Pardamean, Bens},
  year = {2022},
  month = may,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {70},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00626-y},
  abstract = {Albatross Analytics is a statistical and data science data processing platform that researchers can use in disciplines of various fields. Albatross Analytics makes it easy to implement fundamental analysis for various regressions with random model effects, including Hierarchical Generalized Linear Models (HGLMs), Double Hierarchical Generalized Linear Models (DHGLMs), Multivariate Double Hierarchical Generalized Linear Models (MDHGLMs), Survival Analysis, Frailty Models, Support Vector Machines (SVMs), and Hierarchical Likelihood Structural Equation Models (HSEMs). We provide 94 types of dataset examples.},
  keywords = {Albatross analytics,Application,Data science,R shiny,Statistics},
  file = {/Users/tobias/Zotero/storage/9T7V24J3/Caraka et al. - 2022 - Albatross analytics a hands-on into practice stat.pdf}
}

@incollection{carpenterAdaptiveResonanceTheory2017,
  title = {Adaptive {{Resonance Theory}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Carpenter, Gail A. and Grossberg, Stephen},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {24--40},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_6},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@article{cerrutoSocialNetworkData2022,
  title = {Social Network Data Analysis to Highlight Privacy Threats in Sharing Data},
  author = {Cerruto, Francesca and Cirillo, Stefano and Desiato, Domenico and Gambardella, Simone Michele and Polese, Giuseppe},
  year = {2022},
  month = feb,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {19},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00566-7},
  abstract = {Social networks are a vast source of information, and they have been increasing impact on people's daily lives. They permit us to share emotions, passions, and interactions with other people around the world. While enabling people to exhibit their lives, social networks guarantee their privacy. The definitions of privacy requirements and default policies for safeguarding people's data are the most difficult challenges that social networks have to deal with. In this work, we have collected data concerning people who have different social network profiles, aiming to analyse privacy requirements offered by social networks. In particular, we have built a tool exploiting image-recognition techniques to recognise a user from his/her picture, aiming to collect his/her personal data accessible through social networks where s/he has a profile. We have composed a dataset of 5000 users by combining data available from several social networks; we compared social network data mandatory in the registration phases, publicly accessible and those retrieved by our analysis. We aim to analyse the amount of extrapolated data for evaluating privacy threats when users share information on different social networks to help them be aware of these aspects. This work shows how users data on social networks can be retrieved easily by representing a clear privacy violation. Our research aims to improve the user's awareness concerning the spreading and managing of social networks data. To this end, we highlighted all the statistical evaluations made over the gathered data for putting in evidence the privacy issues.},
  keywords = {Data analysis,Privacy,Social networks},
  file = {/Users/tobias/Zotero/storage/Z5T6W6MC/Cerruto et al. - 2022 - Social network data analysis to highlight privacy .pdf;/Users/tobias/Zotero/storage/R4G5F4B3/articles.html}
}

@article{ceteraPotentialUseLarge2022,
  title = {Potential for the Use of Large Unstructured Data Resources by Public Innovation Support Institutions},
  author = {Cetera, Wies{\l}aw and Gogo{\l}ek, W{\l}odzimierz and {\.Z}o{\l}nierski, Aleksander and Jaruga, Dariusz},
  year = {2022},
  month = apr,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {46},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00610-6},
  abstract = {Effective programming of research and development (R\&D) support, adjusted to the actual potential of beneficiaries, requires the use of modern analytical tools. An efficient R\&D support system requires up-to-date data on technological trends, ongoing (and planning) research, market needs and developing innovation. The most popular programming methods were based on the analysis of data with a 4 to 5-year time delay until recently. Having described the method of refining information from unstructured data, we explore how to make it possible not only to solve the issue of up-to-date data but to identify of the latest trends in R\&D activities.},
  keywords = {Big Data,Business statistics,C810,Data management,H110,Information refining,Information technologies management,Innovation,O320,Research and development management,Research and development support programming},
  file = {/Users/tobias/Zotero/storage/4WLHRZVG/Cetera et al. - 2022 - Potential for the use of large unstructured data r.pdf;/Users/tobias/Zotero/storage/GRXUDIB2/articles.html}
}

@incollection{chandolaActiveLearning2017,
  title = {Active {{Learning}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Chandola, Varun and Banerjee, Arindam and Kumar, Vipin},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {42--56},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_912},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@misc{chernickAnswerHowWould2012,
  title = {Answer to "{{How}} Would You Explain Covariance to Someone Who Understands Only the Mean?"},
  shorttitle = {Answer to "{{How}} Would You Explain Covariance to Someone Who Understands Only the Mean?},
  author = {Chernick, Michael R.},
  year = {2012},
  month = may,
  journal = {Cross Validated},
  file = {/Users/tobias/Zotero/storage/QHD8TNJT/how-would-you-explain-covariance-to-someone-who-understands-only-the-mean.html}
}

@article{chichePartSpeechTagging2022,
  title = {Part of Speech Tagging: A Systematic Review of Deep Learning and Machine Learning Approaches},
  shorttitle = {Part of Speech Tagging},
  author = {Chiche, Alebachew and Yitagesu, Betselot},
  year = {2022},
  month = jan,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {10},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00561-y},
  abstract = {Natural language processing (NLP) tools have sparked a great deal of interest due to rapid improvements in information and communications technologies. As a result, many different NLP tools are being produced. However, there are many challenges for developing efficient and effective NLP tools that accurately process natural languages. One such tool is part of speech (POS) tagging, which tags a particular sentence or words in a paragraph by looking at the context of the sentence/words inside the paragraph. Despite enormous efforts by researchers, POS tagging still faces challenges in improving accuracy while reducing false-positive rates and in tagging unknown words. Furthermore, the presence of ambiguity when tagging terms with different contextual meanings inside a sentence cannot be overlooked. Recently, Deep learning (DL) and Machine learning (ML)-based POS taggers are being implemented as potential solutions to efficiently identify words in a given sentence across a paragraph. This article first clarifies the concept of part of speech POS tagging. It then provides the broad categorization based on the famous ML and DL techniques employed in designing and implementing part of speech taggers. A comprehensive review of the latest POS tagging articles is provided by discussing the weakness and strengths of the proposed approaches. Then, recent trends and advancements of DL and ML-based part-of-speech-taggers are presented in terms of the proposed approaches deployed and their performance evaluation metrics. Using the limitations of the proposed approaches, we emphasized various research gaps and presented future recommendations for the research in advancing DL and ML-based POS tagging.},
  keywords = {Deep learning,Hybrid approach,Machine learning,NLP,Part of speech,Part of speech tagging,Performance metrics},
  file = {/Users/tobias/Zotero/storage/K9IEQCR7/Chiche and Yitagesu - 2022 - Part of speech tagging a systematic review of dee.pdf;/Users/tobias/Zotero/storage/HCSSRXPR/s40537-022-00561-y.html}
}

@article{chichePartSpeechTagging2022a,
  title = {Part of Speech Tagging: A Systematic Review of Deep Learning and Machine Learning Approaches},
  shorttitle = {Part of Speech Tagging},
  author = {Chiche, Alebachew and Yitagesu, Betselot},
  year = {2022},
  month = jan,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {10},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00561-y},
  abstract = {Natural language processing (NLP) tools have sparked a great deal of interest due to rapid improvements in information and communications technologies. As a result, many different NLP tools are being produced. However, there are many challenges for developing efficient and effective NLP tools that accurately process natural languages. One such tool is part of speech (POS) tagging, which tags a particular sentence or words in a paragraph by looking at the context of the sentence/words inside the paragraph. Despite enormous efforts by researchers, POS tagging still faces challenges in improving accuracy while reducing false-positive rates and in tagging unknown words. Furthermore, the presence of ambiguity when tagging terms with different contextual meanings inside a sentence cannot be overlooked. Recently, Deep learning (DL) and Machine learning (ML)-based POS taggers are being implemented as potential solutions to efficiently identify words in a given sentence across a paragraph. This article first clarifies the concept of part of speech POS tagging. It then provides the broad categorization based on the famous ML and DL techniques employed in designing and implementing part of speech taggers. A comprehensive review of the latest POS tagging articles is provided by discussing the weakness and strengths of the proposed approaches. Then, recent trends and advancements of DL and ML-based part-of-speech-taggers are presented in terms of the proposed approaches deployed and their performance evaluation metrics. Using the limitations of the proposed approaches, we emphasized various research gaps and presented future recommendations for the research in advancing DL and ML-based POS tagging.},
  keywords = {Deep learning,Hybrid approach,Machine learning,NLP,Part of speech,Part of speech tagging,Performance metrics},
  file = {/Users/tobias/Zotero/storage/ED4RC9G6/Chiche and Yitagesu - 2022 - Part of speech tagging a systematic review of dee.pdf;/Users/tobias/Zotero/storage/9FEQCINB/articles.html}
}

@misc{chlAnswerHowWould2011,
  title = {Answer to "{{How}} Would You Explain Covariance to Someone Who Understands Only the Mean?"},
  shorttitle = {Answer to "{{How}} Would You Explain Covariance to Someone Who Understands Only the Mean?},
  author = {{chl}},
  year = {2011},
  month = nov,
  journal = {Cross Validated},
  file = {/Users/tobias/Zotero/storage/PINHBTFW/how-would-you-explain-covariance-to-someone-who-understands-only-the-mean.html}
}

@incollection{coatesAutonomousHelicopterFlight2017,
  title = {Autonomous {{Helicopter Flight Using Reinforcement Learning}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Coates, Adam and Abbeel, Pieter and Ng, Andrew Y.},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {75--85},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_16},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@article{coimbraVeilGraphIncrementalGraph2022,
  title = {{{VeilGraph}}: Incremental Graph Stream Processing},
  shorttitle = {{{VeilGraph}}},
  author = {Coimbra, Miguel E. and Esteves, S{\'e}rgio and Francisco, Alexandre P. and Veiga, Lu{\'i}s},
  year = {2022},
  month = feb,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {23},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00565-8},
  abstract = {Graphs are found in a plethora of domains, including online social networks, the World Wide Web and the study of epidemics, to name a few. With the advent of greater volumes of information and the need for continuously updated results under temporal constraints, it is necessary to explore alternative approaches that further enable performance improvements. In the scope of stream processing over graphs, we research the trade-offs between result accuracy and the speedup of approximate computation techniques. The relationships between the frequency of graph algorithm execution, the update rate and the type of update play an important role in applying these techniques. Herein we present VeilGraph, through which we conducted our research. We showcase an innovative model for approximate graph processing implemented in Apache Flink. We analyse the feasibility of our model and evaluate it with the case study of the PageRank algorithm, the most famous measure of vertex centrality used to rank websites in search engine results. Our experiments show that VeilGraph can often reduce latency closely to half (speedup of 2.0\texttimes ), while achieving result quality above 95\% when compared to results of the traditional version of PageRank executing in Apache Flink with Gelly (i.e. without any summarization or approximation techniques). In some cases, depending on the workload, speedups against Apache Flink reach up to 3.0x (i.e. yielding a reduction of up to 66\% in latency). We have found VeilGraph implementation on Flink to be scalable, as it is able to improve performance up to 10X speedups, when more resources are employed (16 workers), achieving better speedups with scale for larger graphs, which are the most relevant.},
  keywords = {Approximate processing,Dataflow programming,Distributed computation,Graph processing,Stream processing,Summarization},
  file = {/Users/tobias/Zotero/storage/TQFHSFVI/Coimbra et al. - 2022 - VeilGraph incremental graph stream processing.pdf;/Users/tobias/Zotero/storage/8PYLD998/articles.html}
}

@article{coquelinAcceleratingNeuralNetwork2022,
  title = {Accelerating Neural Network Training with Distributed Asynchronous and Selective Optimization ({{DASO}})},
  author = {Coquelin, Daniel and Debus, Charlotte and G{\"o}tz, Markus and {von der Lehr}, Fabrice and Kahn, James and Siggel, Martin and Streit, Achim},
  year = {2022},
  month = feb,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {14},
  issn = {2196-1115},
  doi = {10.1186/s40537-021-00556-1},
  abstract = {With increasing data and model complexities, the time required to train neural networks has become prohibitively large. To address the exponential rise in training time, users are turning to data parallel neural networks (DPNN) and large-scale distributed resources on computer clusters. Current DPNN approaches implement the network parameter updates by synchronizing and averaging gradients across all processes with blocking communication operations after each forward-backward pass. This synchronization is the central algorithmic bottleneck. We introduce the distributed asynchronous and selective optimization (DASO) method, which leverages multi-GPU compute node architectures to accelerate network training while maintaining accuracy. DASO uses a hierarchical and asynchronous communication scheme comprised of node-local and global networks while adjusting the global synchronization rate during the learning process. We show that DASO yields a reduction in training time of up to 34\% on classical and state-of-the-art networks, as compared to current optimized data parallel training methods.},
  keywords = {Data parallel training,Machine learning,Multi-GPU,Multi-node,Neural networks,Stale gradients},
  file = {/Users/tobias/Zotero/storage/XZ7SZ543/Coquelin et al. - 2022 - Accelerating neural network training with distribu.pdf;/Users/tobias/Zotero/storage/Z2UJNMXG/articles.html}
}

@misc{CPSC470570,
  title = {{{CPSC}} 470/570 - {{Artificial Intelligence}}},
  howpublished = {https://zoo.cs.yale.edu/classes/cs470/index.html},
  keywords = {artificial intelligence,downloads,material,repository,yale},
  file = {/Users/tobias/Zotero/storage/SUKLS4VG/index.html}
}

@misc{CS344Policies,
  title = {{{CS}} 344 - {{Policies}}},
  howpublished = {https://cs.calvin.edu/courses/cs/344/kvlinden/policies.html},
  file = {/Users/tobias/Zotero/storage/ZCD9ZFWR/policies.html}
}

@misc{CuPy,
  title = {{{CuPy}}},
  journal = {CuPy},
  abstract = {NumPy \& SciPy for GPU},
  howpublished = {https://cupy.dev/},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/BAW9XGWQ/cupy.dev.html}
}

@misc{dakkaronAnswerCombinationsElements2015,
  title = {Answer to "{{Combinations}} between Elements in Two Tuples in {{Python}}"},
  author = {Dakkaron},
  year = {2015},
  month = jun,
  journal = {Stack Overflow},
  keywords = {combinations,combinatorics,itertools,itertools.product},
  file = {/Users/tobias/Zotero/storage/QVGCEYV9/combinations-between-elements-in-two-tuples-in-python.html}
}

@incollection{dasguptaActiveLearningTheory2017,
  title = {Active {{Learning Theory}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Dasgupta, Sanjoy},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {14--19},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_7},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@misc{DataPreparationMachine,
  title = {Data\_preparation\_for\_machine\_learning.Pdf},
  file = {/Users/tobias/Zotero/storage/PNIF6ELI/data_preparation_for_machine_learning.pdf}
}

@misc{DeepLearning,
  title = {Deep {{Learning}}},
  howpublished = {https://www.deeplearningbook.org/},
  keywords = {deep learning,exercises,lectures,website},
  file = {/Users/tobias/Zotero/storage/5KSZ9PST/www.deeplearningbook.org.html}
}

@misc{DeepLearningComputer,
  title = {Deep\_learning\_for\_computer\_vision.Pdf},
  file = {/Users/tobias/Zotero/storage/DAMJB49W/deep_learning_for_computer_vision.pdf}
}

@misc{DeepLearningNlp,
  title = {Deep\_learning\_for\_nlp.Pdf},
  file = {/Users/tobias/Zotero/storage/FABZSYQV/deep_learning_for_nlp.pdf}
}

@misc{DeepLearningPython,
  title = {Deep\_learning\_with\_python.Pdf},
  file = {/Users/tobias/Zotero/storage/BTFD7DLC/deep_learning_with_python.pdf}
}

@misc{DeepLearningTensorflow2022,
  title = {Deep {{Learning}} with {{Tensorflow}} 2.0},
  year = {2022},
  month = feb,
  abstract = {Practical Exercises in TensorFlow 2.0 for Ian Goodfellows Deep Learning Book},
  howpublished = {ADhiraiyan AI Solutions},
  keywords = {\#nosource,1,2,3,4,algorithms,chapters,deep learning book,deep-learning,github,jupyter-notebook,machine-learning,notebooks,python,repo,tensorflow}
}

@misc{DeepLearningTime,
  title = {Deep\_learning\_time\_series\_forecasting.Pdf},
  file = {/Users/tobias/Zotero/storage/5J6X2J6J/deep_learning_time_series_forecasting.pdf}
}

@book{deepProbabilityStatisticsIntegrated2006,
  title = {Probability and Statistics with Integrated Software Routines},
  author = {Deep, Ronald},
  year = {2006},
  publisher = {{Academic Press}},
  address = {{Burlington, MA}},
  isbn = {978-0-12-369463-8},
  langid = {english},
  lccn = {QA273.19.E4 D44 2006},
  keywords = {Computer simulation,exercises,how to probability theory,how to sample,Mathematical statistics,Probabilities},
  file = {/Users/tobias/Zotero/storage/89VJF3QJ/Deep - 2006 - Probability and statistics with integrated softwar.pdf}
}

@article{demilieDetectionFakeNews2022,
  title = {Detection of Fake News and Hate Speech for {{Ethiopian}} Languages: A Systematic Review of the Approaches},
  shorttitle = {Detection of Fake News and Hate Speech for {{Ethiopian}} Languages},
  author = {Demilie, Wubetu Barud and Salau, Ayodeji Olalekan},
  year = {2022},
  month = may,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {66},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00619-x},
  abstract = {With the proliferation of social media platforms that provide anonymity, easy access, online community development, and online debate, detecting and tracking hate speech has become a major concern for society, individuals, policymakers, and researchers. Combating hate speech and fake news are the most pressing societal issues. It is difficult to expose false claims before they cause significant harm. Automatic fact or claim verification has recently piqued the interest of various research communities. Despite efforts to use automatic approaches for detection and monitoring, their results are still unsatisfactory, and that requires more research work in the area. Fake news and hate speech messages are any messages on social media platforms that spread negativity in society about sex, caste, religion, politics, race, disability, sexual orientation, and so on. Thus, the type of massage is extremely difficult to detect and combat. This work aims to analyze the optimal approaches for this kind of problem, as well as the relationship between the approaches, dataset type, size, and accuracy. Finally, based on the analysis results of the implemented approaches, deep learning (DL) approaches have been recommended for other Ethiopian languages to increase the performance of all evaluation metrics from different social media platforms. Additionally, as the review results indicate, the combination of DL and machine learning (ML) approaches with a balanced dataset can improve the detection and combating performance of the system.},
  keywords = {Artificial intelligence,Deep learning,Ethiopian languages,Fake news,Hate speech,Machine learning,Social media platform},
  file = {/Users/tobias/Zotero/storage/SZPN62SB/Demilie and Salau - 2022 - Detection of fake news and hate speech for Ethiopi.pdf}
}

@misc{DistillLatestArticles,
  title = {Distill \textemdash{} {{Latest}} Articles about Machine Learning},
  journal = {Distill},
  abstract = {Articles about Machine Learning},
  howpublished = {http://distill.pub/},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/YAMSI5N7/distill.pub.html}
}

@incollection{dorigoAntColonyOptimization2017,
  title = {Ant {{Colony Optimization}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Dorigo, Marco and Birattari, Mauro},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {56--59},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_22},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{drummondAttribute2017,
  title = {Attribute},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Drummond, Chris},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {73--75},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_923},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@article{eckardtReinforcementLearningPrecision2021,
  title = {Reinforcement {{Learning}} for {{Precision Oncology}}},
  author = {Eckardt, Jan-Niklas and Wendt, Karsten and Bornh{\"a}user, Martin and Middeke, Jan Moritz},
  year = {2021},
  month = sep,
  journal = {Cancers},
  volume = {13},
  number = {18},
  pages = {4624},
  issn = {2072-6694},
  doi = {10.3390/cancers13184624},
  abstract = {Precision oncology is grounded in the increasing understanding of genetic and molecular mechanisms that underly malignant disease and offer different treatment pathways for the individual patient. The growing complexity of medical data has led to the implementation of machine learning techniques that are vastly applied for risk assessment and outcome prediction using either supervised or unsupervised learning. Still largely overlooked is reinforcement learning (RL) that addresses sequential tasks by exploring the underlying dynamics of an environment and shaping it by taking actions in order to maximize cumulative rewards over time, thereby achieving optimal long-term outcomes. Recent breakthroughs in RL demonstrated remarkable results in gameplay and autonomous driving, often achieving human-like or even superhuman performance. While this type of machine learning holds the potential to become a helpful decision support tool, it comes with a set of distinctive challenges that need to be addressed to ensure applicability, validity and safety. In this review, we highlight recent advances of RL focusing on studies in oncology and point out current challenges and pitfalls that need to be accounted for in future studies in order to successfully develop RL-based decision support systems for precision oncology.},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/87DXWXYI/Eckardt et al. - 2021 - Reinforcement Learning for Precision Oncology.pdf}
}

@misc{EnsembleLearningAlgorithms,
  title = {Ensemble\_learning\_algorithms\_with\_python.Pdf},
  file = {/Users/tobias/Zotero/storage/V7F3DF44/ensemble_learning_algorithms_with_python.pdf}
}

@article{fattahiImprovedCostsensitiveRepresentation2022,
  title = {Improved Cost-Sensitive Representation of Data for Solving the Imbalanced Big Data Classification Problem},
  author = {Fattahi, Mahboubeh and Moattar, Mohammad Hossein and Forghani, Yahya},
  year = {2022},
  month = may,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {60},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00617-z},
  abstract = {Dimension reduction is a preprocessing step in machine learning for eliminating undesirable features and increasing learning accuracy. In order to reduce the redundant features, there are data representation methods, each of which has its own advantages. On the other hand, big data with imbalanced classes is one of the most important issues in pattern recognition and machine learning. In this paper, a method is proposed in the form of a cost-sensitive optimization problem which implements the process of selecting and extracting the features simultaneously. The feature extraction phase is based on reducing error and maintaining geometric relationships between data by solving a manifold learning optimization problem. In the feature selection phase, the cost-sensitive optimization problem is adopted based on minimizing the upper limit of the generalization error. Finally, the optimization problem which is constituted from the above two problems is solved by adding a cost-sensitive term to create a balance between classes without manipulating the data. To evaluate the results of the feature reduction, the multi-class linear SVM classifier is used on the reduced data. The proposed method is compared with some other approaches on 21 datasets from the UCI learning repository, microarrays and high-dimensional datasets, as well as imbalanced datasets from the KEEL repository. The results indicate the significant efficiency of the proposed method compared to some similar approaches.},
  keywords = {Big data classification,Cost sensitive,Feature extraction,Feature selection,Imbalanced data,Optimization},
  file = {/Users/tobias/Zotero/storage/43ZN2956/Fattahi et al. - 2022 - Improved cost-sensitive representation of data for.pdf}
}

@incollection{fernandez-grandaProbabilityStatisticsData,
  title = {Probability and {{Statistics}} for {{Data Science}}},
  author = {{Fernandez-Granda}, Carlos},
  pages = {234},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/S8XEEARP/Fernandez-Granda - Probability and Statistics for Data Science.pdf}
}

@article{feteneSpatialHeterogeneitiesAcute2022,
  title = {Spatial Heterogeneities in Acute Lower Respiratory Infections Prevalence and Determinants across {{Ethiopian}} Administrative Zones},
  author = {Fetene, Meseret Tadesse and Fenta, Haile Mekonnen and Tesfaw, Lijalem Melie},
  year = {2022},
  month = may,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {68},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00618-y},
  abstract = {Acute lower respiratory infections (ALRI) are a major cause of mortality among children under five. This study aimed to investigate the spatiotemporal pattern of ALRI in Ethiopian administrative zones.},
  keywords = {Acute lower respiratory infection,Administrative zones,Best unbiased predictor,Children aged under five,Generalized linear mixed model},
  file = {/Users/tobias/Zotero/storage/TJYVPCJ7/Fetene et al. - 2022 - Spatial heterogeneities in acute lower respiratory.pdf}
}

@inproceedings{firouzniaAdaptiveCooperativeCoevolutionary2022,
  title = {An {{Adaptive Cooperative Coevolutionary Algorithm}} for {{Parallel Feature Selection}} in {{High-Dimensional Datasets}}},
  booktitle = {2022 30th {{Euromicro International Conference}} on {{Parallel}}, {{Distributed}} and {{Network-based Processing}} ({{PDP}})},
  author = {Firouznia, Marjan and Trunfio, Giuseppe A.},
  year = {2022},
  month = mar,
  pages = {211--218},
  issn = {2377-5750},
  doi = {10.1109/PDP55904.2022.00040},
  abstract = {Nowadays, it is common in many disciplines and application fields to collect large volumes of data characterized by a high number of features. Such datasets are at the basis of modern applications of supervised Machine Learning, where the goal is to create a classifier for newly presented data. However, it is well known that the presence of irrelevant features in the dataset can lead to a harder learning phase and, above all, can produce suboptimal classifiers. For this reason, the ability to select an appropriate subset of the available features is becoming increasingly important. Traditionally, optimization metaheuristics have been used with success in the task of feature selection. However, many of the approaches presented in the literature are not applicable to datasets with thousands of features since common optimization algorithms often suffer from poor scalability with respect to the size of the search space. In this paper, the problem of feature subset optimization is successfully addressed by a cooperative coevolutionary algorithm based on Differential Evolution. In the proposed algorithm, parallelized for multi-threaded execution on shared-memory architectures, a suitable strategy for reducing the dimensionality of the search space and adapting the population size during the optimization results in a significant performance. A numerical investigation on some high-dimensional datasets show that, in most cases, the proposed approach can achieve smaller feature subsets and higher classification performance than other state-of-the-art methods.},
  keywords = {Computer architecture,Cooperative Coevolution,Differential Evolution,Feature extraction,Feature selection,Handheld computers,Machine learning,Metaheuristics,Parallel Computing,Scalability,Sociology},
  file = {/Users/tobias/Zotero/storage/9PRFZW6M/Firouznia and Trunfio - 2022 - An Adaptive Cooperative Coevolutionary Algorithm f.pdf;/Users/tobias/Zotero/storage/RBI346YC/9756693.html}
}

@misc{FloatingPointPrecision,
  title = {Floating Point Precision ({{FP16}} vs. {{FP32}}) | {{Deep Learning}} with {{Dell EMC Isilon}} | {{Dell Technologies Info Hub}}},
  abstract = {\hspace{0pt}This document demonstrates how the Dell EMC Isilon F800 All-Flash Scale-out NAS and Dell EMC PowerEdge C4140 with NVIDIA Tesla V100 GPUs can be used to accelerate and scale deep learning training workloads.},
  howpublished = {https://infohub.delltechnologies.com/l/deep-learning-with-dell-emc-isilon-1/floating-point-precision-fp16-vs-fp32},
  langid = {english},
  keywords = {deep learning,FP16,FP32,neural net,precision,training},
  file = {/Users/tobias/Zotero/storage/96WX7GAM/floating-point-precision-fp16-vs-fp32.html}
}

@misc{flomAnswerHowWould2011,
  title = {Answer to "{{How}} Would You Explain Covariance to Someone Who Understands Only the Mean?"},
  shorttitle = {Answer to "{{How}} Would You Explain Covariance to Someone Who Understands Only the Mean?},
  author = {Flom, Peter},
  year = {2011},
  month = nov,
  journal = {Cross Validated},
  file = {/Users/tobias/Zotero/storage/GLHL9UDJ/how-would-you-explain-covariance-to-someone-who-understands-only-the-mean.html}
}

@article{ganfureComparativeAnalysisDeep2022,
  title = {Comparative Analysis of Deep Learning Based {{Afaan Oromo}} Hate Speech Detection},
  author = {Ganfure, Gaddisa Olani},
  year = {2022},
  month = jun,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {76},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00628-w},
  abstract = {Social media platforms like Facebook, YouTube, and Twitter are banking on developing machine learning models to help stop the spread of hateful speech on their platforms. The idea is that machine learning models that utilize natural language processing will detect hate speech faster and better than people can. Despite numerous progress has been made for resource reach language, only a few attempts have been made for Ethiopian Languages such as Afaan Oromo. This paper examines the viability of deep learning models for Afaan Oromo hate speech recognition. Toward this, the biggest dataset of hate speech was collected and annotated by the language experts. Variations of profound deep learning models such as CNN, LSTMs, BiLSTMs, LSTM, GRU, and CNN-LSTM are examined to evaluate their viability in identifying Afaan Oromo Hate speeches. The result uncovers that the model dependent on CNN and Bi-LSTM outperforms all the other investigated models with an average F1-score of 87\%.},
  keywords = {Afaan Oromo,Artificial Intelligence,Deep Learning,Ethiopian Languages,Hate Speech Detection},
  file = {/Users/tobias/Zotero/storage/FVIQGLKB/Ganfure - 2022 - Comparative analysis of deep learning based Afaan .pdf}
}

@article{gangilPredictingClinicalOutcomes2022,
  title = {Predicting Clinical Outcomes of Radiotherapy for Head and Neck Squamous Cell Carcinoma Patients Using Machine Learning Algorithms},
  author = {Gangil, Tarun and Shahabuddin, Amina Beevi and Dinesh Rao, B. and Palanisamy, Krishnamoorthy and Chakrabarti, Biswaroop and Sharan, Krishna},
  year = {2022},
  month = feb,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {25},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00578-3},
  abstract = {Radiotherapy is frequently used to treat head and neck Squamous cell carcinomas (HNSCC). Treatment outcomes being highly uncertain, there is a significant need for robust predictive tools to improvise treatment decision-making and better understand HNSCC by recognizing hidden patterns in data. We conducted this study to identify if Machine Learning (ML) could accurately predict outcomes and identify new prognostic variables in HNSCC.},
  keywords = {Feature selection,Machine learning,Missing value imputation,Prognosis,Recurrence pattern,Shapely values,Squamous cell head and neck cancer},
  file = {/Users/tobias/Zotero/storage/EMEV24LV/Gangil et al. - 2022 - Predicting clinical outcomes of radiotherapy for h.pdf;/Users/tobias/Zotero/storage/6R6L2NXA/articles.html}
}

@article{garouaniUsingMetalearningAutomated2022,
  title = {Using Meta-Learning for Automated Algorithms Selection and Configuration: An Experimental Framework for Industrial Big Data},
  shorttitle = {Using Meta-Learning for Automated Algorithms Selection and Configuration},
  author = {Garouani, Moncef and Ahmad, Adeel and Bouneffa, Mourad and Hamlich, Mohamed and Bourguin, Gregory and Lewandowski, Arnaud},
  year = {2022},
  month = apr,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {57},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00612-4},
  abstract = {Advanced analytics are fundamental to transform large manufacturing data into resourceful knowledge for various purposes. In its very nature, such ``industrial big data'' can relay its usefulness to reach further utilitarian applications. In this context, Machine Learning~(ML) is among the major predictive modeling approaches that can enable manufacturing researchers and practitioners to improve the product quality and achieve resource efficiency by exploiting large amounts of data~(which is collected during manufacturing process). However, disposing ML algorithms is a challenging task for manufacturing industrial actors due to the prior specification of one or more algorithms hyperparameters~(HPs) and their values. Moreover, manufacturing industrial actors often lack the technical expertise to apply advanced analytics. Consequently, it necessitates frequent consultations with data scientists; but such collaborations tends to cost the delays, which can generate the risks such as human-resource bottlenecks. As the complexity of these tasks increases, so does the demand for support solutions. In response, the field of automated ML~(AutoML) is a data mining-based formalism that aims to reduce human effort and speedup the development cycle through automation. In this regard, existing approaches include evolutionary algorithms, Bayesian optimization, and reinforcement learning. These approaches mainly focus on providing the user assistance by automating the partial or entire data analysis process, but they provide very limited details concerning their impact on the analysis. The major goal of these conventional approaches has been generally focused on the performance factors, while the other important and even crucial aspects such as computational complexity are rather omitted. Therefore, in this paper, we present a novel meta-learning based approach to automate ML predictive models built over the industrial big data. The approach is leveraged with development of, AMLBID, an Automated ML tool for Big Industrial Data analyses. It attempts to support the manufacturing engineers and researchers who presumably have meager skills to carry out the advanced analytics. The empirical results show that AMLBID surpasses the state-of-the-art approaches and could retrieve the usefulness of large manufacturing data to prosper the research in manufacturing domain and improve the use of predictive models instead of precluding their outcomes.},
  keywords = {Algorithms selection,AutoML,Big industrial data,Decision support systems,Industry 4.0,Machine learning,Meta-learning},
  file = {/Users/tobias/Zotero/storage/JWSD9XRG/Garouani et al. - 2022 - Using meta-learning for automated algorithms selec.pdf}
}

@misc{GenerativeAdversarialNetworks,
  title = {Generative\_adversarial\_networks.Pdf},
  file = {/Users/tobias/Zotero/storage/5UWHHCD8/generative_adversarial_networks.pdf}
}

@misc{GensimTopicModelling,
  title = {Gensim: Topic Modelling for Humans},
  shorttitle = {Gensim},
  abstract = {Efficient topic modelling in Python},
  howpublished = {https://radimrehurek.com/gensim/dist\_lsi.html},
  langid = {english},
  keywords = {gensim,logging library,parallel computing,python},
  file = {/Users/tobias/Zotero/storage/I6GMS775/dist_lsi.html}
}

@incollection{gerstnerBiologicalLearningSynaptic2017,
  title = {Biological {{Learning}}: {{Synaptic Plasticity}}, {{Hebb Rule}} and {{Spike Timing Dependent Plasticity}}},
  shorttitle = {Biological {{Learning}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Gerstner, Wulfram},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {140--143},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_80},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@misc{GettingStartedKit,
  title = {Getting {{Started Kit}} for {{Accelerated Data Science}} | {{NVIDIA}}},
  howpublished = {https://www.nvidia.com/en-us/ai-data-science/resources/rapids-kit/},
  file = {/Users/tobias/Zotero/storage/7H5MSP63/rapids-kit.html}
}

@misc{GitIgnoringFiles,
  title = {Git - {{Ignoring Files}}},
  howpublished = {https://www.logicbig.com/tutorials/misc/git/git-ignore.html},
  file = {/Users/tobias/Zotero/storage/BQXYRS3N/git-ignore.html}
}

@article{goethalsNonlinearNatureCost2022,
  title = {The Non-Linear Nature of the Cost of Comprehensibility},
  author = {Goethals, Sofie and Martens, David and Evgeniou, Theodoros},
  year = {2022},
  month = mar,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {30},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00579-2},
  abstract = {A key challenge in Artificial Intelligence (AI) has been the potential trade-off between the accuracy and comprehensibility of machine learning models, as that also relates to their safe and trusted adoption. While there has been a lot of talk about this trade-off, there is no systematic study that assesses to what extent it exists, how often it occurs, and for what types of datasets. Based on the analysis of 90 benchmark classification datasets, we find that this trade-off exists for most (69\%) of the datasets, but that somewhat surprisingly for the majority of cases it is rather small while for only a few it is very large. Comprehensibility can be enhanced by adding yet another algorithmic step, that of surrogate modelling using so-called `explainable' models. Such models can improve the accuracy-comprehensibility trade-off, especially in cases where the black box was initially better. Finally, we find that dataset characteristics related to the complexity required to model the dataset, and the level of noise, can significantly explain this trade-off and thus the cost of comprehensibility. These insights lead to specific guidelines on how and when to apply AI algorithms when comprehensibility is required.},
  keywords = {Accuracy-comprehensibility trade-off,Cost of comprehensibility,Explainable Artificial Intelligence},
  file = {/Users/tobias/Zotero/storage/Z2I8XQDP/Goethals et al. - 2022 - The non-linear nature of the cost of comprehensibi.pdf;/Users/tobias/Zotero/storage/43CCYHKK/articles.html}
}

@article{gomez-craviotoSupervisedMachineLearning2022,
  title = {Supervised Machine Learning Predictive Analytics for Alumni Income},
  author = {{Gomez-Cravioto}, Daniela A. and {Diaz-Ramos}, Ramon E. and {Hernandez-Gress}, Neil and Preciado, Jose Luis and Ceballos, Hector G.},
  year = {2022},
  month = jan,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {11},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00559-6},
  abstract = {This paper explores machine learning algorithms and approaches for predicting alum income to obtain insights on the strongest predictors and a `high' earners' class.},
  keywords = {Alumni survey analysis,Explainable Artificial Intelligence,Income prediction,Knowledge Discovery,Machine learning},
  file = {/Users/tobias/Zotero/storage/ULIG5MK6/Gomez-Cravioto et al. - 2022 - Supervised machine learning predictive analytics f.pdf;/Users/tobias/Zotero/storage/Y9CZ6RPD/articles.html}
}

@misc{GoogleColaboratory,
  title = {Google {{Colaboratory}}},
  howpublished = {https://colab.research.google.com/github/adhiraiyan/DeepLearningWithTF2.0/blob/master/notebooks/03.00-Probability-and-Information-Theory.ipynb\#scrollTo=AnKUDzrkCwZw},
  langid = {english},
  keywords = {3,chapter,deep learning book,exercise,first chapter,information theory,introduction,ipynb,notebook,probability,todo,visualize margins},
  file = {/Users/tobias/Zotero/storage/LQBE4MR2/01.00-Introduction.html;/Users/tobias/Zotero/storage/TXZLZKP8/03.00-Probability-and-Information-Theory.html}
}

@article{goyvaertsRegexBuddyManual,
  title = {{{RegexBuddy Manual}}},
  author = {Goyvaerts, Jan},
  pages = {519},
  keywords = {⛔ No DOI found},
  file = {/Users/tobias/Zotero/storage/S97VTYCS/Goyvaerts - RegexBuddy Manual.pdf}
}

@article{guiIdentificationMRNAVaccines2022,
  title = {Identification of {{mRNA}} Vaccines and Conserved Ferroptosis Related Immune Landscape for Individual Precision Treatment in Bladder Cancer},
  author = {Gui, Cheng-Peng and Li, Jia-Ying and Fu, Liang-Min and Luo, Cheng-Gong and Zhang, Chi and Tang, Yi-Ming and Zhang, Li-zhen and Shu, Guan-nan and Wu, Rong-Pei and Luo, Jun-Hang},
  year = {2022},
  month = jul,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {88},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00641-z},
  abstract = {The aim of this study was to identify the ferroptosis induced tumor microenvironment (FeME) landscape in bladder cancer (BCa) for mRNA vaccine development and selecting suitable patients for precision treatment.},
  keywords = {Bladder cancer,Ferroptosis,Immunotherapy,mRNA vaccine,Precise treatment,Tumor immune microenvironment},
  file = {/Users/tobias/Zotero/storage/WK5WIWP5/Gui et al. - 2022 - Identification of mRNA vaccines and conserved ferr.pdf}
}

@article{habibDiscoveringTopweightedKtruss2022,
  title = {Discovering Top-Weighted k-Truss Communities in Large Graphs},
  author = {Habib, Wafaa M. A. and Mokhtar, Hoda M. O. and {El-Sharkawi}, Mohamed E.},
  year = {2022},
  month = apr,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {36},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00588-1},
  abstract = {Community Search is the problem of querying networks in order to discover dense subgraphs-communities-that satisfy given query parameters. Most community search models consider link structure and ignore link weight while answering the required queries. Given the importance of link weight in different networks, this paper considers both link structure and link weight to discover top-r weighted k-truss communities via community search. The top-weighted k-truss communities are those communities with the highest weight and the highest cohesiveness within the network. All recent studies that considered link weight discover top-weighted communities via global search and index-based search techniques. In this paper three different algorithms are proposed to scale-up the existing approaches of weighted community search via local search. The performance evaluation shows that the proposed algorithms significantly outperform the existing state-of-the-art algorithms over different datasets in terms of search time by several orders of magnitude.},
  keywords = {Community search,k-truss community detection model,Weighted graph},
  file = {/Users/tobias/Zotero/storage/T79WK8BK/Habib et al. - 2022 - Discovering top-weighted k-truss communities in la.pdf;/Users/tobias/Zotero/storage/G955RSCH/articles.html}
}

@inproceedings{hamadaEvaluationRecursiveFeature2021,
  title = {Evaluation of {{Recursive Feature Elimination}} and {{LASSO Regularization-based}} Optimized Feature Selection Approaches for Cervical Cancer Prediction},
  booktitle = {2021 {{IEEE}} 14th {{International Symposium}} on {{Embedded Multicore}}/{{Many-core Systems-on-Chip}} ({{MCSoC}})},
  author = {Hamada, Mohamed and Tanimu, Jesse Jeremiah and Hassan, Mohammed and Kakudi, Habeebah Adamu and Robert, Patience},
  year = {2021},
  month = dec,
  pages = {333--339},
  doi = {10.1109/MCSoC51149.2021.00056},
  abstract = {Cervical cancer is one of the leading causes of premature mortality among women worldwide and more than 85\% of these deaths are in developing countries. There are several risk factors associated with cervical cancer. In this research, the aim is to develop a predictive model for predicting the outcome of patient's cervical cancer results, given risk patterns from individual medical records and preliminary screening. This work presents a machine learning method using Decision Tree (DT) algorithm to analyze the risk factors of cervical cancer. Recursive Feature Elimination (RFE) and least absolute shrinkage and selection operator (LASSO) feature selection techniques were fully explored to determine the most important attributes for cervical cancer prediction. Comparative analysis of the 2 feature selection techniques were performed to show the importance of feature selection in cervical cancer prediction. Based on the result of the analysis, we can conclude that the proposed model produced the highest accuracy of 98\% and 96\% respectively while using DT with RFE and LASSO feature selection techniques respectively.},
  keywords = {Analytical models,cervical cancer,Developing countries,Feature extraction,LASSO,machine learning,Machine learning,Machine learning algorithms,Multicore processing,prediction,Predictive models,RFE},
  file = {/Users/tobias/Zotero/storage/5VYVCWYA/Hamada et al. - 2021 - Evaluation of Recursive Feature Elimination and LA.pdf;/Users/tobias/Zotero/storage/WAP6EUC5/9691991.html}
}

@article{hansunMultivariateCryptocurrencyPrediction2022,
  title = {Multivariate Cryptocurrency Prediction: Comparative Analysis of Three Recurrent Neural Networks Approaches},
  shorttitle = {Multivariate Cryptocurrency Prediction},
  author = {Hansun, Seng and Wicaksana, Arya and Khaliq, Abdul Q. M.},
  year = {2022},
  month = apr,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {50},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00601-7},
  abstract = {As a new type of currency introduced in the new millennium, cryptocurrency has established its ecosystems and attracts many people to use and invest in it. However, cryptocurrencies are highly dynamic and volatile, making it challenging to predict their future values. In this research, we use a multivariate prediction approach and three different recurrent neural networks (RNNs), namely the long short-term memory (LSTM), the bidirectional LSTM (Bi-LSTM), and the gated recurrent unit (GRU). We also propose simple three layers deep networks architecture for the regression task in this study. From the experimental results on five major cryptocurrencies, i.e., Bitcoin (BTC), Ethereum (ETH), Cardano (ADA), Tether (USDT), and Binance Coin (BNB), we find that both Bi-LSTM and GRU have similar performance results in terms of accuracy. However, in terms of the execution time, both LSTM and GRU have similar results, where GRU is slightly better and has lower variation results on average.},
  keywords = {Bidirectional,Cryptocurrency,Gated recurrent unit,Long short-term memory,Prediction,Recurrent neural networks},
  file = {/Users/tobias/Zotero/storage/6EQX28LF/Hansun et al. - 2022 - Multivariate cryptocurrency prediction comparativ.pdf;/Users/tobias/Zotero/storage/MLWNESUC/articles.html}
}

@inproceedings{haquekhantusarDetectingChronicKidney2022,
  title = {Detecting {{Chronic Kidney Disease}}({{CKD}}) at the {{Initial Stage}}: {{A Novel Hybrid Feature-selection Method}} and {{Robust Data Preparation Pipeline}} for {{Different ML Techniques}}},
  shorttitle = {Detecting {{Chronic Kidney Disease}}({{CKD}}) at the {{Initial Stage}}},
  booktitle = {2022 5th {{International Conference}} on {{Computing}} and {{Informatics}} ({{ICCI}})},
  author = {Haque Khan Tusar, Md. Taufiqul and Islam, Md. Touhidul and Raju, Foyjul Islam},
  year = {2022},
  month = mar,
  pages = {400--407},
  doi = {10.1109/ICCI54321.2022.9756094},
  abstract = {Chronic Kidney Disease (CKD) has infected almost 800 million people around the world. Around 1.7 million people die each year because of it. Detecting CKD in the initial stage is essential for saving millions of lives. Many researchers have applied distinct Machine Learning (ML) methods to detect CKD at an early stage, but detailed studies are still missing. We present a structured and thorough method for dealing with the complexities of medical data with optimal performance. Besides, this study will assist researchers in producing clear ideas on the medical data preparation pipeline. In this paper, we applied KNN Imputation to impute missing values, Local Outlier Factor to remove outliers, SMOTE to handle data imbalance, K-stratified K-fold Cross-validation to validate the ML models, and a novel hybrid feature selection method to remove redundant features. Applied algorithms in this study are Support Vector Machine, Gaussian Naive Bayes, Decision Tree, Random Forest, Logistic Regression, K-Nearest Neighbour, Gradient Boosting, Adaptive Boosting, and Extreme Gradient Boosting. Finally, the Random Forest can detect CKD with 100\% accuracy without any data leakage.},
  keywords = {Boosting,Complexity theory,Data models,Early Diagnosis,Feature extraction,Healthcare Informatics,Informatics,Machine Learning,Medical diagnostic imaging,Pipelines,Pre-processing},
  file = {/Users/tobias/Zotero/storage/T6WAP5Q8/Haque Khan Tusar et al. - 2022 - Detecting Chronic Kidney Disease(CKD) at the Initi.pdf;/Users/tobias/Zotero/storage/EAWQ25XZ/9756094.html}
}

@incollection{hartikainenDataBasedForestManagement2016,
  title = {Data-{{Based Forest Management}} with {{Uncertainties}} and {{Multiple Objectives}}},
  booktitle = {Machine {{Learning}}, {{Optimization}}, and {{Big Data}}},
  author = {Hartikainen, Markus and Eyvindson, Kyle and Miettinen, Kaisa and Kangas, Annika},
  editor = {Pardalos, Panos M. and Conca, Piero and Giuffrida, Giovanni and Nicosia, Giuseppe},
  year = {2016},
  volume = {10122},
  pages = {16--29},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-51469-7_2},
  abstract = {In this paper, we present an approach of employing multiobjective optimization to support decision making in forest management planning. The planning is based on data representing so-called stands, each consisting of homogeneous parts of the forest, and simulations of how the trees grow in the stands under different treatment options. Forest planning concerns future decisions to be made that include uncertainty. We employ as objective functions both the expected values of incomes and biodiversity as well as the value at risk for both of these objectives. In addition, we minimize the risk level for both the income value and the biodiversity value. There is a tradeoff between the expected value and the value at risk, as well as between the value at risk of the two objectives of interest and, thus, decision support is needed to find the best balance between the conflicting objectives. We employ an interactive method where a decision maker iteratively provides preference information to find the most preferred management plan and at the same time learns about the interdependencies of the objectives.},
  isbn = {978-3-319-51468-0 978-3-319-51469-7},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/CQEBYI5U/Hartikainen et al. - 2016 - Data-Based Forest Management with Uncertainties an.pdf}
}

@article{harywantoBERTweetbasedDesignMonitoring2022,
  title = {A {{BERTweet-based}} Design for Monitoring Behaviour Change Based on Five Doors Theory on Coral Bleaching Campaign},
  author = {Harywanto, Gabriela Nathania and Veron, Juan Sebastian and Suhartono, Derwin},
  year = {2022},
  month = may,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {73},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00615-1},
  abstract = {Coral reefs are very important ecosystem which are the foundation of all life on this earth, but now they are under threat. Coral bleaching are happening now at a serious rate and the ultimate goal of conservation effort toward this issue is behaviour change. One of the most important parts of conservation effort is monitoring. However, monitoring the success of the coral bleaching campaign on behaviour change requires extensive data collection so traditional methods are not effective because they require resources that may not be met. The goal of this study is to build fast and vast automation in analyzing the stage of behaviour change. Social media data has prospect to become good alternative to be used because social media usage is currently increasing every year, including Twitter. Therefore, an automatic classification model was designed which can identify the stages of behaviour change based on the Five Doors Theory on Twitter. Five Doors Theory define 5 stages of behavior change: Desirability, Enabling Context, Can Do, Buzz, and Invitation. The data was fetched through a trusted repository, Mendeley Data, with title "An Annotated Dataset for Identifying Behaviour Change Based on Five Doors Theory Under Coral Bleaching Phenomenon on Twitter". There are 1,222 tweets with keywords related to coral bleaching that have been annotated according to the behaviour change stages. There are two proposed designs: embedding extraction which utilizes the output of each encoder layer in BERTweet and stacking ensemble which uses several BERTweet models with different hyperparameters that are ensembled using a logistic regression model. The best accuracy of 0.7796 with an f1-score of 0.7945 was obtained in the stacking ensemble design scenario. The classification model created can identify each class at the stage of behaviour change well, even though the dataset is unbalanced in its distribution. The proposed design has a performance that exceeds all baseline models and the standalone BERTweet. In conclusion, the automatic classification model create the process of monitoring the stages of behavior change run effectively and efficiently so that the success of the coral bleaching campaign can be monitored and achieved.},
  keywords = {Behaviour change,BERTweet model,Embedding extraction,Ensemble technique,Five Doors Theory,Tweet classification},
  file = {/Users/tobias/Zotero/storage/YCCZQ2LI/Harywanto et al. - 2022 - A BERTweet-based design for monitoring behaviour c.pdf}
}

@book{hastieElementsStatisticalLearning2009,
  title = {The Elements of Statistical Learning: Data Mining, Inference, and Prediction},
  shorttitle = {The Elements of Statistical Learning},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, J. H.},
  year = {2009},
  series = {Springer Series in Statistics},
  edition = {2nd ed},
  publisher = {{Springer}},
  address = {{New York, NY}},
  isbn = {978-0-387-84857-0 978-0-387-84858-7},
  langid = {english},
  lccn = {Q325.5 .H39 2009},
  keywords = {Bioinformatics,Computational intelligence,Data mining,Forecasting,Inference,Machine learning,Methodology,Statistics,top},
  file = {/Users/tobias/Zotero/storage/58NLYS52/Hastie et al. - 2009 - The elements of statistical learning data mining,.pdf}
}

@incollection{hintonBoltzmannMachines2017,
  title = {Boltzmann {{Machines}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Hinton, Geoffrey},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {164--168},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_31},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@article{hofmannLetterValuePlotsBoxplots2017,
  title = {Letter-{{Value Plots}}: {{Boxplots}} for {{Large Data}}},
  shorttitle = {Letter-{{Value Plots}}},
  author = {Hofmann, Heike and Wickham, Hadley and Kafadar, Karen},
  year = {2017},
  month = jul,
  journal = {Journal of Computational and Graphical Statistics},
  volume = {26},
  number = {3},
  pages = {469--477},
  issn = {1061-8600, 1537-2715},
  doi = {10.1080/10618600.2017.1305277},
  abstract = {Conventional boxplots (Tukey, 1977) are useful displays for conveying rough information about the central 50\% and the extent of data. For small-sized data sets (n {$<$} 200), detailed estimates of tail behavior beyond the quartiles may not be trustworthy, so the information provided by boxplots is appropriately somewhat vague beyond the quartiles, and the expected number of ``outliers'' of size n is often less than 10 (Hoaglin et al., 1986). Larger data sets (n {$\approx$} 10, 000\textendash 100, 000) afford more precise estimates of quantiles beyond the quartiles, but conventional boxplots do not show this information about the tails, and, in addition, show large numbers of extreme, but not unexpected, observations.},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/8ZINH2PZ/Hofmann et al. - 2017 - Letter-Value Plots Boxplots for Large Data.pdf}
}

@article{hosnaTransferLearningFriendly2022,
  title = {Transfer Learning: A Friendly Introduction},
  shorttitle = {Transfer Learning},
  author = {Hosna, Asmaul and Merry, Ethel and Gyalmo, Jigmey and Alom, Zulfikar and Aung, Zeyar and Azim, Mohammad Abdul},
  year = {2022},
  month = oct,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {102},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00652-w},
  abstract = {Infinite numbers of real-world applications use Machine Learning (ML) techniques to develop potentially the best data available for the users. Transfer learning (TL), one of the categories under ML, has received much attention from the research communities in the past few years. Traditional ML algorithms perform under the assumption that a model uses limited data distribution to train and test samples. These conventional methods predict target tasks undemanding and are applied to small data distribution. However, this issue conceivably is resolved using TL. TL is acknowledged for its connectivity among the additional testing and training samples resulting in faster output with efficient results. This paper contributes to the domain and scope of TL, citing situational use based on their periods and a few of its applications. The paper provides an in-depth focus on the techniques; Inductive TL, Transductive TL, Unsupervised TL, which consists of sample selection, and domain adaptation, followed by contributions and future directions.},
  keywords = {Domain adaptation,Image classification,Machine learning,Multi-task learning,Sample selection,Sentiment classification,Transfer learning,Zero shot translation},
  file = {/Users/tobias/Zotero/storage/P3G3GMIB/Hosna et al. - 2022 - Transfer learning a friendly introduction.pdf}
}

@article{huiNoninvasiveIdentificationBenign2022,
  title = {Noninvasive Identification of {{Benign}} and Malignant Eyelid Tumors Using Clinical Images via Deep Learning System},
  author = {Hui, Shiqi and Dong, Li and Zhang, Kai and Nie, Zihan and Jiang, Xue and Li, Heyan and Hou, Zhijia and Ding, Jingwen and Wang, Yue and Li, Dongmei},
  year = {2022},
  month = jun,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {84},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00634-y},
  abstract = {Eyelid tumors accounts for 5\textendash 10\% of skin tumors. It is important but difficult to identify malignant eyelid tumors from benign lesions in a cost-effective way. Traditional screening methods for malignancy in eyelid tumors require laborious and time-consuming histopathological process. Therefore, we aimed to develop a deep learning (DL)-based image analysis system for automatic identification of benign and malignant eyelid tumors. Using a common digital camera, we collected clinical images from patients who were histopathologically diagnosed with eyelid tumors. We trained 8 convolutional neural network (CNN) models to identify benign and malignant eyelid tumors, including ResNet-50, ResNet-101, InceptionV3, and InceptionResNetV2. Another group of patients with eyelid tumors were also collected as the prospective validation dataset. Performance of DL models and human clinicians in prospective validation dataset were evaluated and compared. A total of 309 images from 209 patients were used for training DL system, all eight models reached an average accuracy greater than 0.958 in the internal cross-validation. 36 images from 36 patients were included for the prospective validation, the models reached the best performance in accuracy, sensitivity, specificity, and area under curve (AUC) of 0.889 (95\% CI 0.747\textendash 0.956), 0.933 (95\% CI 0.702\textendash 0.988), 0.857 (95\% CI 0.654\textendash 0.950), and 0.966 (95\% CI 0.850\textendash 0.993), respectively. DL system had a similar performance as the senior ophthalmologists, and outreached the performance of junior ophthalmologists and medical students. DL system can identify benign and malignant tumors through common clinical images, with a better performance than most ophthalmologists. Combining DL system with smartphone may enable patients' self-monitoring for eyelid tumors and assist in doctors' clinical decision making.},
  keywords = {Clinical image,Deep learning,Eyelid tumor},
  file = {/Users/tobias/Zotero/storage/7C22QM5T/Hui et al. - 2022 - Noninvasive identification of Benign and malignant.pdf}
}

@misc{hystsPyTorchImageClassification2022,
  title = {{{PyTorch Image Classification}}},
  author = {{hysts}},
  year = {2022},
  month = apr,
  abstract = {PyTorch implementation of image classification models for CIFAR-10/CIFAR-100/MNIST/FashionMNIST/Kuzushiji-MNIST/ImageNet},
  copyright = {MIT},
  keywords = {cifar10,computer-vision,fashion-mnist,imagenet,pytorch}
}

@misc{iglovikovForensicDeepLearning2018,
  title = {Forensic {{Deep Learning}}: {{Kaggle Camera Model Identification Challenge}}},
  shorttitle = {Forensic {{Deep Learning}}},
  author = {Iglovikov, Vladimir},
  year = {2018},
  month = dec,
  journal = {Ternaus Blog},
  abstract = {The importance of data augmentation},
  howpublished = {https://ternaus.blog/machine\_learning/2018/12/05/Forensic-Deep-Learning-Kaggle-Camera-Model-Identification-Challenge.html},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/BR8Y2TXL/Forensic-Deep-Learning-Kaggle-Camera-Model-Identification-Challenge.html}
}

@misc{iglovikovTrainedModelWhat2020,
  title = {I Trained a Model. {{What}} Is Next?},
  author = {Iglovikov, Vladimir},
  year = {2020},
  month = aug,
  journal = {Ternaus Blog},
  abstract = {I wish I knew it when I was active at Kaggle.},
  howpublished = {https://ternaus.blog/tutorial/2020/08/28/Trained-model-what-is-next.html},
  langid = {english},
  keywords = {after-competition,blog-post,grandmaster,kaggle,steps-to-take,workflow},
  file = {/Users/tobias/Zotero/storage/PC3HYBEY/Trained-model-what-is-next.html}
}

@article{ileberiMachineLearningBased2022,
  title = {A Machine Learning Based Credit Card Fraud Detection Using the {{GA}} Algorithm for Feature Selection},
  author = {Ileberi, Emmanuel and Sun, Yanxia and Wang, Zenghui},
  year = {2022},
  month = feb,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {24},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00573-8},
  abstract = {The recent advances of e-commerce and e-payment systems have sparked an increase in financial fraud cases such as credit card fraud. It is therefore crucial to implement mechanisms that can detect the credit card fraud. Features of credit card frauds play important role when machine learning is used for credit card fraud detection, and they must be chosen properly. This paper proposes a machine learning (ML) based credit card fraud detection engine using the genetic algorithm (GA) for feature selection. After the optimized features are chosen, the proposed detection engine uses the following ML classifiers: Decision Tree (DT), Random Forest (RF), Logistic Regression (LR), Artificial Neural Network (ANN), and Naive Bayes (NB). To validate the performance, the proposed credit card fraud detection engine is evaluated using a dataset generated from European cardholders. The result demonstrated that our proposed approach outperforms existing systems.},
  keywords = {Cybersecurity,Fraud detection,Genetic algorithm,Machine learning},
  file = {/Users/tobias/Zotero/storage/AUZN6NH7/Ileberi et al. - 2022 - A machine learning based credit card fraud detecti.pdf;/Users/tobias/Zotero/storage/FLW3TCF8/articles.html}
}

@misc{ImbalancedClassificationPython,
  title = {Imbalanced\_classification\_with\_python.Pdf},
  file = {/Users/tobias/Zotero/storage/DN82T7GP/imbalanced_classification_with_python.pdf}
}

@misc{IndexClassesCs470,
  title = {Index of /Classes/Cs470/Aima},
  howpublished = {https://zoo.cs.yale.edu/classes/cs470/aima/},
  keywords = {ai,ipynb,py,text material,yale},
  file = {/Users/tobias/Zotero/storage/MQQD6CLJ/aima.html}
}

@article{jaafariImpactEnsembleLearning2022,
  title = {The Impact of Ensemble Learning on Surgical Tools Classification during Laparoscopic Cholecystectomy},
  author = {Jaafari, Jaafar and Douzi, Samira and Douzi, Khadija and Hssina, Badr},
  year = {2022},
  month = apr,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {49},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00602-6},
  abstract = {Laparoscopic surgery also know as minimally invasive surgery (MIS), is a type of surgical procedure that allows a surgeon to examine the organs inside of the abdomen without having to make large incisions in the skin. It unifies the competence and skills of highly trained surgeons with the power and precision of machines. Furthermore, surgical instruments are inserted through the abdomen with the help of a laparoscope, which is a tube with a high-intensity light and a high-resolution camera at the end. In addition, recorded videos from this type of surgery have become a steadily more important information source. However, MIS videos are often very long, thereby, navigating through these videos is time and effort consuming. The automatic identification of tool presence in laparoscopic videos leads to detecting what tools are used at each time in surgery and helps in the automatic recognition of surgical workflow. The aim of this paper is to predict surgical tools from laparoscopic videos using three states of the arts CNNs, namely: VGG19, Inception v-4, and NASNet-A. In addition, an ensemble learning method is proposed, combining the three CNNs, to solve the tool presence detection problem as a multi-label classification problem. The proposed methods are evaluated on a dataset of 80 cholecystectomy videos (Cholec80 dataset). The results present an improvement of approximately 6.19\% and a mean average precision of 97.84\% when the ensemble learning method is applied.},
  keywords = {Computer vision,Convolutional neural network,Ensemble learning,Laparoscopic surgery,Transfer learning},
  file = {/Users/tobias/Zotero/storage/3E6NU5C6/Jaafari et al. - 2022 - The impact of ensemble learning on surgical tools .pdf;/Users/tobias/Zotero/storage/UCEJGAEF/articles.html}
}

@misc{JeffreyUllmanBooks,
  title = {Jeffrey {{D}}. {{Ullman}} --- {{Books}}},
  howpublished = {http://infolab.stanford.edu/\textasciitilde ullman/ullman-books.html},
  keywords = {database,massive dataset mining,stanford,supplemental material},
  file = {/Users/tobias/Zotero/storage/BXE57IXL/ullman-books.html}
}

@inproceedings{joodakiNovelEnsembleFeature2022,
  title = {A Novel Ensemble Feature Selection Method through {{Type I}} Fuzzy},
  booktitle = {2022 9th {{Iranian Joint Congress}} on {{Fuzzy}} and {{Intelligent Systems}} ({{CFIS}})},
  author = {Joodaki, Nazanin Zahra and Bagher Dowlatshahi, Mohammad and Joodaki, Mehdi},
  year = {2022},
  month = mar,
  pages = {1--6},
  issn = {2771-1374},
  doi = {10.1109/CFIS54774.2022.9756433},
  abstract = {These days, one of the needed methods in machine learning is feature selection. In other words, in this manner, the most fitting features are picked. Nevertheless, there are various feature selection methods, getting the most suitable features still is a complex problem. Lately, applying several feature selection methods rather than a unique feature selection method is more efficient. In this paper, a new ensemble feature selection method based upon fuzzy Type-I named EFSF is presented. First, three different individual feature selection methods are applied to determine the rank of features separately. Next, Type-I fuzzy handles feature selections' uncertainty and decrease noise to give each feature the best rank. To validate the act of EFSF, it is compared with some ensemble methods and several advanced feature selection methods. EFSF is assessed based on Accuracy, Precision and Recall, metrics. The outcomes verify that the EFSF is better than its competitors. The source code of EFSF is here.},
  keywords = {Codes,Computational modeling,Ensemble feature selection,Feature extraction,Feature selection,Fitting,High-dimensional datasets,Machine learning,Measurement,Type-I fuzzy,Uncertainty},
  file = {/Users/tobias/Zotero/storage/PJGSFEIV/Joodaki et al. - 2022 - A novel ensemble feature selection method through .pdf;/Users/tobias/Zotero/storage/6Q4YCP9L/9756433.html}
}

@misc{JupyterNotebookViewer,
  title = {Jupyter {{Notebook Viewer}}},
  howpublished = {https://nbviewer.org/github/adhiraiyan/DeepLearningWithTF2.0/tree/master/notebooks/},
  keywords = {1,2,3,4,all deep learning book notebooks,chapters,ipynb},
  file = {/Users/tobias/Zotero/storage/Z9UEMU6F/notebooks.html}
}

@article{k.ReadersAffectPredicting2022,
  title = {Readers' Affect: Predicting and Understanding Readers' Emotions with Deep Learning},
  shorttitle = {Readers' Affect},
  author = {K., Anoop and P., Deepak and Sam Abraham, Savitha and V. L., Lajish and P. Gangan, Manjary},
  year = {2022},
  month = jun,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {82},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00614-2},
  abstract = {Emotions are highly useful to model human behavior being at the core of what makes us human. Today, people abundantly express and share emotions through social media. Technological advancements in such platforms enable sharing opinions or expressing any specific emotions towards what others have shared, mainly in the form of textual data. This entails an interesting arena for analysis; as to whether there is a disconnect between the writer's intended emotion and the reader's perception of textual content. In this paper, we present experiments for Readers' Emotion Detection through multi-target regression settings by exploring a Bi-LSTM-based Attention model, where our major intention is to analyze the interpretability and effectiveness of the deep learning model for the task. To conduct experiments, we procure two extensive datasets REN-10k and RENh-4k, apart from using a popular benchmark dataset from SemEval-2007. We perform a two-phase experimental evaluation, first being various coarse-grained and fine-grained evaluations of our model performance in comparison with several baselines belonging to different categories of emotion detection, viz., deep learning, lexicon based, and classical machine learning. Secondly, we evaluate model behavior towards readers' emotion detection assessing attention maps generated by the model through devising a novel set of qualitative and quantitative metrics. The first phase of experiments shows that our Bi-LSTM + Attention model significantly outperforms all baselines. The second analysis reveals that emotions may be correlated to specific words as well as named entities.},
  keywords = {Affective computing,Attention,Deep learning,Interpretability,Readers’ emotion detection,Textual emotion detection},
  file = {/Users/tobias/Zotero/storage/2CTKXBII/K. et al. - 2022 - Readers’ affect predicting and understanding read.pdf}
}

@incollection{kakasAbduction2017,
  title = {Abduction},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Kakas, Antonis C.},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {1--8},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_1},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@article{kannanMachineLearningApproach2022,
  title = {Machine Learning Approach for Predicting Production Delays: A Quarry Company Case Study},
  shorttitle = {Machine Learning Approach for Predicting Production Delays},
  author = {Kannan, Rathimala and Abdul Halim, Haq'ul Aqif and Ramakrishnan, Kannan and Ismail, Shahrinaz and Wijaya, Dedy Rahman},
  year = {2022},
  month = jul,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {94},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00644-w},
  abstract = {Predictive maintenance employing machine learning techniques and big data analytics is a benefit to the industrial business in the Industry 4.0 era. Companies, on the other hand, have difficulties as they move from reactive to predictive manufacturing processes. The purpose of this paper is to demonstrate how data analytics and machine learning approaches may be utilized to predict production delays in a quarry firm as a case study. The dataset contains production records for six months, with a total of 20 columns for each production record for two machines. Cross Industry Standard Process for Data Mining approach is followed to build the machine learning models. Five predictive models were created using machine learning algorithms such as Decision Tree, Neural Network, Random Forest, Nave Bayes and Logistic Regression. The results show that Multilayer Perceptron Neural Network and Logistic Regression outperform other techniques and accurately predicts production delays with a F-measure score of 0.973. The quarry company's improved decision-making reducing potential production line delays demonstrates the value of this study.},
  keywords = {Machine Learning,Prediction models,Production delay,Quarry Industry},
  file = {/Users/tobias/Zotero/storage/X3FRF2XK/Kannan et al. - 2022 - Machine learning approach for predicting productio.pdf}
}

@article{kernsIntroductionProbabilityStatistics,
  title = {Introduction to {{Probability}} and {{Statistics Using R}}},
  author = {Kerns, G Jay},
  pages = {438},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/HSVCEZDQ/Kerns - Introduction to Probability and Statistics Using R.pdf}
}

@article{khaleelIDCQuantitativeEvaluation2022,
  title = {{{IDC}}: Quantitative Evaluation Benchmark of Interpretation Methods for Deep Text Classification Models},
  shorttitle = {{{IDC}}},
  author = {Khaleel, Mohammed and Qi, Lei and Tavanapong, Wallapak and Wong, Johnny and Sukul, Adisak and Peterson, David A. M.},
  year = {2022},
  month = mar,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {34},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00583-6},
  abstract = {Recent advances in deep neural networks have achieved outstanding success in natural language processing tasks. Interpretation methods that provide insight into the decision-making process of these models have received an influx of research attention because of the success and the black-box nature of the deep text classification models. Evaluation of these methods has been based on changes in classification accuracy or prediction confidence when removing important words identified by these methods. There are no measurements of the actual difference between the predicted important words and humans' interpretation of ground truth because of the lack of interpretation ground truth. A large publicly available interpretation ground truth has the potential to advance the development of interpretation methods. Manual labeling important words for each document to create a large interpretation ground truth is very time-consuming. This paper presents (1) IDC, a new benchmark for quantitative evaluation of interpretation methods for deep text classification models, and (2) evaluation of six interpretation methods using the benchmark. The IDC benchmark consists of: (1) Three methods that generate three pseudo-interpretation ground truth datasets. (2) Three performance metrics: interpretation recall, interpretation precision, and Cohen's kappa inter-agreement. Findings: IDC-generated interpretation ground truth agrees with human annotators on sampled movie reviews. IDC identifies Layer-wise Relevance Propagation and the gradient-by-input methods as the winning interpretation methods in this study.},
  keywords = {Machine learning interpretation,Natural language processing,Pseudo interpretation ground truth},
  file = {/Users/tobias/Zotero/storage/QC25ZYBX/Khaleel et al. - 2022 - IDC quantitative evaluation benchmark of interpre.pdf;/Users/tobias/Zotero/storage/Q9YQIEBR/articles.html}
}

@article{khanPrivacyPreservedIncremental2022,
  title = {Privacy Preserved Incremental Record Linkage},
  author = {Khan, Shahidul Islam and Khan, Abir Bin Ayub and Hoque, Abu Sayed Md Latiful},
  year = {2022},
  month = nov,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {105},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00655-7},
  abstract = {Using an incremental approach to solve the record linkage problem is a relatively new research area. In incremental record linkage, every inserted record is compared with some existing clusters of records based on its blocking key value. Then, considering similarity, either the record will be put into an existing cluster, or a new cluster will be created for it. Although few papers have presented their solutions for incremental record linkage targeting the linkage quality or efficiency, privacy issue regarding the approach has not yet been discussed. Privacy is a major concern when record linkage is performed for sensitive data, e.g., health records, financial records, etc. In this regard, we have come up with a novel concept privacy-preserving incremental record linkage (PPiRL) which encapsulates privacy-preserving techniques with an incremental record linkage approach. In this chapter, we have proposed an end-to-end framework as our solution for PPiRL. For preserving privacy, we have used two types of privacy techniques namely phonetic encoding and generalization. We have used a recently developed phonetic algorithm ``nameGist'' to handle text-based features. For generalization, we have used the K-anonymization algorithm for numeric and categorical features. For handling incremental updates and internal linkage, we have used the Naive incremental clustering approach using Hierarchical Agglomerative clustering as the base clustering algorithm. We have performed various experiments to test the privacy and linkage quality of PPiRL. We have compared our work with the existing incremental record linkage framework and also with existing privacy-preserved record linkage techniques. It is apparent from our results that other than a small trade-off in linkage quality, our framework works better as a combined package of privacy and linkage solutions that any existing frameworks do not yet provide.},
  keywords = {Big data,Data matching,Incremental,Privacy,Record linkage},
  file = {/Users/tobias/Zotero/storage/X48QQM8S/Khan et al. - 2022 - Privacy preserved incremental record linkage.pdf}
}

@article{khosraviClassificationMastoidAir2022,
  title = {Classification of Mastoid Air Cells by {{CT}} Scan Images Using Deep Learning Method},
  author = {Khosravi, Mohammad and Jabbari Moghaddam, Yalda and Esmaeili, Mahdad and Keshtkar, Ahmad and Jalili, Javad and Tayefi Nasrabadi, Hamid},
  year = {2022},
  month = may,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {62},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00596-1},
  abstract = {Mastoid abnormalities show different types of ear illnesses, however inadequacy of experts and low accuracy of diagnostic demand a new approach to detect these abnormalities and reduce human mistakes. The manual analysis of mastoid CT scans is time-consuming and labor-intensive. In this paper the first and robust deep learning-based approaches is introduced to diagnose mastoid abnormalities using a large database of CT images obtained in the clinical center with remarkable accuracy.},
  keywords = {Convolutional neural network,CT scan,Deep learning,Ear disease,Mastoid pneumatization},
  file = {/Users/tobias/Zotero/storage/P98HDMIL/Khosravi et al. - 2022 - Classification of mastoid air cells by CT scan ima.pdf}
}

@misc{kingzAnswerHowWould2016,
  title = {Answer to "{{How}} Would You Explain Covariance to Someone Who Understands Only the Mean?"},
  shorttitle = {Answer to "{{How}} Would You Explain Covariance to Someone Who Understands Only the Mean?},
  author = {Kingz},
  year = {2016},
  month = jul,
  journal = {Cross Validated},
  file = {/Users/tobias/Zotero/storage/TSINM752/how-would-you-explain-covariance-to-someone-who-understands-only-the-mean.html}
}

@misc{kleinCompanionJupyterNotebooks2022,
  title = {Companion {{Jupyter}} Notebooks for the Book "{{Deep Learning}} with {{Python}}"},
  author = {Klein, Tobias},
  year = {2022},
  month = feb,
  abstract = {Jupyter notebooks for the code samples of the book "Deep Learning with Python"},
  copyright = {MIT},
  keywords = {\#nosource}
}

@misc{kleinKletobiasCs344code2020,
  title = {Kletobias/Cs344-Code},
  author = {Klein, Tobias},
  year = {2020},
  month = may,
  keywords = {\#nosource}
}

@misc{kleinPytudes2022,
  title = {Pytudes},
  author = {Klein, Tobias},
  year = {2022},
  month = feb,
  abstract = {Python programs, usually short, of considerable difficulty, to perfect particular skills.},
  copyright = {MIT},
  keywords = {\#nosource}
}

@article{koggalahewaUnsupervisedMethodSocial2022,
  title = {An Unsupervised Method for Social Network Spammer Detection Based on User Information Interests},
  author = {Koggalahewa, Darshika and Xu, Yue and Foo, Ernest},
  year = {2022},
  month = jan,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {7},
  issn = {2196-1115},
  doi = {10.1186/s40537-021-00552-5},
  abstract = {Online Social Networks (OSNs) are a popular platform for communication and collaboration. Spammers are highly active in OSNs. Uncovering spammers has become one of the most challenging problems in OSNs. Classification-based supervised approaches are the most commonly used method for detecting spammers. Classification-based systems suffer from limitations of ``data labelling'', ``spam drift'', ``imbalanced datasets'' and ``data fabrication''. These limitations effect the accuracy of a classifier's detection. An unsupervised approach does not require labelled datasets. We aim to address the limitation of data labelling and spam drifting through an unsupervised approach.We present a pure unsupervised approach for spammer detection based on the peer acceptance of a user in a social network to distinguish spammers from genuine users. The peer acceptance of a user to another user is calculated based on common shared interests over multiple shared topics between the two users. The main contribution of this paper is the introduction of a pure unsupervised spammer detection approach based on users' peer acceptance. Our approach does not require labelled training datasets. While it does not better the accuracy of supervised classification-based approaches, our approach has become a successful alternative for traditional classifiers for spam detection by achieving an accuracy of 96.9\%.},
  keywords = {Classification,Information interest,Peer acceptance,Spam detection,Unsupervised learning},
  file = {/Users/tobias/Zotero/storage/SD6HDVLC/Koggalahewa et al. - 2022 - An unsupervised method for social network spammer .pdf;/Users/tobias/Zotero/storage/IYX6H3ZX/articles.html}
}

@article{kolajoRealtimeEventDetection2022,
  title = {Real-Time Event Detection in Social Media Streams through Semantic Analysis of Noisy Terms},
  author = {Kolajo, Taiwo and Daramola, Olawande and Adebiyi, Ayodele A.},
  year = {2022},
  month = jul,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {90},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00642-y},
  abstract = {Interactions via social media platforms have made it possible for anyone, irrespective of physical location, to gain access to quick information on events taking place all over the globe. However, the semantic processing of social media data is complicated due to challenges such as language complexity, unstructured data, and ambiguity. In this paper, we proposed the Social Media Analysis Framework for Event Detection (SMAFED). SMAFED aims to facilitate improved semantic analysis of noisy terms in social media streams, improved representation/embedding of social media stream content, and improved summarization of event clusters in social media streams. For this, we employed key concepts such as integrated knowledge base, resolving ambiguity, semantic representation of social media streams, and Semantic Histogram-based Incremental Clustering based on semantic relatedness. Two evaluation experiments were conducted to validate the approach. First, we evaluated the impact of the data enrichment layer of SMAFED. We found that SMAFED outperformed other pre-processing frameworks with a lower loss function of 0.15 on the first dataset and 0.05 on the second dataset. Second, we determined the accuracy of SMAFED at detecting events from social media streams. The result of this second experiment showed that SMAFED outperformed existing event detection approaches with better Precision (0.922), Recall (0.793), and F-Measure (0.853) metric scores. The findings of the study present SMAFED as a more efficient approach to event detection in social media.},
  keywords = {Event detection,Event summarization,Semantic analysis,Social media stream,Word sense disambiguation},
  file = {/Users/tobias/Zotero/storage/AWUWHGVY/Kolajo et al. - 2022 - Real-time event detection in social media streams .pdf}
}

@article{kotiosDeepLearningEnhancing2022,
  title = {Deep Learning Enhancing Banking Services: A Hybrid Transaction Classification and Cash Flow Prediction Approach},
  shorttitle = {Deep Learning Enhancing Banking Services},
  author = {Kotios, Dimitrios and Makridis, Georgios and Fatouros, Georgios and Kyriazis, Dimosthenis},
  year = {2022},
  month = oct,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {100},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00651-x},
  abstract = {Small Medium Enterprises (SMEs) are vital to the global economy and all societies. However, they face a complex and challenging environment, as in most sectors they are lagging behind in their digital transformation. Banks, retaining a variety of data of their SME customers to perform their main activities, could offer a solution by leveraging all available data to provide a Business Financial Management (BFM) toolkit to their customers, providing value added services on top of their core business. In this direction, this paper revolves around the development of a smart, highly personalized hybrid transaction categorization model, interconnected with a cash flow prediction model based on Recurrent Neural Networks (RNNs). As the classification of transactions is of great significance, this research is extended towards explainable AI, where LIME and SHAP frameworks are utilized to interpret and illustrate the ML classification results. Our approach shows promising results on a real-world banking use case and acts as the foundation for the development of further BFM banking microservices, such as transaction fraud detection and budget monitoring.},
  keywords = {Cash flow prediction,Data analytics,Deep learning,Surrogate data,Time series forecasting,Transaction categorization},
  file = {/Users/tobias/Zotero/storage/4CQK44UU/Kotios et al. - 2022 - Deep learning enhancing banking services a hybrid.pdf}
}

@article{koupilUnifiedRepresentationTransformation2022,
  title = {A Unified Representation and Transformation of Multi-Model Data Using Category Theory},
  author = {Koupil, Pavel and Holubov{\'a}, Irena},
  year = {2022},
  month = may,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {61},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00613-3},
  abstract = {The support for multi-model data has become a standard for most of the existing DBMSs. However, the step from a conceptual (e.g., ER or UML) schema to a logical multi-model schema of a particular DBMS is not straightforward. In this paper, we extend our previous proposal of multi-model data representation using category theory for transformations between models. We introduce a mapping between multi-model data and the categorical representation and algorithms for mutual transformations between them. We also show how the algorithms can be implemented using the idea of wrappers with the interface published but specific internal details concealed. Finally, we discuss the applicability of the approach to various data management tasks, such as conceptual querying.},
  keywords = {Category theory,Model transformations,Multi-model data},
  file = {/Users/tobias/Zotero/storage/KKC2PRFF/Koupil and Holubová - 2022 - A unified representation and transformation of mul.pdf}
}

@article{koupilUniversalApproachMultimodel2022,
  title = {A Universal Approach for Multi-Model Schema Inference},
  author = {Koupil, Pavel and Hricko, Sebasti{\'a}n and Holubov{\'a}, Irena},
  year = {2022},
  month = aug,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {97},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00645-9},
  abstract = {The variety feature of Big Data, represented by multi-model data, has brought a new dimension of complexity to all aspects of data management. The need to process a set of distinct but interlinked data models is a challenging task. In this paper, we focus on the problem of inference of a schema, i.e., the description of the structure of data. While several verified approaches exist in the single-model world, their application for multi-model data is not straightforward. We introduce an approach that ensures inference of a common schema of multi-model data capturing their specifics. It can infer local integrity constraints as well as intra- and inter-model references. Following the standard features of Big Data, it can cope with overlapping models, i.e., data redundancy, and it is designed to process efficiently significant amounts of data.To the best of our knowledge, ours is the first approach addressing schema inference in the world of multi-model databases.},
  keywords = {Cross-model references,Data redundancy,Multi-model data,Schema inference},
  file = {/Users/tobias/Zotero/storage/WVYMJ3P7/Koupil et al. - 2022 - A universal approach for multi-model schema infere.pdf}
}

@book{kuhnAppliedPredictiveModeling2013,
  title = {Applied {{Predictive Modeling}}},
  author = {Kuhn, Max and Johnson, Kjell},
  year = {2013},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4614-6849-3},
  isbn = {978-1-4614-6848-6 978-1-4614-6849-3},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/3MDSBPDW/Kuhn and Johnson - 2013 - Applied Predictive Modeling.pdf}
}

@article{kumariDetectingDenialService2022,
  title = {Detecting {{Denial}} of {{Service}} Attacks Using Machine Learning Algorithms},
  author = {Kumari, Kimmi and Mrunalini, M.},
  year = {2022},
  month = apr,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {56},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00616-0},
  abstract = {Currently, Distributed Denial of Service Attacks are the most dangerous cyber danger. By inhibiting the server's ability to provide resources to genuine customers, the affected server's resources, such as bandwidth and buffer size, are slowed down. A mathematical model for distributed denial-of-service attacks is proposed in this study. Machine learning algorithms such as Logistic Regression and Naive Bayes, are used to detect attacks and normal scenarios. The CAIDA 2007 Dataset is used for experimental study. The machine learning algorithms are trained and tested using this dataset and the trained algorithms are validated. Weka data mining platform are used in this study for implementation and results of the same are analysed and compared. Other machine learning algorithms used with respect to denial of service attacks are compared with the existing work.},
  keywords = {DDOS attacks,Machine learning for security,Mathematical model for Bandwidth Depletion,Throughput analysis of attack and normal scenario},
  file = {/Users/tobias/Zotero/storage/RZV39VKM/Kumari and Mrunalini - 2022 - Detecting Denial of Service attacks using machine .pdf;/Users/tobias/Zotero/storage/IWNJVXPT/articles.html}
}

@article{kyeongTwostageCreditScoring2022,
  title = {Two-Stage Credit Scoring Using {{Bayesian}} Approach},
  author = {Kyeong, Sunghyon and Shin, Jinho},
  year = {2022},
  month = nov,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {106},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00665-5},
  abstract = {Commercial banks are required to explain the credit evaluation results to their customers. Therefore, banks attempt to improve the performance of their credit scoring models while ensuring the interpretability of the results. However, there is a tradeoff between the logistic regression model and machine learning-based techniques regarding interpretability and model performance because machine learning-based models are a black box. To deal with the tradeoff, in this study, we present a two-stage logistic regression method based on the Bayesian approach. In the first stage, we generate the derivative variables by linearly combining the original features with their explanatory powers based on the Bayesian inference. The second stage involves developing a credit scoring model through logistic regression using these derivative variables. Through this process, the explanatory power of a large number of original features can be utilized for default prediction, and the use of logistic regression maintains the model's interpretability. In the empirical analysis, the independent sample t-test reveals that our proposed approach significantly improves the model's performance compared to that based on the conventional single-stage approach, i.e., the baseline model. The Kolmogorov\textendash Smirnov statistics show a 3.42 percentage points (\%p) increase, and the area under the receiver operating characteristic shows a 2.61\%p increase. Given that our two-stage modeling approach has the advantages of interpretability and enhanced performance of the credit scoring model, our proposed method is essential for those in charge of banking who must explain credit evaluation results and find ways to improve the performance of credit scoring models.},
  keywords = {Bayesian approach,Credit scoring model,Machine learning,Two-stage logistic regression},
  file = {/Users/tobias/Zotero/storage/AL2AJFSH/Kyeong and Shin - 2022 - Two-stage credit scoring using Bayesian approach.pdf}
}

@article{lawiImplementationLongShortTerm2022,
  title = {Implementation of {{Long Short-Term Memory}} and {{Gated Recurrent Units}} on Grouped Time-Series Data to Predict Stock Prices Accurately},
  author = {Lawi, Armin and Mesra, Hendra and Amir, Supri},
  year = {2022},
  month = jul,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {89},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00597-0},
  abstract = {Stocks are an attractive investment option because they can generate large profits compared to other businesses. The movement of stock price patterns in the capital market is very dynamic. Therefore, accurate data modeling is needed to forecast stock prices with a low error rate. Forecasting models using Deep Learning are believed to be able to predict stock price movements accurately with time-series data input, especially the Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) algorithms. Unfortunately, several previous studies and investigations of LSTM/GRU implementation have not yielded convincing performance results. This paper proposes eight new architectural models for stock price forecasting by identifying joint movement patterns in the stock market. The technique is to combine the LSTM and GRU models with four neural network block architectures. Then, the proposed architectural model is evaluated using three accuracy measures obtained from the loss function Mean Absolute Percentage Error (MAPE), Root Mean Squared Percentage Error (RMSPE), and Rooted Mean Dimensional Percentage Error (RMDPE). The three accuracies, MAPE, RMSPE, and RMDPE, represent lower accuracy, true accuracy, and higher accuracy in using the model.},
  keywords = {Deep Learning,Forecasting accuracy,Forecasting methods,Gated Recurrent Unit,Long-Short Term Memory,Recurrent Neural Network,Stock price,Time-series forecasting},
  file = {/Users/tobias/Zotero/storage/STAFNPTZ/Lawi et al. - 2022 - Implementation of Long Short-Term Memory and Gated.pdf}
}

@article{leeDevelopingInsightsCollective2022,
  title = {Developing Insights from the Collective Voice of Target Users in {{Twitter}}},
  author = {Lee, Kang-Pyo and Song, Suyong},
  year = {2022},
  month = jun,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {75},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00611-5},
  abstract = {This study develops a pragmatic scheme that facilitates insight development from the collective voice of target users in Twitter, which has not been considered in the existing literature. While relying on a wide range of existing approaches to Twitter user profiling, this study provides a novel and generic procedure that enables researchers to identify the right users in Twitter and discover topical and social insights from their tweets. To identify a target audience of Twitter users that meets certain criteria, we first explore user profiling, potentially followed by text-based, customized user profiling leveraging hashtags as features for machine learning. We then present how to mine popular topics and influential actors from Twitter data. Two case studies on 16 thousand young women interested in fashion and 68 thousand people sharing the same interest in the Me Too movement indicate that our approach facilitates discovery of social trends among people in a particular domain.},
  keywords = {Big Data,Social trends,Text analysis,Twitter,User profiling},
  file = {/Users/tobias/Zotero/storage/MQTZ5PLK/Lee and Song - 2022 - Developing insights from the collective voice of t.pdf}
}

@article{leskovecMiningMassiveDatasets,
  title = {Mining of {{Massive Datasets}}},
  author = {Leskovec, Jure and Rajaraman, Anand and Ullman, Jeffrey D},
  pages = {603},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/WPGXPTZV/Leskovec et al. - Mining of Massive Datasets.pdf}
}

@book{liArtificialIntelligenceHuman2021,
  title = {Artificial {{Intelligence}} for {{Human Computer Interaction}}: {{A Modern Approach}}},
  shorttitle = {Artificial {{Intelligence}} for {{Human Computer Interaction}}},
  editor = {Li, Yang and Hilliges, Otmar},
  year = {2021},
  series = {Human\textendash{{Computer Interaction Series}}},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-82681-9},
  isbn = {978-3-030-82680-2 978-3-030-82681-9},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/4XS49DQ8/Li and Hilliges - 2021 - Artificial Intelligence for Human Computer Interac.pdf}
}

@article{liEfficientAnnealingassistedDifferential2022,
  title = {An Efficient Annealing-Assisted Differential Evolution for Multi-Parameter Adaptive Latent Factor Analysis},
  author = {Li, Qing and Pang, Guansong and Shang, Mingsheng},
  year = {2022},
  month = jul,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {95},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00638-8},
  abstract = {A high-dimensional and incomplete (HDI) matrix is a typical representation of big data. However, advanced HDI data analysis models tend to have many extra parameters. Manual tuning of these parameters, generally adopting the empirical knowledge, unavoidably leads to additional overhead. Although variable adaptive mechanisms have been proposed, they cannot balance the exploration and exploitation with early convergence. Moreover, learning such multi-parameters brings high computational time, thereby suffering gross accuracy especially when solving a bilinear problem like conducting the commonly used latent factor analysis (LFA) on an HDI matrix. Herein, an efficient annealing-assisted differential evolution for multi-parameter adaptive latent factor analysis (ADMA) is proposed to address these problems. First, a periodic equilibrium mechanism is employed using the physical mechanism annealing, which is embedded in the mutation operation of differential evolution (DE). Then, to further improve its efficiency, we adopt a probabilistic evaluation mechanism consistent with the crossover probability of DE. Experimental results of both adaptive and non-adaptive state-of-the-art methods on industrial HDI datasets illustrate that ADMA achieves a desirable global optimum with reasonable overhead and prevails competing methods in terms of predicting the missing data in HDI matrices.},
  keywords = {Big data analysis,Differential evolution algorithm,Latent factor analysis,Multi-parameter adaptive,Simulated annealing},
  file = {/Users/tobias/Zotero/storage/5UWNZ8LS/Li et al. - 2022 - An efficient annealing-assisted differential evolu.pdf}
}

@article{liScalableAssociationRule2022,
  title = {A Scalable Association Rule Learning and Recommendation Algorithm for Large-Scale Microarray Datasets},
  author = {Li, Haosong and Sheu, Phillip C.-Y.},
  year = {2022},
  month = mar,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {35},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00577-4},
  abstract = {Association rule learning algorithms have been applied to microarray datasets to find association rules among genes. With the development of microarray technology, larger datasets have been generated recently that challenge the current association rule learning algorithms. Specifically, the large number of items per transaction significantly increases the running time and memory consumption of such tasks. In this paper, we propose the Scalable Association Rule Learning (SARL) heuristic that efficiently learns gene-disease association rules and gene\textendash gene association rules from large-scale microarray datasets. The rules are ranked based on their importance. Our experiments show the SARL algorithm outperforms the Apriori algorithm by one to three orders of magnitude.},
  keywords = {Apriori algorithm,Association rule learning,Frequent itemset mining,Graph partitioning,Microarray dataset,Scalability},
  file = {/Users/tobias/Zotero/storage/KVA94FRN/Li and Sheu - 2022 - A scalable association rule learning and recommend.pdf;/Users/tobias/Zotero/storage/QUMFV4GE/articles.html}
}

@article{liuTitle2VecContextualJob2022,
  title = {{{Title2Vec}}: A Contextual Job Title Embedding for Occupational Named Entity Recognition and Other Applications},
  shorttitle = {{{Title2Vec}}},
  author = {Liu, Junhua and Ng, Yung Chuen and Gui, Zitong and Singhal, Trisha and Blessing, Lucienne T. M. and Wood, Kristin L. and Lim, Kwan Hui},
  year = {2022},
  month = sep,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {99},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00649-5},
  abstract = {Occupational data mining and analysis is an important task in understanding today's industry and job market. Various machine learning techniques are proposed and gradually deployed to improve companies' operations for upstream tasks, such as employee churn prediction, career trajectory modelling and automated interview. Job titles analysis and embedding, as the fundamental building blocks, are crucial upstream tasks to address these occupational data mining and analysis problems. A relevant occupational job title dataset is required to accomplish these tasks and towards that effort, we present the Industrial and Professional Occupations Dataset (IPOD). The IPOD dataset contains over 475,073 job titles based on 192,295 user profiles from a major professional networking site. To further facilitate these applications of occupational data mining and analysis, we propose Title2vec, a contextual job title vector representation using a bidirectional Language Model approach. To demonstrate the effectiveness of Title2vec, we also define an occupational Named Entity Recognition (NER) task and proposed two methods based on Conditional Random Fields (CRF) and bidirectional Long Short-Term Memory with CRF (LSTM-CRF). Using a large occupational job title dataset, experimental results show that both CRF and LSTM-CRF outperform human and baselines in both exact-match accuracy and F1 scores. The dataset and pre-trained embeddings have been made publicly available at https://www.github.com/junhua/ipod.},
  keywords = {Named entity recognition,Occupational mining,Social computing,Social networks,Word embedding},
  file = {/Users/tobias/Zotero/storage/HIPN2L4W/Liu et al. - 2022 - Title2Vec a contextual job title embedding for oc.pdf}
}

@misc{LongShortTerm,
  title = {Long\_short\_term\_memory\_networks\_with\_python.Pdf},
  file = {/Users/tobias/Zotero/storage/TPC42BSU/long_short_term_memory_networks_with_python.pdf}
}

@article{lopez-rodriguezModelingScientometricIndicators2022,
  title = {Modeling Scientometric Indicators Using a Statistical Data Ontology},
  author = {{Lopez-Rodriguez}, Victor and Ceballos, Hector G.},
  year = {2022},
  month = jan,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {9},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00562-x},
  abstract = {Scientometrics is the field of study and evaluation of scientific measures such as the impact of research papers and academic journals. It is an important field because nowadays different rankings use key indicators for university rankings and universities themselves use them as Key Performance Indicators (KPI). The purpose of this work is to propose a semantic modeling of scientometric indicators using the ontology Statistical Data and Metadata Exchange (SDMX). We develop a case study at Tecnologico de Monterrey following the Cross-Industry Standard Process for Data Mining (CRISP-DM) methodology. We evaluate the benefits of storing and querying scientometric indicators using linked data as a mean for providing flexible and quick access knowledge representation that supports indicator discovery, enquiring and composition. The semi-automatic generation and further storage of this linked data in the Neo4j graph database enabled an updatable and quick access model.},
  keywords = {CRISP-DM,Graph database,Neo4j,Ontology generation,Query evaluation},
  file = {/Users/tobias/Zotero/storage/VIPL3GDK/Lopez-Rodriguez and Ceballos - 2022 - Modeling scientometric indicators using a statisti.pdf;/Users/tobias/Zotero/storage/5L8FZIZP/articles.html}
}

@misc{loshchilovSGDRStochasticGradient2017,
  title = {{{SGDR}}: {{Stochastic Gradient Descent}} with {{Warm Restarts}}},
  shorttitle = {{{SGDR}}},
  author = {Loshchilov, Ilya and Hutter, Frank},
  year = {2017},
  month = may,
  number = {arXiv:1608.03983},
  eprint = {1608.03983},
  eprinttype = {arxiv},
  primaryclass = {cs, math},
  publisher = {{arXiv}},
  abstract = {Restart techniques are common in gradient-free optimization to deal with multimodal functions. Partial warm restarts are also gaining popularity in gradient-based optimization to improve the rate of convergence in accelerated gradient schemes to deal with ill-conditioned functions. In this paper, we propose a simple warm restart technique for stochastic gradient descent to improve its anytime performance when training deep neural networks. We empirically study its performance on the CIFAR-10 and CIFAR-100 datasets, where we demonstrate new state-of-the-art results at 3.14\% and 16.21\%, respectively. We also demonstrate its advantages on a dataset of EEG recordings and on a downsampled version of the ImageNet dataset. Our source code is available at https://github.com/loshchil/SGDR},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,cosinus annealing,learning rate,Mathematics - Optimization and Control,paper,SGD,stochastik gradient descent,warm restart},
  file = {/Users/tobias/Zotero/storage/U34HQF2X/Loshchilov and Hutter - 2017 - SGDR Stochastic Gradient Descent with Warm Restar.pdf}
}

@article{luPracticalAlzheimerDisease2022,
  title = {A Practical {{Alzheimer}}'s Disease Classifier via Brain Imaging-Based Deep Learning on 85,721 Samples},
  author = {Lu, Bin and Li, Hui-Xian and Chang, Zhi-Kai and Li, Le and Chen, Ning-Xuan and Zhu, Zhi-Chen and Zhou, Hui-Xia and Li, Xue-Ying and Wang, Yu-Wei and Cui, Shi-Xian and Deng, Zhao-Yu and Fan, Zhen and Yang, Hong and Chen, Xiao and Thompson, Paul M. and Castellanos, Francisco Xavier and Yan, Chao-Gan},
  year = {2022},
  month = oct,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {101},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00650-y},
  abstract = {Beyond detecting brain lesions or tumors, comparatively little success has been attained in identifying brain disorders such as Alzheimer's disease (AD), based on magnetic resonance imaging (MRI). Many machine learning algorithms to detect AD have been trained using limited training data, meaning they often generalize poorly when applied to scans from previously unseen scanners/populations. Therefore, we built a practical brain MRI-based AD diagnostic classifier using deep learning/transfer learning on a dataset of unprecedented size and diversity. A retrospective MRI dataset pooled from more than 217 sites/scanners constituted one of the largest brain MRI samples to date (85,721 scans from 50,876 participants) between January 2017 and August 2021. Next, a state-of-the-art deep convolutional neural network, Inception-ResNet-V2, was built as a sex classifier with high generalization capability. The sex classifier achieved 94.9\% accuracy and served as a base model in transfer learning for the objective diagnosis of AD. After transfer learning, the model fine-tuned for AD classification achieved 90.9\% accuracy in leave-sites-out cross-validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI, 6,857 samples) dataset and 94.5\%/93.6\%/91.1\% accuracy for direct tests on three unseen independent datasets (AIBL, 669 samples / MIRIAD, 644 samples / OASIS, 1,123 samples). When this AD classifier was tested on brain images from unseen mild cognitive impairment (MCI) patients, MCI patients who converted to AD were 3 times more likely to be predicted as AD than MCI patients who did not convert (65.2\% vs. 20.6\%). Predicted scores from the AD classifier showed significant correlations with illness severity. In sum, the proposed AD classifier offers a medical-grade marker that has potential to be integrated into AD diagnostic practice.},
  keywords = {Alzheimer’s disease,Convolutional neural network,Magnetic resonance brain imaging,Sex differences,Transfer learning},
  file = {/Users/tobias/Zotero/storage/MEE6YFVP/Lu et al. - 2022 - A practical Alzheimer’s disease classifier via bra.pdf}
}

@misc{MachineLearning,
  title = {Machine {{Learning}}},
  journal = {Coursera},
  abstract = {Learn Machine Learning from Stanford University. Machine learning is the science of getting computers to act without being explicitly programmed. In the past decade, machine learning has given us self-driving cars, practical speech recognition, ...},
  howpublished = {https://www.coursera.org/learn/machine-learning},
  langid = {english},
  keywords = {5million enrolled,coursea course,machine learning,paid},
  file = {/Users/tobias/Zotero/storage/J3EDHJ62/machine-learning.html}
}

@misc{MachineLearningAlgorithms,
  title = {Machine\_learning\_algorithms\_from\_scratch.Pdf},
  file = {/Users/tobias/Zotero/storage/LWB6XNKC/machine_learning_algorithms_from_scratch.pdf}
}

@misc{MachineLearningMastery,
  title = {Machine\_learning\_mastery\_with\_weka.Pdf},
  file = {/Users/tobias/Zotero/storage/5NVZTJ95/machine_learning_mastery_with_weka.pdf}
}

@misc{MachineLearningMasterya,
  title = {Machine\_learning\_mastery\_with\_python.Pdf},
  file = {/Users/tobias/Zotero/storage/S2LEMAEW/machine_learning_mastery_with_python.pdf}
}

@misc{MachineLearningMasteryb,
  title = {Machine\_learning\_mastery\_with\_r.Pdf},
  file = {/Users/tobias/Zotero/storage/XX5FWAEZ/machine_learning_mastery_with_r.pdf}
}

@book{MachineLearningOptimization,
  title = {Machine {{Learning}}, {{Optimization}}, and {{Data Science}}},
  abstract = {The post conference proceeding LOD 2021 presents papers on topics such as artificial intelligence, reinforcement learning, and much more.},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/H2BLBUXT/978-3-030-95467-3.html}
}

@book{MachineLearningOptimizationa,
  title = {Machine {{Learning}}, {{Optimization}}, and {{Big Data}}},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/4CNTGRST/978-3-319-51469-7.html}
}

@article{maduakoDeepLearningComponent2022,
  title = {Deep Learning for Component Fault Detection in Electricity Transmission Lines},
  author = {Maduako, Iyke and Igwe, Chukwuemeka Fortune and Abah, James Edebo and Onwuasaanya, Obianuju Esther and Chukwu, Grace Amarachi and Ezeji, Franklin and Okeke, Francis Ifeanyi},
  year = {2022},
  month = jun,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {81},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00630-2},
  abstract = {Component fault detection and inventory are one of the most significant bottlenecks facing the electricity transmission and distribution utility establishments especially in developing countries for delivery of efficient services to the customers and to ensure proper asset audit and management for network optimization and load forecasting. For lack of technology and data, insecurity, the complexity associated with traditional methods, untimeliness, and general human cost, electricity assets monitoring, and management have remained a big problem in many developing countries. In view of this, we explored the use of oblique UAV imagery with high spatial resolution and fine-tuned deep Convolutional Neural Networks (CNNs) for automatic faulty component inspection and inventory in an Electric power transmission network (EPTN). This study investigated the capability of the Single Shot Multibox Detector (SSD), a one-stage object detection model on the electric transmission power line imagery to localize, detect and classify faults. Our proposed neural network model is a CNN based on a multiscale layer feature pyramid network (FPN) using aerial image patches and ground truth to localise and detect faults through a one-phase procedure. The SSD Rest50 architecture variation performed the best with a mean Average Precision (mAP) of 89.61\%. All the developed SSD-based models achieve a high precision rate and low recall rate in detecting faulty components, thus achieving acceptable balance levels of F1-score and representation. We have established in this paper that combined use of UAV imagery and computer vision presents a low-cost method for easy and timely electricity asset inventory, especially in developing countries. This study also provides the guide to various considerations when adopting this technology in terms of the choice of deep learning architecture, adequate training samples over multiple fault characteristics, effects of data augmentation, and balancing of intra-class heterogeneity.},
  keywords = {Deep learning,Power-line fault detection,Single Shot Multibox Detector,UAV imagery},
  file = {/Users/tobias/Zotero/storage/SZ38939Y/Maduako et al. - 2022 - Deep learning for component fault detection in ele.pdf}
}

@phdthesis{mastakouriCausalFeatureSelection2020,
  title = {Causal {{Feature Selection}} in {{Neuroscience}}},
  author = {Mastakouri, Anastasia Atalanti},
  year = {2020},
  month = dec,
  doi = {10.15496/publikation-52164},
  abstract = {Causal inference, at times correct and at times false, is fundamentally intertwined with the human nature. Humans tend to approach and explain the systems in the world and every day life via causal reasoning and causal statements, by unconsciously trying to recover the causal graph that underlies their observations. Nevertheless, causal reasoning based on observations of the real world is seldom equitable and precise. Particularly when the method that one uses is based on plain correlations, causal statements can be far from causal, first, because of the implicit assumption about linear relationships, and second, due to the major problem of hidden confounding.    One of the most complex and difficult systems for an applied scientist to explain is the human brain. The reason for that is threefold. First and foremost, because of the daedal and sophisticated manner that the human brain is constructed. Secondly, because of our limited means of observing its global functionality, which ultimately leads to the problem that no causal sufficiency can be assumed in such a system. In other words, hidden common causes (also termed hidden confounders) in our limited observations will be omnipresent. Finally, the significant heterogeneity that the human brain exhibits in some of its physiological functionalities, across subjects, hinders the problem even further. This, subsequently, justifies the lack of generalization of machine learning methods that try to predict biomarkers through the traditional approach of a non-causal model, across different brains.  Hence, someone should be particularly careful with the methods that she or he selects to use and the causal statements that are made, to understand and interpret the brain functionality.    In this thesis, we focus on constructing theorems and algorithms for causal inference on real data, trying to understand the relationship between the human brain and motor function. More specifically, we target the problem of the identification of causes of a target variable, without assuming causal sufficiency. We tackle both the cases of non-sequential and of time series data, proving theorems for both cases accordingly. Our methods' applications have an immediate focus on the activity of the human motor cortex at the time it arises, first, naturally, and second, from non-invasive brain stimulation. We build experimental set-ups and conduct electroencephalographic (EEG) and stimulation experiments to study the functionality of the motor cortex across different subjects, during these two different cases, with an ultimate goal to explain the observed heterogeneity in the recorded activity.     The work presented in this thesis is both experimental --in its first part-- with non invasive experiments on the human brain, contributing to the better understanding of the motor cortex, and theoretical, with contributions of four theorems in the field of causal inference, and two causal feature selection methods.     We first attempt to approach the brain activity from a purely machine learning perspective, analysing the data of the brain activity of 27 healthy subjects during an upper-limb reaching task. We introduce a multi-task regression method to build personalised models that predict movement stability from limited trials. We do so by taking into account information from other subjects as prior and updating -when necessary- the weights of the model with trials from the current subject. Although the original goal of this work was to show the superiority of this prediction method, a side-observation turned out to be the most fundamental key to define the next steps of the hereby presented research. The learnt features by the individual prediction models differed significantly across subjects, and although no causal claim can be made yet -since this is a correlation-based observation- it is the first hint of existing heterogeneity in the activity of the human motor cortex. Such a discrepancy, in frequency and location in the learnt features, could also imply a discrepancy in the response to non-invasive brain stimulation techniques, over the motor cortex.    To examine this possibility, a new series of electrophysiological experiments, with application of transcranial alternating current stimulation at 70 Hz over the motor cortex --as this has been considered to facilitate movement-- , is conducted on twenty healthy participants.  At this point, having observed a significant variability in the behavioural response, ranging from negative to positive responders, we decided to further investigate the reasons that could explain it. An incremental method with three steps is introduced to narrow down the causal model that can explain the aforementioned discrepancy in responses. With our method, we conclude that the beta oscillatory activity over the motor cortex could play a mediating role between the gamma stimulation and the motor performance, without being able to exclude the case that GABA activity could be a hidden common cause.    Having witnessed such a heterogeneity, both during natural movements and under brain stimulation, we stress the importance of taking steps towards personalisation of brain stimulation parameters. We conclude the experimental part of this work by constructing a pipeline, to predict from \textbackslash textit\{resting state\} EEG data the behavioural response of each subject to the stimulation treatment. Such a screening could avoid redundant or even harmful stimulation sessions. With two different stimulation studies, recruiting in total 42 healthy participants, we identify a biomarker that could be informative about the response of an individual to the aforementioned motor stimulation.    In the theoretical part of this thesis, we focus on the problem of the identification of direct and indirect causes of a target (e.g. motor performance) given a collection of possible candidates (e.g. brain activity in different locations, in different frequencies), allowing at the same time for latent common causes. First, we propose and prove a theorem which introduces sufficient conditions, under assumptions that can naturally be met, to decide for the causal role of a feature, with a single \textbackslash textit\{conditional independence\} test, and a single conditioning variable. Given the hardness of statistical testing of conditional independences in large and dense graphs (such as the brain), limiting the necessary tests to one, significantly boosts the statistical strength of the results.   Application of our conditions on the aforementioned neurophysiological data supports further the validity of the method. Applying the proposed conditions independently on each individual, without prior knowledge, led to three groups of identified causal features, each one being related in a consistent manner with different quality of movements across subjects. We discuss how such a method could contribute in the selection of personalised brain stimulation parameters.    As a final step, we approach the brain signal as continuous time series data. Although time series are observed almost everywhere in nature, yet, causal inference on such data, in the presence of hidden confounders, has been an unsolved problem, with the widely known Granger Causality being the only approach for almost half a century. The final contribution of this thesis, are two theorems with which we introduce both necessary and sufficient conditions for the causal feature selection on time series, under some graph constraints, and a third theorem that relaxes one of the stricter assumptions of the aforementioned two. We demonstrate the validity of our method both on simulated and real data.},
  copyright = {http://tobias-lib.uni-tuebingen.de/doku/lic\_mit\_pod.php?la=de},
  isbn = {9781743258620},
  langid = {english},
  school = {Universit\"at T\"ubingen},
  keywords = {feature selection,neuroscience},
  annotation = {Accepted: 2020-12-18T08:27:56Z},
  file = {/Users/tobias/Zotero/storage/5U6AGG42/Mastakouri - 2020 - Causal Feature Selection in Neuroscience.pdf;/Users/tobias/Zotero/storage/FMTY39DB/110788.html}
}

@misc{MasterMachineLearning,
  title = {Master\_machine\_learning\_algorithms.Pdf},
  file = {/Users/tobias/Zotero/storage/3F66VCRT/master_machine_learning_algorithms.pdf}
}

@article{menzeComparisonRandomForest2009,
  title = {A Comparison of Random Forest and Its {{Gini}} Importance with Standard Chemometric Methods for the Feature Selection and Classification of Spectral Data},
  author = {Menze, Bjoern H. and Kelm, B. Michael and Masuch, Ralf and Himmelreich, Uwe and Bachert, Peter and Petrich, Wolfgang and Hamprecht, Fred A.},
  year = {2009},
  month = jul,
  journal = {BMC Bioinformatics},
  volume = {10},
  number = {1},
  pages = {213},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-10-213},
  abstract = {Regularized regression methods such as principal component or partial least squares regression perform well in learning tasks on high dimensional spectral data, but cannot explicitly eliminate irrelevant features. The random forest classifier with its associated Gini feature importance, on the other hand, allows for an explicit feature elimination, but may not be optimally adapted to spectral data due to the topology of its constituent classification trees which are based on orthogonal splits in feature space.},
  keywords = {Bovine Spongiform Encephalopathy,Feature Selection,Feature Selection Method,Partial Little Square,Random Forest},
  file = {/Users/tobias/Zotero/storage/RM7KMVC2/Menze et al. - 2009 - A comparison of random forest and its Gini importa.pdf;/Users/tobias/Zotero/storage/2T9U7R3L/1471-2105-10-213.html}
}

@book{michaelisSolvingLargeScale2016,
  title = {Solving {{Large Scale Learning Tasks}}. {{Challenges}} and {{Algorithms}}},
  editor = {Michaelis, Stefan and Piatkowski, Nico and Stolpe, Marco},
  year = {2016},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {9580},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-41706-6},
  isbn = {978-3-319-41705-9 978-3-319-41706-6},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/8IVZG6RL/Michaelis et al. - 2016 - Solving Large Scale Learning Tasks. Challenges and.pdf}
}

@book{michelucciAppliedDeepLearning2022,
  title = {Applied {{Deep Learning}} with {{TensorFlow}} 2: {{Learn}} to {{Implement Advanced Deep Learning Techniques}} with {{Python}}},
  shorttitle = {Applied {{Deep Learning}} with {{TensorFlow}} 2},
  author = {Michelucci, Umberto},
  year = {2022},
  publisher = {{Apress}},
  address = {{Berkeley, CA}},
  doi = {10.1007/978-1-4842-8020-1},
  isbn = {978-1-4842-8019-5 978-1-4842-8020-1},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/9S9MX8BN/Michelucci - 2022 - Applied Deep Learning with TensorFlow 2 Learn to .pdf}
}

@article{mizunoMachineLearningbasedTurbulencerisk2022,
  title = {Machine Learning-Based Turbulence-Risk Prediction Method for the Safe Operation of Aircrafts},
  author = {Mizuno, Shinya and Ohba, Haruka and Ito, Koji},
  year = {2022},
  month = mar,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {29},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00584-5},
  abstract = {This study has proposed a method for detecting turbulence, a primary factor that influences safe aircraft operation. The number of observed turbulence events is limited, thereby indicating the requirement of an appropriate flow for detecting turbulence events from a small number of samples. In addition, the opinions and experiences of pilots must be reflected at the initial stage to address the high risk of turbulence occurrence, which can result in airline operations being cancelled. Thus, this study proposed a method for predicting turbulence occurrence based on the turbulence occurrence date information provided by airlines as well as meteorological data sets obtained from open data available in Japan as teacher data. However, because commonly used machine learning methods are unable to detect the turbulence occurrence date, the proposed method employed principal component analysis coupled with the K-Means method to generate risk clusters with a high likelihood of turbulence occurrence and consequently perform statistical checks. Subsequently, the risk clusters were utilized as supervisory data for turbulence occurrence, while the support vector machine was used for predicting turbulence occurrence. Furthermore, the results obtained with the proposed method were statistically checked as well as practically verified by a pilot to confirm the appropriateness of the turbulence occurrence date predicted.},
  keywords = {k-means,Meteorological data,Mountain waves,Open data,PCA,Risk cluster,SVC},
  file = {/Users/tobias/Zotero/storage/5SIN8WG3/Mizuno et al. - 2022 - Machine learning-based turbulence-risk prediction .pdf;/Users/tobias/Zotero/storage/FW52EAPP/articles.html}
}

@article{mosharrafImprovingLookupQuery2022,
  title = {Improving Lookup and Query Execution Performance in Distributed {{Big Data}} Systems Using {{Cuckoo Filter}}},
  author = {Mosharraf, Sharafat Ibn Mollah and Adnan, Muhammad Abdullah},
  year = {2022},
  month = jan,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {12},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00563-w},
  abstract = {Performance is a critical concern when reading and writing data from billions of records stored in a Big Data warehouse. We introduce two scopes for query performance improvement. One is to improve the performance of lookup queries after data deletion in Big Data systems that use Eventual Consistency. We propose a scheme to improve lookup performance after data deletion by using Cuckoo Filter. Another scope for improvement is to avoid unnecessary network round-trips for querying in remote nodes in a distributed Big Data cluster when it is known that the nodes do not have requested partition of data. We propose a scheme using probabilistic filters that are looked up before querying remote nodes so that queries resulting in no data can be skipped from passing through the network. We evaluate our schemes with Cassandra using real dataset and show that each scheme can improve performance of lookup queries for up to 2x.},
  keywords = {Big Data,Bloom filter,Cuckoo Filter,Distributed systems,Probabilistic data structure,Query optimization},
  file = {/Users/tobias/Zotero/storage/R5S92QAI/Mosharraf and Adnan - 2022 - Improving lookup and query execution performance i.pdf;/Users/tobias/Zotero/storage/S5S9EKZF/articles.html}
}

@article{muClusteringbasedTopicModel2022,
  title = {A Clustering-Based Topic Model Using Word Networks and Word Embeddings},
  author = {Mu, Wenchuan and Lim, Kwan Hui and Liu, Junhua and Karunasekera, Shanika and Falzon, Lucia and Harwood, Aaron},
  year = {2022},
  month = apr,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {38},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00585-4},
  abstract = {Online social networking services like Twitter are frequently used for discussions on numerous topics of interest, which range from mainstream and popular topics (e.g., music and movies) to niche and specialized topics (e.g., politics). Due to the popularity of such services, it is a challenging task to automatically model and determine the numerous discussion topics given the large amount of tweets. Adding on this complexity is the need to identify these topics with the absence of prior knowledge about both the types and number of topics, while having the requirement of the relevant technical expertise to tune the numerous parameters for the various models. To address this challenge, we develop the Clustering-based Topic Modelling (ClusTop) algorithm that first constructs different types of word networks based on different types of n-grams co-occurrence and word embedding distances. Using these word networks, ClusTop is then able to automatically determine the discussion topics using community detection approaches. In contrast to traditional topic models, ClusTop does not require the tuning or setting of numerous parameters and instead uses community detection approaches to automatically determine the appropriate number of topics. The ClusTop algorithm is also able to capture the syntactic meaning in tweets via the use of bigrams, trigrams, other word combinations and word embedding techniques in constructing the word network graph, and utilizes edge weights based on word embedding. Using three Twitter datasets with labelled crises and events as topics, we show that ClusTop outperforms various traditional baselines in terms of topic coherence, pointwise mutual information, precision, recall and F-score.},
  keywords = {Clustering,Microblogs,Social networks,Topic modelling,Twitter,Word embedding},
  file = {/Users/tobias/Zotero/storage/NLJIG462/Mu et al. - 2022 - A clustering-based topic model using word networks.pdf;/Users/tobias/Zotero/storage/6CS7J6BM/articles.html}
}

@article{muhamadTransformingOpenAPISpecification2022,
  title = {Transforming {{OpenAPI Specification}} 3.0 Documents into {{RDF-based}} Semantic Web Services},
  author = {Muhamad, Wardani and {Suhardi} and Bandung, Yoanes},
  year = {2022},
  month = apr,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {55},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00600-8},
  abstract = {Web services are provided with documents that at the very least specify the endpoint, input parameters, and output or response of each operation to expose their capabilities. This should be considered through an understandable format for humans and/or machines. In the Representational State Transfer (REST) architectural style, the OpenAPI Specification (OAS) is used as a reference to create web service descriptions. However, it only supports syntactic interoperability, leading to the incapability of supporting the automated selection process. To overcome this, OAS documents must be enhanced by including semantics to each resource to provide ``understandable'' services. Therefore, this study aims to develop a system capable of transforming resources in OAS documents into RDF-based semantic web services. To begin, a relational database schema based on the OAS structure is created to store all objects in the OAS document. The published open-linked vocabulary was then used to create the ontology, which maps resources and their relationships on the RDF data model. To build RDF-based semantic web services, R2RML was used to generate the relational database model into triple RDF. The proposed system was also tested through prototyping and using a dataset of 106 OAS documents, which were downloaded from APIs.guru between 5\textendash 10 May 2021. The number of triple RDFs generated per document varied with resource rate. An OAS document generates 36 to 16,505 triple RDF in a dataset. The end product was a triple RDF knowledge base maintained by a graph management database. It is now possible to find service operations, input and output parameters, and service composition requirements utilizing the repository semantic web services using SPARQL. On the other hand, the use of relational databases to store OAS resources increased reuse efficiency by approximately 48\%, owing to service developers designing interoperability between uniform parameter services, which were then used as input and output.},
  keywords = {OpenAPI Specification,RDF,Semantic ontology,Semantic web services,Service composition},
  file = {/Users/tobias/Zotero/storage/YPM4MGDR/Muhamad et al. - 2022 - Transforming OpenAPI Specification 3.0 documents i.pdf;/Users/tobias/Zotero/storage/2EEIAQE6/articles.html}
}

@incollection{munroBackpropagation2017,
  title = {Backpropagation},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Munro, Paul},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {93--97},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_51},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@article{naikNovelMultiLayerAttention2022,
  title = {A Novel {{Multi-Layer Attention Framework}} for Visual Description Prediction Using Bidirectional {{LSTM}}},
  author = {Naik, Dinesh and Jaidhar, C. D.},
  year = {2022},
  month = nov,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {104},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00664-6},
  abstract = {The massive influx of text, images, and videos to the internet has recently increased the challenge of computer vision-based tasks in big data. Integrating visual data with natural language to generate video explanations has been a challenge for decades. However, recent experiments on image/video captioning that employ Long-Short-Term-Memory (LSTM) have piqued the interest of researchers studying its possible application in video captioning. The proposed video captioning architecture combines the bidirectional multilayer LSTM (BiLSTM) encoder and unidirectional decoder. The innovative architecture also considers temporal relations when creating superior global video representations. In contrast to the majority of prior work, the most relevant features of a video are selected and utilized specifically for captioning purposes. Existing methods utilize a single-layer attention mechanism for linking visual input with phrase meaning. This approach employs LSTMs and a multilayer attention mechanism to extract characteristics from movies, construct links between multi-modal (words and visual material) representations, and generate sentences with rich semantic coherence. In addition, we evaluated the performance of the suggested system using a benchmark dataset for video captioning. The obtained results reveal superior performance relative to state-of-the-art works in METEOR and promising performance relative to the BLEU score. In terms of quantitative performance, the proposed approach outperforms most existing methodologies.},
  keywords = {Attention,Computer vision,Convolutional Neural Network,LSTM,Video captioning},
  file = {/Users/tobias/Zotero/storage/KYKCPVKU/Naik and Jaidhar - 2022 - A novel Multi-Layer Attention Framework for visual.pdf}
}

@article{naikSemanticContextDriven2022,
  title = {Semantic Context Driven Language Descriptions of Videos Using Deep Neural Network},
  author = {Naik, Dinesh and Jaidhar, C. D.},
  year = {2022},
  month = feb,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {17},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00569-4},
  abstract = {The massive addition of data to the internet in text, images, and videos made computer vision-based tasks challenging in the big data domain. Recent exploration of video data and progress in visual information captioning has been an arduous task in computer vision. Visual captioning is attributable to integrating visual information with natural language descriptions. This paper proposes an encoder-decoder framework with a 2D-Convolutional Neural Network (CNN) model and layered Long Short Term Memory (LSTM) as the encoder and an LSTM model integrated with an attention mechanism working as the decoder with a hybrid loss function. Visual feature vectors extracted from the video frames using a 2D-CNN model capture spatial features. Specifically, the visual feature vectors are fed into the layered LSTM to capture the temporal information. The attention mechanism enables the decoder to perceive and focus on relevant objects and correlate the visual context and language content for producing semantically correct captions. The visual features and GloVe word embeddings are input into the decoder to generate natural semantic descriptions for the videos. The performance of the proposed framework is evaluated on the video captioning benchmark dataset Microsoft Video Description (MSVD) using various well-known evaluation metrics. The experimental findings indicate that the suggested framework outperforms state-of-the-art techniques. Compared to the state-of-the-art research methods, the proposed model significantly increased all measures, B@1, B@2, B@3, B@4, METEOR, and CIDEr, with the score of 78.4, 64.8, 54.2, and 43.7, 32.3, and 70.7, respectively. The progression in all scores indicates a more excellent grasp of the context of the inputs, which results in more accurate caption prediction.},
  keywords = {Attention,Computer vision,Convolutional neural network,LSTM,Video captioning},
  file = {/Users/tobias/Zotero/storage/C3PJ694F/Naik and Jaidhar - 2022 - Semantic context driven language descriptions of v.pdf;/Users/tobias/Zotero/storage/QHQ9XNWW/articles.html}
}

@article{nellerAIEducationDeep2017,
  title = {{{AI}} Education: Deep Neural Network Learning Resources},
  shorttitle = {{{AI}} Education},
  author = {Neller, Todd W.},
  year = {2017},
  month = oct,
  journal = {AI Matters},
  volume = {3},
  number = {3},
  pages = {20--21},
  issn = {2372-3483},
  doi = {10.1145/3137574.3137580},
  abstract = {In this column, we focus on resources for learning and teaching deep neural network learning. Many exciting advances have been made in this area of late, and so many resources have become available online that the flood of relevant concepts and techniques can be overwhelming. Here, we hope to provide a sampling of high-quality resources to guide the newcomer into this booming field.},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/RWHSVZ66/Neller - 2017 - AI education deep neural network learning resourc.pdf}
}

@book{nicosiaMachineLearningOptimization2022,
  title = {Machine {{Learning}}, {{Optimization}}, and {{Data Science}}: 7th {{International Conference}}, {{LOD}} 2021, {{Grasmere}}, {{UK}}, {{October}} 4\textendash 8, 2021, {{Revised Selected Papers}}, {{Part I}}},
  shorttitle = {Machine {{Learning}}, {{Optimization}}, and {{Data Science}}},
  editor = {Nicosia, Giuseppe and Ojha, Varun and La Malfa, Emanuele and La Malfa, Gabriele and Jansen, Giorgio and Pardalos, Panos M. and Giuffrida, Giovanni and Umeton, Renato},
  year = {2022},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {13163},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-95467-3},
  isbn = {978-3-030-95466-6 978-3-030-95467-3},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/F6TPMJHT/Nicosia et al. - 2022 - Machine Learning, Optimization, and Data Science .pdf}
}

@article{nijhawanStressDetectionUsing2022,
  title = {Stress Detection Using Natural Language Processing and Machine Learning over Social Interactions},
  author = {Nijhawan, Tanya and Attigeri, Girija and Ananthakrishna, T.},
  year = {2022},
  month = mar,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {33},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00575-6},
  abstract = {Cyberspace is a vast soapbox for people to post anything that they witness in their day-to-day lives. Social media content is mostly used for review, opinion, influence, or sentiment analysis. In this paper, we aim to extend sentiment and emotion analysis for detecting the stress of an individual based on the posts and comments shared by him/her on social networking platforms. We leverage large-scale datasets with tweets to accomplish sentiment analysis with the aid of machine learning algorithms and a deep learning model, BERT for sentiment classification. We also adopted Latent Dirichlet Allocation which is an unsupervised machine learning method for scanning a group of documents, recognizing the word and phrase patterns within them, and gathering word groups and alike expressions that most precisely illustrate a set of documents. This helps us to predict which topic is linked to the textual data. With the aid of these models, we will be able to detect the emotion of users online. Further, these emotions can be used to analyze stress or depression. In conclusion, the ML models and a BERT model have a very good detection rate. This research is useful for the well-being of one's mental health. The results are evaluated using various metrics at the macro and micro levels and indicate that the trained model detects the status of emotions based on social interactions.},
  keywords = {Decision tree,Latent Dirichlet Algorithm,Logistic regression,Machine learning,Natural Language Processing,Random forest,Sentiment analysis,Topic modelling},
  file = {/Users/tobias/Zotero/storage/Y5S6LTYA/Nijhawan et al. - 2022 - Stress detection using natural language processing.pdf;/Users/tobias/Zotero/storage/QBVU4WMU/articles.html}
}

@misc{norvigPytudes2022,
  title = {Pytudes},
  author = {Norvig, Peter},
  year = {2022},
  month = feb,
  abstract = {Python programs, usually short, of considerable difficulty, to perfect particular skills.},
  copyright = {MIT},
  keywords = {\#nosource,demonstrate-skills,exercises,perfecting programming skills,practice,programming,python,python-3}
}

@article{ojalaMotionDetectionClassification2022,
  title = {Motion Detection and Classification: Ultra-Fast Road User Detection},
  shorttitle = {Motion Detection and Classification},
  author = {Ojala, Risto and Veps{\"a}l{\"a}inen, Jari and Tammi, Kari},
  year = {2022},
  month = mar,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {28},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00581-8},
  abstract = {With the emerge of intelligent and connected transportation systems, driver perception and on-board safety systems could be extended with roadside camera units. Computer vision can be utilised to detect road users, conveying their presence to vehicles that cannot perceive them. However, accurate object detection algorithms are typically computationally heavy, depending on delay-prone cloud computation or expensive local hardware. Similar problems are faced in many intelligent transportation applications, in which road users are detected with a roadside camera. We propose utilising Motion Detection and Classification (MoDeCla) for road user detection. The approach is computationally lightweight and capable of running in real-time on an inexpensive single-board computer. To validate the applicability of MoDeCla in intelligent transportation applications, a detection benchmark was carried out on manually labelled data gathered from surveillance cameras overseeing urban areas in Espoo, Finland. Separate datasets were gathered during winter and summer, enabling comparison of the detectors in significantly different weather conditions. Compared to state-of-the-art object detectors, MoDeCla performed detection an order of magnitude faster, yet achieved similar accuracy. The most impactful deficiency of MoDeCla was errors in bounding box placement. Car headlights and long dark shadows were found especially difficult for the motion detection, which caused incorrect bounding boxes. Future improvements are also required for separately detecting overlapping road users.},
  keywords = {Background subtraction,Convolutional neural networks,Intelligent transportation systems,Motion detection,Object detection,Winter conditions},
  file = {/Users/tobias/Zotero/storage/DGENSE9P/Ojala et al. - 2022 - Motion detection and classification ultra-fast ro.pdf;/Users/tobias/Zotero/storage/57SF5M5I/articles.html}
}

@incollection{orbanzBayesianNonparametricModels2017,
  title = {Bayesian {{Nonparametric Models}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Orbanz, Peter and Teh, Yee Whye},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {107--116},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_928},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/STJKDKYQ/Orbanz and Teh - 2017 - Bayesian Nonparametric Models.pdf}
}

@misc{OSTBTSTranstats,
  title = {{{OST}}\_{{R}} | {{BTS}} | {{Transtats}}},
  howpublished = {https://www.transtats.bts.gov/Homepage.asp},
  keywords = {bureau_of_transportation_statistics,data,data_source,official,usa},
  file = {/Users/tobias/Zotero/storage/268BWSCN/Homepage.html}
}

@incollection{pageBiomedicalInformatics2017,
  title = {Biomedical {{Informatics}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Page, C David and Natarajan, Sriraam},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {143--163},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_30},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@article{paisNLPbasedPlatformService2022,
  title = {{{NLP-based}} Platform as a Service: A Brief Review},
  shorttitle = {{{NLP-based}} Platform as a Service},
  author = {Pais, Sebasti{\~a}o and Cordeiro, Jo{\~a}o and Jamil, M. Luqman},
  year = {2022},
  month = apr,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {54},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00603-5},
  abstract = {Natural language processing (NLP) refers to the field of study that focuses on the interactions between human language and computers. It has recently gained much attention for analyzing human language computationally and has spread its applications for various tasks such as machine translation, information extraction, summarization, question answering, and others. With the rapid growth of cloud computing services, merging NLP in the cloud is a significant benefit. It allows researchers to conduct NLP-related experiments on large amounts of data handled by big data techniques while harnessing the cloud's vast, on-demand computing power. However, it has not sufficiently spread its tools and applications as a service in the cloud and there is little literature available that discusses the scope of interdisciplinary work. NLP, cloud Computing, and big data are vast domains and contain their challenges and potentials. By overcoming those challenges and integrating these fields, great potential for NLP and its applications can be unleashed. This paper presents a survey of NLP in cloud computing with a key focus on the comparison of cloud-based NLP services, challenges of NLP and big data while emphasizing the necessity of viable cloud-based NLP services. In the first part of this paper, an overview of NLP is presented by discussing different levels of NLP and components of natural language generation (NLG), followed by the applications of NLP. In the second part, the concept of cloud computing is discussed that highlights the architectural layers and deployment models of cloud computing and cloud-hosted NLP services. In the third part, the field of big data in the cloud is discussed with an emphasis on NLP. Furthermore, information extraction via NLP techniques within big data is introduced.},
  keywords = {Big data,Cloud computing,Natural language processing},
  file = {/Users/tobias/Zotero/storage/IG5XQGPX/Pais et al. - 2022 - NLP-based platform as a service a brief review.pdf;/Users/tobias/Zotero/storage/XLVGWCPG/articles.html}
}

@misc{PapersCodeCosine,
  title = {Papers with {{Code}} - {{Cosine Annealing Explained}}},
  abstract = {Cosine Annealing is a type of learning rate schedule that has the effect of starting with a large learning rate that is relatively rapidly decreased to a minimum value before being increased rapidly again. The resetting of the learning rate acts like a simulated restart of the learning process and the re-use of good weights as the starting point of the restart is referred to as a "warm restart" in contrast to a "cold restart" where a new set of small random numbers may be used as a starting point. \$\$\textbackslash eta\_\{t\} = \textbackslash eta\_\{min\}\^\{i\} + \textbackslash frac\{1\}\{2\}\textbackslash left(\textbackslash eta\_\{max\}\^\{i\}-\textbackslash eta\_\{min\}\^\{i\}\textbackslash right)\textbackslash left(1+\textbackslash cos\textbackslash left(\textbackslash frac\{T\_\{cur\}\}\{T\_\{i\}\}\textbackslash pi\textbackslash right)\textbackslash right) \$\$ Where where \$\textbackslash eta\_\{min\}\^\{i\}\$ and \$ \textbackslash eta\_\{max\}\^\{i\}\$ are ranges for the learning rate, and \$T\_\{cur\}\$ account for how many epochs have been performed since the last restart. Text Source: Jason Brownlee Image Source: Gao Huang},
  howpublished = {https://paperswithcode.com/method/cosine-annealing},
  langid = {english},
  keywords = {cosine annealing,definition,explanation,learning rate,SGD,stochastik gradient descent},
  file = {/Users/tobias/Zotero/storage/I46VY3F9/cosine-annealing.html}
}

@misc{PapersCodeSGDR,
  title = {Papers with {{Code}} - {{SGDR}}: {{Stochastic Gradient Descent}} with {{Warm Restarts}}},
  shorttitle = {Papers with {{Code}} - {{SGDR}}},
  abstract = {Implemented in 17 code libraries.},
  howpublished = {https://paperswithcode.com/paper/sgdr-stochastic-gradient-descent-with-warm},
  langid = {english},
  keywords = {cosinus annealing,learning rate,paper,SGD,stochastik gradient descent,warm restart},
  file = {/Users/tobias/Zotero/storage/LPHCF2S5/sgdr-stochastic-gradient-descent-with-warm.html}
}

@book{pardalosMachineLearningOptimization2016,
  title = {Machine {{Learning}}, {{Optimization}}, and {{Big Data}}: {{Second International Workshop}}, {{MOD}} 2016, {{Volterra}}, {{Italy}}, {{August}} 26-29, 2016, {{Revised Selected Papers}}},
  shorttitle = {Machine {{Learning}}, {{Optimization}}, and {{Big Data}}},
  editor = {Pardalos, Panos M. and Conca, Piero and Giuffrida, Giovanni and Nicosia, Giuseppe},
  year = {2016},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {10122},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-51469-7},
  isbn = {978-3-319-51468-0 978-3-319-51469-7},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/DHNSVFAZ/Pardalos et al. - 2016 - Machine Learning, Optimization, and Big Data Seco.pdf}
}

@misc{phdAnswerHowWould2011,
  title = {Answer to "{{How}} Would You Explain Covariance to Someone Who Understands Only the Mean?"},
  shorttitle = {Answer to "{{How}} Would You Explain Covariance to Someone Who Understands Only the Mean?},
  author = {PhD},
  year = {2011},
  month = nov,
  journal = {Cross Validated},
  file = {/Users/tobias/Zotero/storage/KTA3JQXT/how-would-you-explain-covariance-to-someone-who-understands-only-the-mean.html}
}

@misc{phdHowWouldYou2020,
  type = {Forum Post},
  title = {How Would You Explain Covariance to Someone Who Understands Only the Mean?},
  author = {PhD},
  year = {2020},
  month = jul,
  journal = {Cross Validated},
  file = {/Users/tobias/Zotero/storage/XRK4V5EY/how-would-you-explain-covariance-to-someone-who-understands-only-the-mean.html}
}

@article{phiwhormAdaptiveMultipleImputations2022,
  title = {Adaptive Multiple Imputations of Missing Values Using the Class Center},
  author = {Phiwhorm, Kritbodin and Saikaew, Charnnarong and Leung, Carson K. and Polpinit, Pattarawit and Saikaew, Kanda Runapongsa},
  year = {2022},
  month = apr,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {52},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00608-0},
  abstract = {Big data has become a core technology to provide innovative solutions in many fields. However, the collected dataset for data analysis in various domains will contain missing values. Missing value imputation is the primary method for resolving problems involving incomplete datasets. Missing attribute values are replaced with values from a selected set of observed data using statistical or machine learning methods. Although machine learning techniques can generate reasonably accurate imputation results, they typically require longer imputation durations than statistical techniques. This study proposes the adaptive multiple imputations of missing values using the class center (AMICC) approach to produce effective imputation results efficiently. AMICC is based on the class center and defines a threshold from the weighted distances between the center and other observed data for the imputation step. Additionally, the distance can be an adaptive nearest neighborhood or the center to estimate the missing values. The experimental results are based on numerical, categorical, and mixed datasets from the University of California Irvine (UCI) Machine Learning Repository with introduced missing values rate from 10 to 50\% in 27 datasets. The proposed AMICC approach outperforms the other missing value imputation methods with higher average accuracy at 81.48\% which is higher than those of other methods about 9~\textendash ~14\%. Furthermore, execution time is different from the Mean/Mode method, about seven seconds; moreover, it requires significantly less time for imputation than some machine learning approaches about 10~\textendash ~14~s.},
  keywords = {Big data,Class center,Data mining,Incomplete data,Machine learning,Missing value imputation},
  file = {/Users/tobias/Zotero/storage/FDR4XHM3/Phiwhorm et al. - 2022 - Adaptive multiple imputations of missing values us.pdf;/Users/tobias/Zotero/storage/PD9GCGZH/articles.html}
}

@article{pietrolajNeuralNetworkTraining2022,
  title = {Neural Network Training with Limited Precision and Asymmetric Exponent},
  author = {Pietro{\l}aj, Mariusz and Blok, Marek},
  year = {2022},
  month = may,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {63},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00606-2},
  abstract = {Along with an extremely increasing number of mobile devices, sensors and other smart utilities, an unprecedented growth of data can be observed in today's world. In order to address multiple challenges facing the big data domain, machine learning techniques are often leveraged for data analysis, filtering and classification. Wide usage of artificial intelligence with large amounts of data creates growing demand not only for storage and operational memory, but also computational power. Increasing complexity and variety of neural network architectures are vivid examples of such trends in the modern data-driven industry. In response to this situation, focusing on less demanding operations for inference and training of neural networks became a popular approach among many researchers to overcome resources related issues. This work aims to investigate one of the paths associated with the mentioned efficiency problems and shows the impact of floating-point precision limitation on convolutional neural networks, including experiments on various exponent and mantissa sizes. Additionally, authors explore floating-point numbers utilization and optimization techniques in the scope of neural network training. Based on conducted research a novel method of asymmetric exponent utilization is presented achieving almost identical accuracy of 32-bit floating-point parameters while training a neural network with only 12-bit variables without additional rounding.},
  keywords = {Asymmetric exponent,Big data,Deep learning,Machine learning,Neural network,Precision limitation},
  file = {/Users/tobias/Zotero/storage/XDYSZ8UG/Pietrołaj and Blok - 2022 - Neural network training with limited precision and.pdf}
}

@incollection{poupartBayesianReinforcementLearning2017,
  title = {Bayesian {{Reinforcement Learning}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Poupart, Pascal},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {116--120},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_929},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/KPUHPF5L/Poupart - 2017 - Bayesian Reinforcement Learning.pdf}
}

@misc{ProbabilityMachineLearning,
  title = {Probability\_for\_machine\_learning\_pdf\_summary.Pdf},
  file = {/Users/tobias/Zotero/storage/7PLPRLZ9/probability_for_machine_learning_pdf_summary.pdf}
}

@article{putraTrafficRoadConditions2022,
  title = {Traffic and Road Conditions Monitoring System Using Extracted Information from {{Twitter}}},
  author = {Putra, Prabu Kresna and Mahendra, Rahmad and Budi, Indra},
  year = {2022},
  month = may,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {65},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00621-3},
  abstract = {Congested roads and daily traffic jams cause traffic disturbances. A traffic monitoring system using closed-circuit television (CCTV) has been implemented, but the information gathered is still limited for public use. This research focuses on utilizing Twitter data to monitor traffic and road conditions. Traffic-related information is extracted from social media using text mining approach. The methods include Tweet classification for filtering relevant data, location information extraction, and geocoding in order to convert text-based location into coordinate information that can be deployed into Geographic Information System. We test several supervised classification algorithms in this study, i.e., Na\"ive Bayes, Random Forest, Logistic Regression, and Support Vector Machine. We experiment with Bag Of Words (BOW) and Term Frequency - Inverse Document Frequency (TF-IDF) as the feature representation. The location information is extracted using Named Entity Recognition (NER) and Part-Of-Speech (POS) Tagger. The geocoding is implemented using the ArcPy library. The best model for Tweet relevance classification is the Logistic Regression classifier with the feature combination of unigram and char n-gram, achieving an F1-score of 93\%. The NER-based location extractor obtains an F1-score of 54\% with a precision of 96\%. The geocoding success rate for extracting the location information is 68\%. In addition, a web-based visualization is also implemented in order to display traffic information using the spatial interface.},
  keywords = {Geocoding,Information extraction,Road condition,Text classification,Text mining,Traffic situation,Twitter},
  file = {/Users/tobias/Zotero/storage/NCY8PXEM/Putra et al. - 2022 - Traffic and road conditions monitoring system usin.pdf}
}

@book{PythonMachineLearning2020,
  title = {Python Machine Learning for Beginners: Learning from Scratch {{NumPy}}, Pandas, {{Matplotlib}}, {{Seaborn}}, {{Scikitlearn}}, and {{TensorFlow}} for {{Machine Learning}} and {{Data Science}}.},
  shorttitle = {Python Machine Learning for Beginners},
  year = {2020},
  abstract = {Python Machine Learning for BeginnersMachine Learning (ML) and Artificial Intelligence (AI) are here to stay. Yes, that's right. Based on a significant amount of data and evidence, it's obvious that ML and AI are here to stay.Consider any industry today. The practical applications of ML are really driving business results. Whether it's healthcare, e-commerce, government, transportation, social media sites, financial services, manufacturing, oil and gas, marketing and salesYou name it. The list goes on. There's no doubt that ML is going to play a decisive role in every domain in the future.But what does a Machine Learning professional do?A Machine Learning specialist develops intelligent algorithms that learn from data and also adapt to the data quickly. Then, these high-end algorithms make accurate predictions.  Python Machine Learning for Beginners presents you with a hands-on approach to learn ML fast.How Is This Book Different?AI Publishing strongly believes in learning by doing methodology. With this in mind, we have crafted this book with care. You will find that the emphasis on the theoretical aspects of machine learning is equal to the emphasis on the practical aspects of the subject matter.You'll learn about data analysis and visualization in great detail in the first half of the book. Then, in the second half, you'll learn about machine learning and statistical models for data science.Each chapter presents you with the theoretical framework behind the different data science and machine learning techniques, and practical examples illustrate the working of these techniques.When you buy this book, your learning journey becomes so much easier. The reason is you get instant access to all the related learning material presented with this book--references, PDFs, Python codes, and exercises--on the publisher's website. All this material is available to you at no extra cost. You can download the ML datasets used in this book at runtime, or you can access them via the Resources/Datasets folder. You'll also find the short course on Python programming in the second chapter immensely useful, especially if you are new to Python. Since this book gives you access to all the Python codes and datasets, you only need access to a computer with the internet to get started.},
  isbn = {978-1-73479-015-3},
  langid = {english},
  annotation = {OCLC: 1268558270},
  file = {/Users/tobias/Zotero/storage/PV25J98Y/2020 - Python machine learning for beginners learning fr.pdf}
}

@article{rajiComputationalMethodsPredicting2022,
  title = {Computational Methods for Predicting the Outcome of Thoracic Transplantation},
  author = {Raji, C. G. and Safna, A. K.},
  year = {2022},
  month = may,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {58},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00609-z},
  abstract = {Cardiac disease and the death rates due to coronary heart failure and cardiomyopathy are increasing. Thoracic transplantation is now a widely accepted therapeutic option for end-stage cardiac failure. The survival rate after the organ transplantation is crucial. Survival prediction after heart transplantation is a hot area of research. The use of conventional statistical techniques is computationally expensive and does not provide reliable solutions. Artificial Neural Networks based survival prediction helps surgeons make precise decisions and predict the best outcomes. The proposed system implements multi-layer perceptron algorithm, which shows good performance in survival prediction. We also implemented our work in the Radial Basis Function Network model to prove the accuracy of proposed model. For this research study, data were collected from United Network for Organ Sharing database and extracted the relevant thoracic transplantation survival prediction attributes with the help of suitable data mining techniques. We obtained an accuracy of 97.1\% from the multi-layer perceptron model with the evaluation of various performance measures. In order to assure the validity of the proposed model we implemented the Radial Basis Function model and obtained an accuracy of 92.37\%. We collated the accuracy of proposed survival prediction models with existing systems and proved that the proposed system appeared to be best for survival prediction with higher accuracy compared to 85.9\% in the existing system. The outcome of the model will be an asset for the lifesaving procedures in the medical field.},
  keywords = {Multi layer perceptron,Radial basis function,Survival prediction,Thoracic transplantation,Validation},
  file = {/Users/tobias/Zotero/storage/8PZ4AE4Y/Raji and Safna - 2022 - Computational methods for predicting the outcome o.pdf}
}

@incollection{rajnarayanBiasVarianceTradeOffsNovel2017,
  title = {Bias-{{Variance Trade-Offs}}: {{Novel Applications}}},
  shorttitle = {Bias-{{Variance Trade-Offs}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Rajnarayan, Dev and Wolpert, David},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {129--139},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_28},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@article{ramosCanonicalModelSeasonal2022,
  title = {A Canonical Model for Seasonal Climate Prediction Using {{Big Data}}},
  author = {Ramos, M. P. and Tasinaffo, P. M. and Cunha, A. M. and Silva, D. A. and Gon{\c c}alves, G. S. and Dias, L. A. V.},
  year = {2022},
  month = mar,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {27},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00580-9},
  abstract = {This article addresses the elaboration of a canonical model, involving methods, techniques, metrics, tools, and Big Data, applied to the knowledge of seasonal climate prediction, aiming at greater dynamics, speed, conciseness, and scalability. The proposed model was hosted in an environment capable of integrating different types of meteorological data and centralizing data stores. The seasonal climate prediction method called M-PRECLIS was designed and developed for practical application. The usability and efficiency of the proposed model was tested through a case study that made use of operational data generated by an atmospheric numerical model of the climate area found in the supercomputing environment of the Center for Weather Forecasting and Climate Studies linked to the Brazilian Institute for Space Research. The seasonal climate prediction uses ensemble members method to work and the main Big Data technologies used for data processing were: Python language, Apache Hadoop, Apache Hive, and the Optimized Row Columnar (ORC) file format. The main contributions of this research are the canonical model, its modules and internal components, the proposed method M-PRECLIS, and its use in a case study. After applying the model to a practical and real experiment, it was possible to analyze the results obtained and verify: the consistency of the model by the output images, the code complexity, the performance, and also to perform the comparison with related works. Thus, it was found that the proposed canonical model, based on the best practices of Big Data, is a viable alternative that can guide new paths to be followed.},
  keywords = {Atmospheric numerical model,Big Data,Hadoop,Hive,MapReduce,Seasonal climate prediction},
  file = {/Users/tobias/Zotero/storage/JIYG2W2Z/Ramos et al. - 2022 - A canonical model for seasonal climate prediction .pdf;/Users/tobias/Zotero/storage/PVP7YFF5/articles.html}
}

@misc{rAnswerCombinationsElements2015,
  title = {Answer to "{{Combinations}} between Elements in Two Tuples in {{Python}}"},
  author = {R, Matthew},
  year = {2015},
  month = jun,
  journal = {Stack Overflow},
  keywords = {combinations,combinatorics,itertools,itertools.product},
  file = {/Users/tobias/Zotero/storage/5E7MPWX4/combinations-between-elements-in-two-tuples-in-python.html}
}

@misc{RealtimeServingXGBoost2022,
  title = {Real-Time {{Serving}} for {{XGBoost}}, {{Scikit-Learn RandomForest}}, {{LightGBM}}, and {{More}}},
  year = {2022},
  month = feb,
  journal = {NVIDIA Technical Blog},
  abstract = {Dive into how the NVIDIA Triton Inference Server offers highly optimized real-time serving forest models by using the Forest Inference Library backend.},
  howpublished = {https://developer.nvidia.com/blog/real-time-serving-for-xgboost-scikit-learn-randomforest-lightgbm-and-more/},
  langid = {american},
  file = {/Users/tobias/Zotero/storage/JGTFYVXS/real-time-serving-for-xgboost-scikit-learn-randomforest-lightgbm-and-more.html}
}

@misc{Recommenders2022,
  title = {Recommenders},
  year = {2022},
  month = feb,
  abstract = {Best Practices on Recommendation Systems},
  copyright = {MIT},
  howpublished = {Microsoft},
  keywords = {\#nosource,gpu,movie recommender,multinomial RBM,tensorflow}
}

@article{rezaeiImproveDataClassification2022,
  title = {Improve Data Classification Performance in Diagnosing Diabetes Using the {{Binary Exchange Market Algorithm}}},
  author = {Rezaei, Faranak and Abbasitabar, Maryam and Mirzaei, Shirin and Kamari Direh, Zahra and Ahmadi, Sahar and Azizi, Zahra and Danialy, Darya},
  year = {2022},
  month = apr,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {43},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00598-z},
  abstract = {Today's lifestyle has led to a significant increase in referrals to medical centers to diagnose various diseases. To this end, over the past few years, researchers have turned to new diagnostic methods, including data mining and artificial intelligence, intending to facilitate the detection process and increase reliability. The high volume of data available in medical centers can be considered one of the main problems in using these methods. The optimal selection of essential and influential features reduces the maximum dimension for better diagnosis with more reliability of results. In this paper, a new approach uses a Binary Exchange Market Algorithm (BEMA) to identify essential and practical features in the diabetes dataset and determine the best algorithm binary function (type of sigmoid function) to improve the performance of the EMA algorithm is presented. For validation and efficiency of the proposed BEMA algorithm, several SVM, KNN, and NB classification models have been used to train and test the final model. The results obtained from the evaluations show that the proposed BEMA-SVM combined method has a better performance than the previous methods to improve accuracy and offer an effect equivalent to 98.502\%. Also, to provide better results and more reliability than the proposed method, researchers can use a combination of several classes with the proposed method, which is outside the scope of this study.},
  keywords = {Binary Exchange Market Algorithm (BEMA),Data Mining,Diabetes,Feature Selection (FS),Support Vector Machine (SVM)},
  file = {/Users/tobias/Zotero/storage/WLBR8IQ5/Rezaei et al. - 2022 - Improve data classification performance in diagnos.pdf;/Users/tobias/Zotero/storage/CQ4VLCDL/articles.html}
}

@article{rivasTaskagnosticRepresentationLearning2022,
  title = {Task-Agnostic Representation Learning of Multimodal Twitter Data for Downstream Applications},
  author = {Rivas, Ryan and Paul, Sudipta and Hristidis, Vagelis and Papalexakis, Evangelos E. and {Roy-Chowdhury}, Amit K.},
  year = {2022},
  month = feb,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {18},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00570-x},
  abstract = {Twitter is a frequent target for machine learning research and applications. Many problems, such as sentiment analysis, image tagging, and location prediction have been studied on Twitter data. Much of the prior work that addresses these problems within the context of Twitter focuses on a subset of the types of data available, e.g. only text, or text and image. However, a tweet can have several additional components, such as the location and the author, that can also provide useful information for machine learning tasks. In this work, we explore the problem of jointly modeling several tweet components in a common embedding space via task-agnostic representation learning, which can then be used to tackle various machine learning applications. To address this problem, we propose a deep neural network framework that combines text, image, and graph representations to learn joint embeddings for 5 tweet components: body, hashtags, images, user, and location. In our experiments, we use a large dataset of tweets to learn a joint embedding model and use it in multiple tasks to evaluate its performance vs. state-of-the-art baselines specific to each task. Our results show that our proposed generic method has similar or superior performance to specialized application-specific approaches, including accuracy of 52.43\% vs. 48.88\% for location prediction and recall of up to 15.93\% vs. 12.12\% for hashtag recommendation.},
  keywords = {Deep learning,Joint embedding,Machine learning,Multimodal data,Twitter},
  file = {/Users/tobias/Zotero/storage/PVK5PMJG/Rivas et al. - 2022 - Task-agnostic representation learning of multimoda.pdf;/Users/tobias/Zotero/storage/C22UGN5D/articles.html}
}

@article{rossiterExampleStatisticalData,
  title = {An Example of Statistical Data Analysis Using the {{R}} Environment for Statistical Computing},
  author = {Rossiter, D G},
  pages = {150},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/LHDDJEJT/Rossiter - An example of statistical data analysis using the .pdf}
}

@article{roySystematicReviewResearch2022,
  title = {A Systematic Review and Research Perspective on Recommender Systems},
  author = {Roy, Deepjyoti and Dutta, Mala},
  year = {2022},
  month = may,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {59},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00592-5},
  abstract = {Recommender systems are efficient tools for filtering online information, which is widespread owing to the changing habits of computer users, personalization trends, and emerging access to the internet. Even though the recent recommender systems are eminent in giving precise recommendations, they suffer from various limitations and challenges like scalability, cold-start, sparsity, etc. Due to the existence of various techniques, the selection of techniques becomes a complex work while building application-focused recommender systems. In addition, each technique comes with its own set of features, advantages and disadvantages which raises even more questions, which should be addressed. This paper aims to undergo a systematic review on various recent contributions in the domain of recommender systems, focusing on diverse applications like books, movies, products, etc. Initially, the various applications of each recommender system are analysed. Then, the algorithmic analysis on various recommender systems is performed and a taxonomy is framed that accounts for various components required for developing an effective recommender system. In addition, the datasets gathered, simulation platform, and performance metrics focused on each contribution are evaluated and noted. Finally, this review provides a much-needed overview of the current state of research in this field and points out the existing gaps and challenges to help posterity in developing an efficient recommender system.},
  keywords = {Collaborative filtering,Content-based filtering,Deep learning,Machine learning,Recommender system,Review},
  file = {/Users/tobias/Zotero/storage/7P3XPD97/Roy and Dutta - 2022 - A systematic review and research perspective on re.pdf}
}

@book{russellArtificialIntelligenceModern2021,
  title = {Artificial Intelligence a Modern Approach},
  author = {Russell, Stuart J. and Norvig, Peter and Chang, Ming-wei and Devlin, Jacob and Dragan, Anca and Forsyth, David and Goodfellow, Ian and Malik, Jitendra and Mansinghka, Vikash and Pearl, Judea and Woolridge, Michael},
  year = {2021},
  edition = {Fourth Edition},
  publisher = {{Pearson}},
  address = {{Hoboken, NJ}},
  isbn = {978-0-13-461099-3},
  file = {/Users/tobias/Zotero/storage/2QW2W3I9/Russell et al. - 2021 - Artificial intelligence a modern approach.pdf}
}

@article{sabharwalIntelligentLiteratureReview2022,
  title = {An Intelligent Literature Review: Adopting Inductive Approach to Define Machine Learning Applications in the Clinical Domain},
  shorttitle = {An Intelligent Literature Review},
  author = {Sabharwal, Renu and Miah, Shah J.},
  year = {2022},
  month = apr,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {53},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00605-3},
  abstract = {Big data analytics utilizes different techniques to transform large volumes of big datasets. The analytics techniques utilize various computational methods such as Machine Learning (ML) for converting raw data into valuable insights. The ML assists individuals in performing work activities intelligently, which empowers decision-makers. Since academics and industry practitioners have growing interests in ML, various existing review studies have explored different applications of ML for enhancing knowledge about specific problem domains. However, in most of the cases existing studies suffer from the limitations of employing a holistic, automated approach. While several researchers developed various techniques to automate the systematic literature review process, they also seemed to lack transparency and guidance for future researchers. This research aims to promote the utilization of intelligent literature reviews for researchers by introducing a step-by-step automated framework. We offer an intelligent literature review to obtain in-depth analytical insight of ML applications in the clinical domain to (a) develop the intelligent literature framework using traditional literature and Latent Dirichlet Allocation (LDA) topic modeling, (b) analyze research documents using traditional systematic literature review revealing ML applications, and (c) identify topics from documents using LDA topic modeling. We used a PRISMA framework for the review to harness samples sourced from four major databases (e.g., IEEE, PubMed, Scopus, and Google Scholar) published between 2016 and 2021 (September). The framework comprises two stages\textemdash (a) traditional systematic literature review consisting of three stages (planning, conducting, and reporting) and (b) LDA topic modeling that consists of three steps (pre-processing, topic modeling, and post-processing). The intelligent literature review framework transparently and reliably reviewed 305 sample documents.},
  keywords = {Clinical research,Latent Dirichlet Allocation,Machine learning,Systematic literature review,Topic modeling},
  file = {/Users/tobias/Zotero/storage/3UKZ8DU5/Sabharwal and Miah - 2022 - An intelligent literature review adopting inducti.pdf;/Users/tobias/Zotero/storage/WEYEKPY4/articles.html}
}

@misc{salCmmCallFormat2013,
  type = {Forum Post},
  title = {Cmm Call Format for Foreign Primop (Integer-Gmp Example)},
  author = {Sal},
  year = {2013},
  month = apr,
  journal = {Stack Overflow},
  keywords = {16-bit,32-bit,advantages of FP16 over FP32,binary representation,deep learning,drawbacks of FP16 compared to FP32,floating point numbers,fp16,fp32,half precision,memory allocated,mixed precision,single precision,theory,training a model faster},
  file = {/Users/tobias/Zotero/storage/ZZ7WS68K/cmm-call-format-for-foreign-primop-integer-gmp-example.html}
}

@article{salmanStabilityDifferentAggregation2022,
  title = {The Stability of Different Aggregation Techniques in Ensemble Feature Selection},
  author = {Salman, Reem and Alzaatreh, Ayman and Sulieman, Hana},
  year = {2022},
  month = apr,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {51},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00607-1},
  abstract = {To mitigate the curse of dimensionality in high-dimensional datasets, feature selection has become a crucial step in most data mining applications. However, no feature selection method consistently delivers the best performance across different domains. For this reason and in order to improve the stability of the feature selection process, ensemble feature selection frameworks have become increasingly popular. While many have examined the construction of ensemble techniques under various considerations, little work has been done to shed light on the influence of the aggregation process on the stability of the ensemble feature selection. In contribution to this field, this work aims to explore the impact of some selected aggregation strategies on the ensemble's stability and accuracy. Using twelve classification real datasets from various domains, the stability and accuracy of five different aggregation techniques were examined under four standard filter feature selection methods. The experimental analysis revealed significant differences in both the stability and accuracy behavior of the ensemble under different aggregations, especially between score-based and rank-based aggregation strategies. Moreover, it was observed that the simpler score-based strategies based on the Arithmetic Mean or L2-norm aggregation appear to be efficient and compelling in most cases. Given the data structure or associated application domain, this work's findings can guide the construction of feature selection ensembles using the most efficient and suitable aggregation rules.},
  keywords = {Ensemble learning,Feature selection,Mean aggregation,Stability},
  file = {/Users/tobias/Zotero/storage/Q6BB2J86/Salman et al. - 2022 - The stability of different aggregation techniques .pdf;/Users/tobias/Zotero/storage/B26NVQCU/articles.html}
}

@incollection{sammutAbsoluteErrorLoss2017,
  title = {Absolute {{Error Loss}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {8--8},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100504},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAccuracy2017,
  title = {Accuracy},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {8--8},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_3},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutACO2017,
  title = {{{ACO}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {8--8},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100003},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutActions2017,
  title = {Actions},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {9--9},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_5},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAdaboost2017,
  title = {Adaboost},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {19--20},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_917},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAdaptiveControlProcesses2017,
  title = {Adaptive {{Control Processes}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {20--20},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100004},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAdaptiveLearning2017,
  title = {Adaptive {{Learning}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {20--20},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100005},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAdaptiveSystem2017,
  title = {Adaptive {{System}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {40--40},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100505},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAgent2017,
  title = {Agent},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {40--40},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_13},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAgentBasedComputationalModels2017,
  title = {Agent-{{Based Computational Models}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {40--40},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100007},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAgentBasedModelingSimulation2017,
  title = {Agent-{{Based Modeling}} and {{Simulation}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {40--40},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100008},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAgentBasedSimulationModels2017,
  title = {Agent-{{Based Simulation Models}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {40--40},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100009},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAIS2017,
  title = {{{AIS}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {40--40},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100010},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAnalogicalReasoning2017,
  title = {Analogical {{Reasoning}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {41--41},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100012},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAnalysisText2017,
  title = {Analysis of {{Text}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {41--41},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100013},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAnalyticalLearning2017,
  title = {Analytical {{Learning}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {41--41},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100015},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAnytimeAlgorithm2017,
  title = {Anytime {{Algorithm}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {59--59},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_23},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAODE2017,
  title = {{{AODE}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {60--60},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100016},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutApprenticeshipLearning2017,
  title = {Apprenticeship {{Learning}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {60--60},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100017},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutApproximateDynamicProgramming2017,
  title = {Approximate {{Dynamic Programming}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {60--60},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100018},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/XM4I2IK7/Sammut and Webb - 2017 - Approximate Dynamic Programming.pdf}
}

@incollection{sammutAQ2017,
  title = {{{AQ}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {61--61},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100508},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutArchitecture2017,
  title = {Architecture},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {61--61},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100019},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAreaCurve2017,
  title = {Area {{Under Curve}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {61--61},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_918},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutARL2017,
  title = {{{ARL}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {61--61},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100020},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutART2017,
  title = {{{ART}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {61--61},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100509},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutARTDP2017,
  title = {{{ARTDP}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {61--61},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100021},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutArtificialLife2017,
  title = {Artificial {{Life}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {65--65},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_920},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutArtificialNeuralNetworks2017,
  title = {Artificial {{Neural Networks}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {65--66},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_921},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAssertion2017,
  title = {Assertion},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {70--70},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_37},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAssessmentModelPerformance2017,
  title = {Assessment of {{Model Performance}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {70--70},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100022},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAssociativeBanditProblem2017,
  title = {Associative {{Bandit Problem}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {71--71},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100023},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAttributeSelection2017,
  title = {Attribute {{Selection}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {75--75},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100506},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAttributeValueLearning2017,
  title = {Attribute-{{Value Learning}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {75--75},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_43},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAUC2017,
  title = {{{AUC}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {75--75},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_10025},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAuthorityControl2017,
  title = {Authority {{Control}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {75--75},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100026},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAverageCostNeuroDynamicProgramming2017,
  title = {Average-{{Cost Neuro-Dynamic Programming}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {85--85},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100027},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAverageCostOptimization2017,
  title = {Average-{{Cost Optimization}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {85--85},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100028},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutAveragePayoffReinforcementLearning2017,
  title = {Average-{{Payoff Reinforcement Learning}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {87--87},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100029},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBackprop2017,
  title = {Backprop},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {93--93},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100030},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBagging2017,
  title = {Bagging},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {97--98},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_925},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBakeOff2017,
  title = {Bake-{{Off}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {98--98},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_53},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBanditProblemSide2017,
  title = {Bandit {{Problem}} with {{Side Information}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {98--98},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100031},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBanditProblemSide2017a,
  title = {Bandit {{Problem}} with {{Side Observations}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {98--98},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100032},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBasicLemma2017,
  title = {Basic {{Lemma}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {98--98},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100033},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBatchLearning2017,
  title = {Batch {{Learning}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {98--99},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_58},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBaumWelchAlgorithm2017,
  title = {Baum-{{Welch Algorithm}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {99--99},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_59},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBayesAdaptiveMarkov2017,
  title = {Bayes {{Adaptive Markov Decision Processes}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {99--99},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100034},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBayesianModelAveraging2017,
  title = {Bayesian {{Model Averaging}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {106--106},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100038},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/HZEUWIXR/Sammut and Webb - 2017 - Bayesian Model Averaging.pdf}
}

@incollection{sammutBayesianNetwork2017,
  title = {Bayesian {{Network}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {106--107},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_927},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBayesNet2017,
  title = {Bayes {{Net}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {99--99},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100035},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBayesTheorem2017,
  title = {Bayes' {{Theorem}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {100--100},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100036},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBeamSearch2017,
  title = {Beam {{Search}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Sammut, Claude},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {120--120},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_68},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBehavioralCloning2017,
  title = {Behavioral {{Cloning}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Sammut, Claude},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {120--124},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_69},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBeliefStateMarkov2017,
  title = {Belief {{State Markov Decision Processes}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {125--125},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100039},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBellmanEquation2017,
  title = {Bellman {{Equation}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {125--125},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_930},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBias2017,
  title = {Bias},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {125--125},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_72},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBiasVarianceCovarianceDecomposition2017,
  title = {Bias-{{Variance-Covariance Decomposition}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {139--140},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_932},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBiasVarianceDecomposition2017,
  title = {Bias {{Variance Decomposition}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {128--129},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_74},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBilingualLexiconExtraction2017,
  title = {Bilingual {{Lexicon Extraction}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {140--140},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_78},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBinning2017,
  title = {Binning},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {140--140},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100040},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBlogMining2017,
  title = {Blog {{Mining}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {163--164},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_934},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBoosting2017,
  title = {Boosting},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {168--168},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_84},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBootstrapSampling2017,
  title = {Bootstrap {{Sampling}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {168--168},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_977},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBottomClause2017,
  title = {Bottom {{Clause}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {169--169},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_936},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBoundedDifferencesInequality2017,
  title = {Bounded {{Differences Inequality}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {169--169},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100041},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBP2017,
  title = {{{BP}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {169--169},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100042},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutBreakevenPoint2017,
  title = {Breakeven {{Point}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {169--169},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_937},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutCandidateEliminationAlgorithm2017,
  title = {Candidate-{{Elimination Algorithm}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {171--171},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_91},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{sammutCannotLinkConstraint2017,
  title = {Cannot-{{Link Constraint}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {171--171},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_938},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@book{sammutEncyclopediaMachineLearning2017,
  title = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/4P24ZFWV/Sammut and Webb - 2017 - Encyclopedia of Machine Learning and Data Mining.pdf}
}

@misc{sammutEncyclopediaMachineLearning2017a,
  title = {Encyclopedia of Machine Learning and Data Mining},
  author = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  publisher = {{Springer}},
  address = {{Boston, MA}},
  howpublished = {https://katalog.ub.uni-freiburg.de/link?kid=1658146808},
  isbn = {9781489976871},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/GKWWNURI/Search.html}
}

@incollection{sammutTesting2017,
  title = {A/{{B Testing}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {1--1},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_100507},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@inproceedings{saranyaEfficientFeatureSelection2021,
  title = {An {{Efficient Feature Selection Approach}} Using {{Sensitivity Analysis}} for {{Machine Learning}} Based {{Heart Desease Classification}}},
  booktitle = {2021 10th {{IEEE International Conference}} on {{Communication Systems}} and {{Network Technologies}} ({{CSNT}})},
  author = {Saranya, G. and Pravin, A.},
  year = {2021},
  month = jun,
  pages = {539--542},
  issn = {2329-7182},
  doi = {10.1109/CSNT51715.2021.9509673},
  abstract = {Feature Selection in machine learning is an important pre-processing task. The selection process involves selecting the attribute subset in the original selection set. It tries to identify and eliminate as much information as possible that is irrelevant and redundant. Redundant features help to incorrectly classify data. The removal of redundant characteristics thus reduces data size and computational complexity. It is non-trivial task to identify a good subset of features for effective classification. This paper focuses on the use of an analysis of feature sensitivity to determine the optimum feature subset using MATLAB with improved accuracy and sensitivity for classification. In comparison to the already well-known algorithms for wrapper selection, filter and embedded method, the effectiveness of the proposed algorithms is evaluated. The proposed approach to the selection of features using the Variance based Sensitivity (VSA) approach outperforms the wrapper selection with accuracy 87\% and sensitivity 90.12\%.},
  keywords = {attributes,Conferences,Feature extraction,Feature selection,Filtering algorithms,Heart,Machine learning,Machine learning algorithms,redundant features,Sensitivity,Sensitivity analysis},
  file = {/Users/tobias/Zotero/storage/IVQ2I535/Saranya and Pravin - 2021 - An Efficient Feature Selection Approach using Sens.pdf;/Users/tobias/Zotero/storage/46ZUX6SV/9509673.html}
}

@misc{sarkarTextAnalyticsPython2022,
  title = {Text {{Analytics}} with {{Python}} - 2nd {{Edition}}},
  author = {Sarkar, Dipanjan (DJ)},
  year = {2022},
  month = nov,
  abstract = {Learn how to process, classify, cluster, summarize, understand syntax, semantics and sentiment of text data with the power of Python! This repository contains code and datasets used in my book, "Text Analytics with Python" published by Apress/Springer.},
  copyright = {Apache-2.0}
}

@article{sauber-coleUseGenerativeAdversarial2022,
  title = {The Use of Generative Adversarial Networks to Alleviate Class Imbalance in Tabular Data: A Survey},
  shorttitle = {The Use of Generative Adversarial Networks to Alleviate Class Imbalance in Tabular Data},
  author = {{Sauber-Cole}, Rick and Khoshgoftaar, Taghi M.},
  year = {2022},
  month = aug,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {98},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00648-6},
  abstract = {The existence of class imbalance in a dataset can greatly bias the classifier towards majority classification. This discrepancy can pose a serious problem for deep learning models, which require copious and diverse amounts of data to learn patterns and output classifications. Traditionally, data-level and algorithm-level techniques have been instrumental in mitigating the adverse effect of class imbalance. With the recent development and proliferation of Generative Adversarial Networks (GANs), researchers across a variety of disciplines have adapted the architecture of GANs and implemented them on imbalanced datasets to generate instances of the underrepresented class(es). Though the bulk of research has been centered on the application of this methodology in computer vision tasks, GANs are likewise being appropriated for use in tabular data, or data consisting of rows and columns with traditional structured data types. In this survey paper, we assess the methodology and efficacy of these modifications on tabular datasets, across domains such network traffic classification and financial transactions over the past seven years. We examine what methodologies and experimental factors have resulted in the greatest machine learning efficacy, as well as the research works and frameworks which have proven most influential in the development of the application of GANs in tabular data settings. Specifically, we note the prevalence of the CGAN architecture, the optimality of novel methods with CNN learners and minority-class sensitive measures such as F1 score, the popularity of SMOTE as a baseline technique, and the improved performance in the year-over-year use of GANs in imbalanced tabular datasets.},
  keywords = {Class imbalance,Deep learning,Generative adversarial networks,Tabular data},
  file = {/Users/tobias/Zotero/storage/NB4U9E8T/Sauber-Cole and Khoshgoftaar - 2022 - The use of generative adversarial networks to alle.pdf}
}

@misc{saysPandasDataFrameTutorial2021,
  title = {Pandas {{DataFrame Tutorial}} - {{Beginner}}'s {{Guide}} to {{GPU Accelerated DataFrames}} in {{Python}}},
  author = {peter Says, Painting},
  year = {2021},
  month = mar,
  journal = {NVIDIA Technical Blog},
  abstract = {This post is the first installment of the series of introductions to the RAPIDS ecosystem. The series explores and discusses various aspects of RAPIDS that allow its users solve ETL (Extract\ldots},
  howpublished = {https://developer.nvidia.com/blog/pandas-dataframe-tutorial-beginners-guide-to-gpu-accelerated-dataframes-in-python/},
  langid = {american},
  keywords = {acceleration,cudf,gpu,nvidia,pandas,rapids},
  file = {/Users/tobias/Zotero/storage/K67W2Q68/pandas-dataframe-tutorial-beginners-guide-to-gpu-accelerated-dataframes-in-python.html}
}

@misc{ScalarsNumPyV1,
  title = {Scalars \textemdash{} {{NumPy}} v1.23 {{Manual}}},
  howpublished = {https://numpy.org/doc/stable/reference/arrays.scalars.html\#numpy.single},
  keywords = {deep learning,floating-point number types,numpy},
  file = {/Users/tobias/Zotero/storage/6TFLG2UR/arrays.scalars.html}
}

@article{schosserTensorExtrapolationAdaptation2022,
  title = {Tensor Extrapolation: An Adaptation to Data Sets with Missing Entries},
  shorttitle = {Tensor Extrapolation},
  author = {Schosser, Josef},
  year = {2022},
  month = feb,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {26},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00574-7},
  abstract = {Contemporary data sets are frequently relational in nature. In retail, for example, data sets are more granular than traditional data, often indexing individual products, outlets, or even users, rather than aggregating them at the group level. Tensor extrapolation is used to forecast relational time series data; it combines tensor decompositions and time series extrapolation. However, previous approaches to tensor extrapolation are restricted to complete data sets. This paper adapts tensor extrapolation to situations with missing entries and examines the method's performance in terms of forecast accuracy.},
  keywords = {Forecast accuracy,Missing values,Relational data,Tensor decomposition,Time series analysis},
  file = {/Users/tobias/Zotero/storage/EQ78B6WS/Schosser - 2022 - Tensor extrapolation an adaptation to data sets w.pdf;/Users/tobias/Zotero/storage/MFRUHDA2/articles.html}
}

@article{shafieiDetectionFickleTrolls2022,
  title = {Detection of Fickle Trolls in Large-Scale Online Social Networks},
  author = {Shafiei, Hossein and Dadlani, Aresh},
  year = {2022},
  month = feb,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {22},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00572-9},
  abstract = {Online social networks have attracted billions of active users over the past decade. These systems play an integral role in the everyday life of many people around the world. As such, these platforms are also attractive for misinformation, hoaxes, and fake news campaigns which usually utilize social trolls and/or social bots for propagation. Detection of so-called social trolls in these platforms is challenging due to their large scale and dynamic nature where users' data are generated and collected at the scale of multi-billion records per hour. In this paper, we focus on fickle trolls, i.e., a special type of trolling activity in which the trolls change their identity frequently to maximize their social relations. This kind of trolling activity may become irritating for the users and also may pose a serious threat to their privacy. To the best of our knowledge, this is the first work that introduces mechanisms to detect these trolls. In particular, we discuss and analyze troll detection mechanisms on different scales. We prove that the order of centralized single-machine detection algorithm is \$\$O(n\^3)\$\$which is slow and impractical for early troll detection in large-scale social platforms comprising of billions of users. We also prove that the streaming approach where data is gradually fed to the system is not practical in many real-world scenarios. In light of such shortcomings, we then propose a massively parallel detection approach. Rigorous evaluations confirm that our proposed method is at least six times faster compared to conventional parallel approaches.},
  keywords = {Large-scale networks,Online social networks,Troll detection},
  file = {/Users/tobias/Zotero/storage/XN5W69CE/Shafiei and Dadlani - 2022 - Detection of fickle trolls in large-scale online s.pdf;/Users/tobias/Zotero/storage/KLB8VIRL/articles.html}
}

@misc{shiftAnswerCombinationsElements2015,
  title = {Answer to "{{Combinations}} between Elements in Two Tuples in {{Python}}"},
  author = {Shift, Red},
  year = {2015},
  month = jun,
  journal = {Stack Overflow},
  keywords = {combinations,combinatorics,itertools,itertools.product},
  file = {/Users/tobias/Zotero/storage/HZMWKDY7/combinations-between-elements-in-two-tuples-in-python.html}
}

@incollection{shultzCascadeCorrelation2017,
  title = {Cascade {{Correlation}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Shultz, Thomas R. and Fahlman, Scott E.},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {171--180},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_33},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@inproceedings{sinhaStudyFeatureSelection2022,
  title = {A {{Study}} of {{Feature Selection}} and {{Extraction Algorithms}} for {{Cancer Subtype Prediction}}},
  booktitle = {2022 {{International Conference}} for {{Advancement}} in {{Technology}} ({{ICONAT}})},
  author = {Sinha, Vaibhav and Dash, Siladitya and Naskar, Nazma and Hossain, Sk Md Mosaddek},
  year = {2022},
  month = jan,
  pages = {1--6},
  doi = {10.1109/ICONAT53423.2022.9726007},
  abstract = {In this work, we study and analyze different feature selection algorithms that can be used to classify cancer subtypes in case of highly varying high-dimensional data. We apply three different feature selection methods on five different types of cancers having two separate omics each. We show that the existing feature selection methods are computationally expensive when applied individually. Instead, we apply these algorithms sequentially which helps in lowering the computational cost and improving the predictive performance. We further show that reducing the number of features using some dimension reduction techniques can improve the performance of machine learning models in some cases. We support our findings through comprehensive data analysis and visualization.},
  keywords = {Cancer Subtype,Computational modeling,Dimensionality reduction,Feature extraction,Feature Selection,Genomics,Machine Learning,Machine learning algorithms,Prediction algorithms,Sensitivity,Support Vector Classifier (SVC),The Cancer Genome Atlas (TCGA),Transcriptomics},
  file = {/Users/tobias/Zotero/storage/ZHRW6E5F/Sinha et al. - 2022 - A Study of Feature Selection and Extraction Algori.pdf;/Users/tobias/Zotero/storage/DBYUI6QQ/9726007.html}
}

@article{siriborvornratanakulHumanBehaviorImagebased2022,
  title = {Human Behavior in Image-Based {{Road Health Inspection Systems}} despite the Emerging {{AutoML}}},
  author = {Siriborvornratanakul, Thitirat},
  year = {2022},
  month = jul,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {96},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00646-8},
  abstract = {The emergence of automated machine learning or AutoML has raised an interesting trend of no-code and low-code machine learning where most tasks in the machine learning pipeline can possibly be automated without support from human data scientists. While it sounds reasonable that we should leave repetitive trial-and-error tasks of designing complex network architectures and tuning a lot of hyperparameters to AutoML, leading research using AutoML is still scarce. Thereby, the overall purpose of this case study is to investigate the gap between current AutoML frameworks and practical machine learning development.},
  keywords = {Artificial Intelligence,Automated Machine Learning,AutoML,Human Behavior,Machine Learning,Road Health Inspection},
  file = {/Users/tobias/Zotero/storage/TMJARCPG/Siriborvornratanakul - 2022 - Human behavior in image-based Road Health Inspecti.pdf}
}

@article{skoutaHemorrhageSemanticSegmentation2022,
  title = {Hemorrhage Semantic Segmentation in Fundus Images for the Diagnosis of Diabetic Retinopathy by Using a Convolutional Neural Network},
  author = {Skouta, Ayoub and Elmoufidi, Abdelali and {Jai-Andaloussi}, Said and Ouchetto, Ouail},
  year = {2022},
  month = jun,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {78},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00632-0},
  abstract = {Because retinal hemorrhage is one of the earliest symptoms of diabetic retinopathy, its accurate identification is essential for early diagnosis. One of the major obstacles ophthalmologists face in making a quick and effective diagnosis is viewing too many images to manually identify lesions of different shapes and sizes. To this end, researchers are working to develop an automated method for screening for diabetic retinopathy. This paper presents a modified CNN UNet architecture for identifying retinal hemorrhages in fundus images. Using the graphics processing unit (GPU) and the IDRiD dataset, the proposed UNet was trained to segment and detect potential areas that may harbor retinal hemorrhages. The experiment was also tested using the IDRiD and DIARETDB1 datasets, both freely available on the Internet. We applied preprocessing to improve the image quality and increase the data, which play an important role in defining the complex features involved in the segmentation task. A significant improvement was then observed in the learning neural network that was able to effectively segment the bleeding and achieve sensitivity, specificity and accuracy of 80.49\%, 99.68\%, and 98.68\%, respectively. The experimental results also yielded an IoU of 76.61\% and a Dice value of 86.51\%, showing that the predictions obtained by the network are effective and can significantly reduce the efforts of ophthalmologists. The results revealed a significant increase in the diagnostic performance of one of the most important retinal disorders caused by diabetes.},
  keywords = {Artificial intelligence,CAD system,Convolutional neural networks,Deep learning,Detection,Diabetic retinopathy,Fundus images,Segmentation},
  file = {/Users/tobias/Zotero/storage/57IFKTRX/Skouta et al. - 2022 - Hemorrhage semantic segmentation in fundus images .pdf}
}

@article{smithComparingTraditionalNews2022,
  title = {Comparing Traditional News and Social Media with Stock Price Movements; Which Comes First, the News or the Price Change?},
  author = {Smith, Stephen and O'Hare, Anthony},
  year = {2022},
  month = apr,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {47},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00591-6},
  abstract = {Twitter has been responsible for some major stock market news in the recent past, from rogue CEOs damaging their company to very active world leaders asking for brand boycotts, but despite its impact Twitter has still not been as impactful on markets as traditional news sources. In this paper we examine whether daily news sentiment of several companies and Twitter sentiment from their CEOs have an impact on their market performance and whether traditional news sources and Twitter activity of heads of government impact the benchmark indexes of major world economies over a period spanning the outbreak of the SAR-COV-2 pandemic. Our results indicate that there is very limited correlation between Twitter sentiment and price movements and that this does not change much when returns are taken relative to the market or when the market is calm or turbulent. There is almost no correlation under any circumstances between non-financial news sources and price movements, however there is some correlation between financial news sentiment and stock price movements. We also find this correlation gets stronger when returns are taken relative to the market. There are fewer companies correlated in both turbulent and calm economic times. There is no clear pattern to the direction and strength of the correlation, with some being strongly negatively correlated and others being strongly positively correlated, but in general the size of the correlation tends to indicate that price movement is driving sentiment, except in the turbulent economic times of the SARS-COV-2 pandemic in 2020.},
  keywords = {Sentiment analysis,Stock market,Twitter},
  file = {/Users/tobias/Zotero/storage/XQ3NMR7B/Smith and O’Hare - 2022 - Comparing traditional news and social media with s.pdf;/Users/tobias/Zotero/storage/QIETJSCH/articles.html}
}

@misc{soganiAnswerCombinationsElements2015,
  title = {Answer to "{{Combinations}} between Elements in Two Tuples in {{Python}}"},
  author = {Sogani, Naman},
  year = {2015},
  month = jun,
  journal = {Stack Overflow},
  keywords = {combinations,combinatorics,itertools,itertools.product},
  file = {/Users/tobias/Zotero/storage/RCHZV2JS/combinations-between-elements-in-two-tuples-in-python.html}
}

@book{sohilIntroductionStatisticalLearning2021,
  title = {An Introduction to Statistical Learning with Applications in {{R}}: By {{Gareth James}}, {{Daniela Witten}}, {{Trevor Hastie}}, and {{Robert Tibshirani}}, {{New York}}, {{Springer Science}} and {{Business Media}}, 2013, \$41.98, {{eISBN}}: 978-1-4614-7137-7},
  shorttitle = {An Introduction to Statistical Learning with Applications in {{R}}},
  author = {Sohil, Fariha and Sohali, Muhammad Umair and Shabbir, Javid},
  year = {2021},
  month = sep,
  langid = {english},
  keywords = {beginner level,introduction,no probability theory},
  file = {/Users/tobias/Zotero/storage/AF4SBFVP/Sohil_et_al-2021-An_introduction_to_statistical_learning_with_appli.pdf}
}

@book{SolvingLargeScale,
  title = {Solving {{Large Scale Learning Tasks}}. {{Challenges}} and {{Algorithms}}},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/HWXJ83ZU/978-3-319-41706-6.html}
}

@article{sooknananEstimatingCarbonContent2022,
  title = {Estimating the Carbon Content of Oceans Using Satellite Sensor Data},
  author = {Sooknanan, Aadidev and Hosein, Patrick},
  year = {2022},
  month = jul,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {93},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00647-7},
  abstract = {The impact of chemical processes in ocean surface waters is far-reaching. Recently, increased significance has been placed on the concentration of Carbon and its compounds and the effects these may have on climate change. Remote-sensing enables near real-time measurement of key sea-surface data which can be used to estimate Carbon levels. We illustrate with the use of hybrid Satellite sensor data. To validate our results we use data collected from cruise ships as the ground truth when training our algorithms. The error rate of our predictor is found to be small and hence the proposed approach can be used to estimate Carbon levels in any ocean. This work improves upon previous research in many ways including the use of sea water salinity as a proxy for Carbon estimates. Binary combinations of typically unary predictor attributes are used for the purposes of predicting the Carbon content of surface water and an inherently non-linear model is used to quantify the relationship.},
  keywords = {Artificial Intelligence,Carbon emissions,Climate change,Ocean acidification,Remote sensing},
  file = {/Users/tobias/Zotero/storage/JJYF9WYU/Sooknanan and Hosein - 2022 - Estimating the carbon content of oceans using sate.pdf}
}

@misc{StatisticalMethodsMachine,
  title = {Statistical\_methods\_for\_machine\_learning.Pdf},
  file = {/Users/tobias/Zotero/storage/D2U394FZ/statistical_methods_for_machine_learning.pdf}
}

@incollection{strehlAssociativeReinforcementLearning2017,
  title = {Associative {{Reinforcement Learning}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Strehl, Alexander L.},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {71--73},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_40},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@article{subaktiPerformanceBERTData2022,
  title = {The Performance of {{BERT}} as Data Representation of Text Clustering},
  author = {Subakti, Alvin and Murfi, Hendri and Hariadi, Nora},
  year = {2022},
  month = feb,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {15},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00564-9},
  abstract = {Text clustering is the task of grouping a set of texts so that text in the same group will be more similar than those from a different group. The process of grouping text manually requires a significant amount of time and labor. Therefore, automation utilizing machine learning is necessary. One of the most frequently used method to represent textual data is Term Frequency Inverse Document Frequency (TFIDF). However, TFIDF cannot consider the position and context of a word in a sentence. Bidirectional Encoder Representation from Transformers (BERT) model can produce text representation that incorporates the position and context of a word in a sentence. This research analyzed the performance of the BERT model as data representation for text. Moreover, various feature extraction and normalization methods are also applied for the data representation of the BERT model. To examine the performances of BERT, we use four clustering algorithms, i.e., k-means clustering, eigenspace-based fuzzy c-means, deep embedded clustering, and improved deep embedded clustering. Our simulations show that BERT outperforms TFIDF method in 28 out of 36 metrics. Furthermore, different feature extraction and normalization produced varied performances. The usage of these feature extraction and normalization must be altered depending on the text clustering algorithm used.},
  keywords = {BERT,Deep learning,Representation learning,Text clustering,Unsupervised learning},
  file = {/Users/tobias/Zotero/storage/WLDYYXEK/Subakti et al. - 2022 - The performance of BERT as data representation of .pdf;/Users/tobias/Zotero/storage/NWY4ZZSZ/articles.html}
}

@article{szegedyInceptionv4InceptionResNetImpact2017,
  title = {Inception-v4, {{Inception-ResNet}} and the {{Impact}} of {{Residual Connections}} on {{Learning}}},
  author = {Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent and Alemi, Alexander},
  year = {2017},
  month = feb,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {31},
  number = {1},
  issn = {2374-3468, 2159-5399},
  doi = {10.1609/aaai.v31i1.11231},
  abstract = {Very deep convolutional networks have been central to the largest advances in image recognition performance in recent years. One example is the Inception architecture that has been shown to achieve very good performance at relatively low computational cost. Recently, the introduction of residual connections in conjunction with a more traditional architecture has yielded state-of-the-art performance in the 2015 ILSVRC challenge; its performance was similar to the latest generation Inception-v3 network. This raises the question of whether there are any benefit in combining the Inception architecture with residual connections. Here we give clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly. There is also some evidence of residual Inception networks outperforming similarly expensive Inception networks without residual connections by a thin margin. We also present several new streamlined architectures for both residual and non-residual Inception networks. These variations improve the single-frame recognition performance on the ILSVRC 2012 classification task significantly. We further demonstrate how proper activation scaling stabilizes the training of very wide residual Inception networks. With an ensemble of three residual and one Inception-v4, we achieve 3.08\% top-5 error on the test set of the ImageNet classification (CLS) challenge.},
  langid = {english},
  keywords = {⛔ No DOI found},
  file = {/Users/tobias/Zotero/storage/8YWS8CN6/Szegedy et al. - 2017 - Inception-v4, Inception-ResNet and the Impact of R.pdf;/Users/tobias/Zotero/storage/FJPYE72G/Szegedy et al. - 2016 - Inception-v4, Inception-ResNet and the Impact of R.pdf;/Users/tobias/Zotero/storage/Y2HFS9I9/forum.html}
}

@incollection{tadepalliAverageRewardReinforcementLearning2017,
  title = {Average-{{Reward Reinforcement Learning}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Tadepalli, Prasad},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {87--92},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_17},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@article{taiMachineLearningModel2022,
  title = {Machine Learning Model for Malaria Risk Prediction Based on Mutation Location of Large-Scale Genetic Variation Data},
  author = {Tai, Kah Yee and Dhaliwal, Jasbir},
  year = {2022},
  month = jun,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {85},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00635-x},
  abstract = {In recent malaria research, the complexity of the disease has been explored using machine learning models via blood smear images, environmental, and even RNA-Seq data. However, a machine learning model based on genetic variation data is still required to fully explore individual malaria risk. Furthermore, many Genome-Wide Associations Studies (GWAS) have associated specific genetic markers, i.e., single nucleotide polymorphisms (SNPs), with malaria. Thus, the present study improves the current state-of-the-art genetic risk score by incorporating SNPs mutation location on large-scale genetic variation data obtained from GWAS. Nevertheless, it becomes computationally expensive for hyperparameter optimization on large-scale datasets. Therefore, this study proposes a machine learning model that incorporates mutation location as well as a Genetic Algorithm (GA) to optimize hyperparameters. Besides that, a deep learning model is also proposed to predict individual malaria risk as an alternative approach. The analysis is performed on the Malaria Genomic Epidemiology Network (MalariaGEN) dataset comprising 20,817 individuals from 11 populations. The findings of this study demonstrated that the proposed GA could overcome the curse of dimensionality and improve resource efficiency compared to commonly used methods. In addition, incorporating the mutation location significantly improved the machine learning models in predicting the individual malaria risk; a Mean Absolute Error (MAE) score of 8.00E-06. Moreover, the deep learning model obtained almost similar MAE scores to the machine learning models, indicating an alternative approach. Thus, this study provides relevant knowledge of genetic and technical deliberations that can improve the state-of-the-art methods for predicting individual malaria risk.},
  keywords = {Deep learning model,Genetic algorithm,Genetic markers,Hyperparameter optimization,Machine learning prediction model,Malaria,Risk score},
  file = {/Users/tobias/Zotero/storage/RMU33BSN/Tai and Dhaliwal - 2022 - Machine learning model for malaria risk prediction.pdf}
}

@misc{teamHowTrainTopic,
  title = {How to Train a {{Topic Tagging}} Model to Assign High-Quality Topics\ldots{} \textendash{} {{Towards AI}}},
  author = {Team, Towards AI},
  abstract = {Originally published on Towards AI the World's Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider...},
  langid = {american},
  file = {/Users/tobias/Zotero/storage/7LNGKY7U/how-to-train-a-topic-tagging-model-to-assign-high-quality-topics-to-articles.html}
}

@article{tharaSocialMediaText2022,
  title = {Social Media Text Analytics of {{Malayalam}}\textendash{{English}} Code-Mixed Using Deep Learning},
  author = {Thara, S. and Poornachandran, Prabaharan},
  year = {2022},
  month = apr,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {45},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00594-3},
  abstract = {Zigzag conversational patterns of contents in social media are often perceived as noisy or informal text. Unrestricted usage of vocabulary in social media communications complicates the processing of code-mixed text. This paper accentuates two major aspects of code mixed text: Offensive Language Identification and Sentiment Analysis for Malayalam\textendash English code-mixed data set. The proffered framework addresses 3 key points apropos these tasks\textemdash dependencies among features created by embedding methods (Word2Vec and FastText), comparative analysis of deep learning algorithms (uni-/bi-directional models, hybrid models, and transformer approaches), relevance of selective translation and transliteration and hyper-parameter optimization\textemdash which ensued in F1-Scores (model's accuracy) of 0.76 for Forum for Information Retrieval Evaluation (FIRE) 2020 and 0.99 for European Chapter of the Association for Computational Linguistics (EACL) 2021 data sets. A detailed error analysis was also done to give meaningful insights. The submitted strategy turned in the best results among the benchmarked models dealing with Malayalam\textendash English code-mixed messages and it serves as an important step towards societal good.},
  keywords = {Deep neural network,Dravidian languages,Multilingual language,Natural Language Processing},
  file = {/Users/tobias/Zotero/storage/H8CIMNGQ/Thara and Poornachandran - 2022 - Social media text analytics of Malayalam–English c.pdf;/Users/tobias/Zotero/storage/7YW8S5IV/articles.html}
}

@misc{thiefmasterAnswerCombinationsElements2015,
  title = {Answer to "{{Combinations}} between Elements in Two Tuples in {{Python}}"},
  author = {ThiefMaster},
  year = {2015},
  month = jun,
  journal = {Stack Overflow},
  keywords = {combinations,combinatorics,itertools,itertools.product},
  file = {/Users/tobias/Zotero/storage/IZXTIUGK/combinations-between-elements-in-two-tuples-in-python.html}
}

@misc{TimeSeriesForecasting,
  title = {Time\_series\_forecasting\_with\_python.Pdf},
  file = {/Users/tobias/Zotero/storage/XVSIC8FW/time_series_forecasting_with_python.pdf}
}

@incollection{timmisArtificialImmuneSystems2017,
  title = {Artificial {{Immune Systems}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Timmis, Jon},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {61--65},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_919},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{toivonenAprioriAlgorithm2017,
  title = {Apriori {{Algorithm}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Toivonen, Hannu},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {60--60},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_27},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{toivonenAssociationRule2017,
  title = {Association {{Rule}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Toivonen, Hannu},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {70--71},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_38},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{toivonenBasketAnalysis2017,
  title = {Basket {{Analysis}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Toivonen, Hannu},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {98--98},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_926},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@misc{TPOT,
  title = {{{TPOT}}},
  howpublished = {http://epistasislab.github.io/tpot/},
  keywords = {automation,candidate model,pipeline,tpot},
  file = {/Users/tobias/Zotero/storage/SSFI7JP6/tpot.html}
}

@misc{trevettPyTorchImageClassification2022,
  title = {{{PyTorch Image Classification}}},
  author = {Trevett, Ben},
  year = {2022},
  month = apr,
  abstract = {Tutorials on how to implement a few key architectures for image classification using PyTorch and TorchVision.},
  copyright = {MIT},
  keywords = {alexnet,cnn,convolutional-networks,convolutional-neural-network,convolutional-neural-networks,image-classification,lenet,pytorch,pytorch-cnn,pytorch-implementation,pytorch-implmention,pytorch-tutorial,pytorch-tutorials,resnet,torchvision,tutorial,vgg}
}

@misc{user2738777AnswerCombinationsElements2015,
  title = {Answer to "{{Combinations}} between Elements in Two Tuples in {{Python}}"},
  author = {{user2738777}},
  year = {2015},
  month = jun,
  journal = {Stack Overflow},
  keywords = {combinations,combinatorics,itertools,itertools.product},
  file = {/Users/tobias/Zotero/storage/AJXDRH9B/combinations-between-elements-in-two-tuples-in-python.html}
}

@article{vanderplasPythonDataScience,
  title = {Python {{Data Science Handbook}}},
  author = {VanderPlas, Jake},
  pages = {548},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/EB5BUTZ9/VanderPlas - Python Data Science Handbook.pdf}
}

@article{vertiganComputationalComplexityTutte2005,
  title = {The {{Computational Complexity}} of {{Tutte Invariants}} for {{Planar Graphs}}},
  author = {Vertigan, Dirk},
  year = {2005},
  month = jan,
  journal = {SIAM Journal on Computing},
  volume = {35},
  number = {3},
  pages = {690--712},
  issn = {0097-5397, 1095-7111},
  doi = {10.1137/S0097539704446797},
  langid = {english},
  keywords = {\#nosource}
}

@article{vranopoulosAddressingBigData2022,
  title = {Addressing Big Data Variety Using an Automated Approach for Data Characterization},
  author = {Vranopoulos, Georgios and Clarke, Nathan and Atkinson, Shirley},
  year = {2022},
  month = jan,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {8},
  issn = {2196-1115},
  doi = {10.1186/s40537-021-00554-3},
  abstract = {The creation of new knowledge from manipulating and analysing existing knowledge is one of the primary objectives of any cognitive system. Most of the effort on Big Data research has been focussed upon Volume and Velocity, while Variety, ``the ugly duckling'' of Big Data, is often neglected and difficult to solve. A principal challenge with Variety is being able to understand and comprehend the data. This paper proposes and evaluates an automated approach for metadata identification and enrichment in describing Big Data. The paper focuses on the use of self-learning systems that will enable automatic compliance of data against regulatory requirements along with the capability of generating valuable and readily usable metadata towards data classification. Two experiments towards data confidentiality and data identification were conducted in evaluating the feasibility of the approach. The focus of the experiments was to confirm that repetitive manual tasks can be automated, thus reducing the focus of a Data Scientist on data identification and thereby providing more focus towards the extraction and analysis of the data itself. The origin of the datasets used were Private/Business and Public/Governmental and exhibited diverse characteristics in relation to the number of files and size of the files. The experimental work confirmed that: (a) the use of algorithmic techniques attributed to the substantial decrease in false positives regarding the identification of confidential information; (b) evidence that the use of a fraction of a data set along with statistical analysis and supervised learning is sufficient in identifying the structure of information within it. With this approach, the issues of understanding the nature of data can be mitigated, enabling a greater focus on meaningful interpretation of the heterogeneous data.},
  keywords = {Big Data,Contextual integrity,Data characterization,Data confidentiality,Data Format,Data origination,Delimiter determination,Metadata,Variety},
  file = {/Users/tobias/Zotero/storage/ZYXPWJGH/Vranopoulos et al. - 2022 - Addressing big data variety using an automated app.pdf;/Users/tobias/Zotero/storage/3KYGW6G7/articles.html}
}

@incollection{webbAlgorithmEvaluation2017,
  title = {Algorithm {{Evaluation}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Webb, Geoffrey I.},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {40--41},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_18},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@incollection{webbBayesRule2017,
  title = {Bayes' {{Rule}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Webb, Geoffrey I.},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {99--99},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_21},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@misc{weiaicunzaiAwesomeImageClassification2022,
  title = {Awesome - {{Image Classification}}},
  author = {{weiaicunzai}},
  year = {2022},
  month = apr,
  abstract = {A curated list of deep learning image classification papers and codes},
  keywords = {awesome,awesome-list,computer-vision,deep-learning,image-classification,papers}
}

@misc{WhatDifferenceFP16,
  title = {What Is the Difference between {{FP16}} and {{FP32}} When Doing Deep Learning?},
  journal = {Quora},
  abstract = {Answer (1 of 2): This is a well-timed question, as we just added FP16 support to Horovod last Friday. So naturally, I'm itching to talk more about it! The value proposition when using FP16 for training a deep neural network is significantly faster training times without ``any'' loss in performance...},
  howpublished = {https://www.quora.com/What-is-the-difference-between-FP16-and-FP32-when-doing-deep-learning},
  langid = {english},
  keywords = {bfp16,binary representation,difference,floating point number,fp16,fp32,quora,theory,understanding},
  file = {/Users/tobias/Zotero/storage/NNM6RNZR/What-is-the-difference-between-FP16-and-FP32-when-doing-deep-learning.html}
}

@misc{whuberAnswerHowWould2011,
  title = {Answer to "{{How}} Would You Explain Covariance to Someone Who Understands Only the Mean?"},
  shorttitle = {Answer to "{{How}} Would You Explain Covariance to Someone Who Understands Only the Mean?},
  author = {{whuber}},
  year = {2011},
  month = nov,
  journal = {Cross Validated},
  file = {/Users/tobias/Zotero/storage/9CSPMC57/how-would-you-explain-covariance-to-someone-who-understands-only-the-mean.html}
}

@article{wibawaTimeseriesAnalysisSmoothed2022,
  title = {Time-Series Analysis with Smoothed {{Convolutional Neural Network}}},
  author = {Wibawa, Aji Prasetya and Utama, Agung Bella Putra and Elmunsyah, Hakkun and Pujianto, Utomo and Dwiyanto, Felix Andika and Hernandez, Leonel},
  year = {2022},
  month = apr,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {44},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00599-y},
  abstract = {CNN originates from image processing and is not commonly known as a forecasting technique in time-series analysis which depends on the quality of input data. One of the methods to improve the quality is by smoothing the data. This study introduces a novel hybrid exponential smoothing using CNN called Smoothed-CNN (S-CNN). The method of combining tactics outperforms the majority of individual solutions in forecasting. The S-CNN was compared with the original CNN method and other forecasting methods such as Multilayer Perceptron (MLP) and Long Short-Term Memory (LSTM). The dataset is a year time-series of daily website visitors. Since there are no special rules for using the number of hidden layers, the Lucas number was used. The results show that S-CNN is better than MLP and LSTM, with the best MSE of 0.012147693 using 76 hidden layers at 80\%:20\% data composition.},
  keywords = {CNN,Exponential smoothing,Optimum smoothing factor,Time-series},
  file = {/Users/tobias/Zotero/storage/KNU9J6LK/Wibawa et al. - 2022 - Time-series analysis with smoothed Convolutional N.pdf;/Users/tobias/Zotero/storage/BIXY3C72/articles.html}
}

@book{wickhamDataScienceImport2017,
  title = {R for {{Data Science}}: {{Import}}, {{Tidy}}, {{Transform}}, {{Visualize}}, and {{Model Data}}},
  shorttitle = {R for {{Data Science}}},
  author = {Wickham, Hadley and Grolemund, Garrett},
  year = {2017},
  month = jan,
  edition = {1 edition},
  publisher = {{O'Reilly Media}},
  address = {{Sebastopol, CA}},
  abstract = {Learn how to use R to turn raw data into insight, knowledge, and understanding. This book introduces you to R, RStudio, and the tidyverse, a collection of R packages designed to work together to make data science fast, fluent, and fun. Suitable for readers with no previous programming experience, R for Data Science is designed to get you doing data science as quickly as possible.Authors Hadley Wickham and Garrett Grolemund guide you through the steps of importing, wrangling, exploring, and modeling your data and communicating the results. You'll get a complete, big-picture understanding of the data science cycle, along with basic tools you need to manage the details. Each section of the book is paired with exercises to help you practice what you've learned along the way.You'll learn how to:Wrangle\textemdash transform your datasets into a form convenient for analysisProgram\textemdash learn powerful R tools for solving data problems with greater clarity and easeExplore\textemdash examine your data, generate hypotheses, and quickly test themModel\textemdash provide a low-dimensional summary that captures true "signals" in your datasetCommunicate\textemdash learn R Markdown for integrating prose, code, and results},
  isbn = {978-1-4919-1039-9},
  langid = {english}
}

@article{wongsoPretrainedTransformerbasedLanguage2022,
  title = {Pre-Trained Transformer-Based Language Models for {{Sundanese}}},
  author = {Wongso, Wilson and Lucky, Henry and Suhartono, Derwin},
  year = {2022},
  month = apr,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {39},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00590-7},
  abstract = {The Sundanese language has over 32 million speakers worldwide, but the language has reaped little to no benefits from the recent advances in natural language understanding. Like other low-resource languages, the only alternative is to fine-tune existing multilingual models. In this paper, we pre-trained three monolingual Transformer-based language models on Sundanese data. When evaluated on a downstream text classification task, we found that most of our monolingual models outperformed larger multilingual models despite the smaller overall pre-training data. In the subsequent analyses, our models benefited strongly from the Sundanese pre-training corpus size and do not exhibit socially biased behavior. We released our models for other researchers and practitioners to use.},
  keywords = {Low-resource Language,Natural Language Understanding,Sundanese Language,Transformers},
  file = {/Users/tobias/Zotero/storage/VVG8NBVZ/Wongso et al. - 2022 - Pre-trained transformer-based language models for .pdf;/Users/tobias/Zotero/storage/7NGCX3UF/articles.html}
}

@misc{wrightAnswerHowWould2015,
  title = {Answer to "{{How}} Would You Explain Covariance to Someone Who Understands Only the Mean?"},
  shorttitle = {Answer to "{{How}} Would You Explain Covariance to Someone Who Understands Only the Mean?},
  author = {Wright, Kevin},
  year = {2015},
  month = aug,
  journal = {Cross Validated},
  file = {/Users/tobias/Zotero/storage/P6GZKN8W/how-would-you-explain-covariance-to-someone-who-understands-only-the-mean.html}
}

@article{wuTumorAntigensImmune2022,
  title = {Tumor Antigens and Immune Subtypes of Glioblastoma: The Fundamentals of {{mRNA}} Vaccine and Individualized Immunotherapy Development},
  shorttitle = {Tumor Antigens and Immune Subtypes of Glioblastoma},
  author = {Wu, Changwu and Qin, Chaoying and Long, Wenyong and Wang, Xiangyu and Xiao, Kai and Liu, Qing},
  year = {2022},
  month = jul,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {92},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00643-x},
  abstract = {Glioblastoma (GBM) is the most common primary brain tumor in adults and is notorious for its lethality. Given its limited therapeutic measures and high heterogeneity, the development of new individualized therapies is important. mRNA vaccines have exhibited promising performance in a variety of solid tumors, those designed for glioblastoma (GBM) need further development. The aim of this study is to explore tumor antigens for the development of mRNA vaccines against GBM and to identify potential immune subtypes of GBM to identify the patients suitable for different immunotherapies.},
  keywords = {Glioblastoma,Immune subtypes,Individualized immunotherapy,mRNA vaccines,Tumor microenvironment},
  file = {/Users/tobias/Zotero/storage/ML889SPD/Wu et al. - 2022 - Tumor antigens and immune subtypes of glioblastoma.pdf}
}

@misc{wuzheShenDuXueXiZaiTuXiangChuLiZhongDeYingYongJiaoCheng2022,
  title = {深度学习在图像处理中的应用教程},
  author = {WuZhe},
  year = {2022},
  month = apr,
  abstract = {deep learning for image processing including classification and object-detection etc.},
  keywords = {bilibili,classification,deep-learning,object-detection,pytorch,segmentation,tensorflow2}
}

@misc{XGBoostParametersXgboosta,
  title = {{{XGBoost Parameters}} \textemdash{} Xgboost 1.6.2 Documentation},
  howpublished = {https://xgboost.readthedocs.io/en/stable/parameter.html},
  keywords = {gpu,gpu doc page,gpu_hist,tree,xgboost},
  file = {/Users/tobias/Zotero/storage/R5KNCTLX/parameter.html}
}

@misc{XgboostPythonPdf,
  title = {Xgboost\_with\_python.Pdf},
  file = {/Users/tobias/Zotero/storage/M7FA5JID/xgboost_with_python.pdf}
}

@misc{yangSupervisedFeatureSelection2022,
  title = {On {{Supervised Feature Selection}} from {{High Dimensional Feature Spaces}}},
  author = {Yang, Yijing and Wang, Wei and Fu, Hongyu and Kuo, C.-C. Jay},
  year = {2022},
  month = apr,
  number = {arXiv:2203.11924},
  eprint = {2203.11924},
  eprinttype = {arxiv},
  primaryclass = {cs},
  institution = {{arXiv}},
  doi = {10.48550/arXiv.2203.11924},
  abstract = {The application of machine learning to image and video data often yields a high dimensional feature space. Effective feature selection techniques identify a discriminant feature subspace that lowers computational and modeling costs with little performance degradation. A novel supervised feature selection methodology is proposed for machine learning decisions in this work. The resulting tests are called the discriminant feature test (DFT) and the relevant feature test (RFT) for the classification and regression problems, respectively. The DFT and RFT procedures are described in detail. Furthermore, we compare the effectiveness of DFT and RFT with several classic feature selection methods. To this end, we use deep features obtained by LeNet-5 for MNIST and Fashion-MNIST datasets as illustrative examples. It is shown by experimental results that DFT and RFT can select a lower dimensional feature subspace distinctly and robustly while maintaining high decision performance.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/tobias/Zotero/storage/2DCWHHSX/Yang et al. - 2022 - On Supervised Feature Selection from High Dimensio.pdf;/Users/tobias/Zotero/storage/R8WMVWPY/2203.html}
}

@article{yaniBetterEntityDetection2022,
  title = {A Better Entity Detection of Question for Knowledge Graph Question Answering through Extracting Position-Based Patterns},
  author = {Yani, Mohammad and Krisnadhi, Adila Alfa and Budi, Indra},
  year = {2022},
  month = jun,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {80},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00631-1},
  abstract = {Entity detection task on knowledge graph question answering systems has been studied well on simple questions. However, the task is still challenging on complex questions. It is due to a complex question is composed of more than one fact or triple. This paper proposes a method to detect entities and their position on triples mentioned in a question. Unlike existing approaches that only focus on detecting the entity name, our method can determine in which triple an entity is located. Furthermore, our approach can also define if an entity is a head or a tail of a triple mentioned in a question. We tested our approach to SimpleQuestions, LC-QuAD~2.0, and QALD series benchmarks. The experiment result demonstrates that our model outperforms the previous works on SimpleQuestions and QALD series datasets. 99.15\% accuracy and 96.15\% accuracy on average, respectively. Our model can also improve entity detection performance on LC-QuAD 2.0 with a merged dataset, namely, 97.4\% accuracy. This paper also presents Wikidata QALD series version that is helpful for researchers to assess the knowledge graph question answering system they develop.},
  keywords = {Complex question,Entity detection,Entity recognition,Knowledge graph question answering,Question pattern},
  file = {/Users/tobias/Zotero/storage/WRQD4FUT/Yani et al. - 2022 - A better entity detection of question for knowledg.pdf}
}

@article{yeExploringFormBig2022,
  title = {Exploring the Form of Big Data Products and the Supporting Systems},
  author = {Ye, Yazhen and Zhang, Yao and Zhu, Yangyong},
  year = {2022},
  month = apr,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {48},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00604-4},
  abstract = {There have been studies and practices about forms and supporting systems of single-type data products. However, little literature is dedicated to these factors of big data products, which are huge in volume and contain a variety of different types of data. For example, we do not know the form of data composed of a relation table and a digital video file at the same time. The lack of certain forms of big data products makes it impossible to design its base unit for measuring. It also causes difficulties in pricing and valuation of big data products, and further causes issues of circulation and supporting services. In this paper, we analyze the challenges of productizing big data. By referring to information media such as books, a product form and supporting systems of big data products based on Data Box are proposed. Different from previous studies, we focus on the system-level design and systematically study the pipeline including containerization, circulation, pricing, protection and etc. The proposed Data Box-based big data products and supporting systems can have a positive influence on the research, exploitation, exchange, and circulation of big data products.},
  keywords = {Big data products,Data Box,Data circulation},
  file = {/Users/tobias/Zotero/storage/8I4PY7NT/Ye et al. - 2022 - Exploring the form of big data products and the su.pdf;/Users/tobias/Zotero/storage/YRILM4JK/articles.html}
}

@article{yunitaEverythingDataOne2022,
  title = {`{{Everything}} Is Data': Towards One Big Data Ecosystem Using Multiple Sources of Data on Higher Education in {{Indonesia}}},
  shorttitle = {`{{Everything}} Is Data'},
  author = {Yunita, Ariana and Santoso, Harry B. and Hasibuan, Zainal A.},
  year = {2022},
  month = jul,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {91},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00639-7},
  abstract = {Big data is increasingly being promoted as a game changer for the future of science, as the volume of data has exploded in recent years. Big data characterized, among others, the data comes from multiple sources, multi-format, comply to 5-V's in nature (value, volume, velocity, variety, and veracity). Big data also constitutes structured data, semi-structured data, and unstructured-data. These characteristics of big data formed ``big data ecosystem'' that have various active nodes involved. Regardless such complex characteristics of big data, the studies show that there exists inherent structure that can be very useful to provide meaningful solutions for various problems. One of the problems is anticipating proper action to students' achievement. It is common practice that lecturer treat his/her class with ``one-size-fits-all'' policy and strategy. Whilst, the degree of students' understanding, due to several factors, may not the same. Furthermore, it is often too late to take action to rescue the student's achievement in trouble. This study attempted to gather all possible features involved from multiple data sources: national education databases, reports, webpages and so forth. The multiple data sources comprise data on undergraduate students from 13 provinces in Indonesia, including students' academic histories, demographic profiles and socioeconomic backgrounds and institutional information (i.e. level of accreditation, programmes of study, type of university, geographical location). Gathered data is furthermore preprocessed using various techniques to overcome missing value, data categorisation, data consistency, data quality assurance, to produce relatively clean and sound big dataset. Principal component analysis (PCA) is employed in order to reduce dimensions of big dataset and furthermore use K-Means methods to reveal clusters (inherent structure) that may occur in that big dataset. There are 7 clusters suggested by K-Means analysis: 1. very low-risk students, 2. low-risk students, 3. moderate-risk students, 4. fluctuating-risk students, 5. high risk students, 6. very high-risk students and, 7. fail students. Among the clusters unreveal, (1) a gap between public universities and private universities across the three regions in Indonesia, (2) a gap between STEM and non-STEM programmes of study, (3) a gap between rural versus urban, (4) a gap of accreditation status, (5) a gap of quality human resources distribution, etc. Further study, we will use the characteristics of each cluster to predict students' achievement based on students' profiles, and provide solutions and interventions strategies for students to improve their likely success.},
  keywords = {Big data,Data collection,Data preprocessing,Higher education,Indonesia},
  file = {/Users/tobias/Zotero/storage/AGGR2USH/Yunita et al. - 2022 - ‘Everything is data’ towards one big data ecosyst.pdf}
}

@article{yuTrafficFlowPrediction2022,
  title = {Traffic Flow Prediction Based on Depthwise Separable Convolution Fusion Network},
  author = {Yu, Yue and Sun, Wei and Liu, Jianhua and Zhang, Changfan},
  year = {2022},
  month = jun,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {83},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00637-9},
  abstract = {Traffic flow prediction is an important part of an intelligent transportation system to alleviate congestion. In practice, most small and medium-sized activities are not given priority in transport planning, yet these activities often bring about a surge in demand for public transport. It is recognized that such patterns are inevitably more difficult to predict than those associated with day-to-day mobility, and that forecasting models built using traffic data alone are not comprehensive enough. Aiming at this problem, a depthwise separable convolutional fusion forecast network (FFN) was proposed by focusing on the impact of event information on traffic flow demand. FFN fused heterogeneous data to model traffic data, weather information, and event information extracted from the Internet. The depthwise separable one-dimensional convolution was used to encode the textual information describing the event layer by layer, and local one-dimensional sequence segments (ie subsequences) were extracted from the sequence to retain rich local semantic features. In the modeling process, the interaction of heterogeneous data was established, that is, the temporal and other data were used to drive the textual information representation in the encoding process to capture better relevant textual representations. Finally, information from different sources and formats was fused to obtain a joint feature representation tensor that predicts the traffic demand in the next day's event area. The experimental results show that the average absolute error of the fusion prediction network is reduced by 26.5\%, the root mean square error is reduced by 11.6\%, and the judgment coefficient is increased by 26.4\% compared with the prediction network that only considers the traffic data.},
  keywords = {Deep learning,Event area,Heterogeneous data fusion,Taxi demand prediction,Textual data},
  file = {/Users/tobias/Zotero/storage/8VADH9LJ/Yu et al. - 2022 - Traffic flow prediction based on depthwise separab.pdf}
}

@article{zeidanEfficientSpatialData2022,
  title = {Efficient Spatial Data Partitioning for Distributed \$\$k\$\${{NN}} Joins},
  author = {Zeidan, Ayman and Vo, Huy T.},
  year = {2022},
  month = jun,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {77},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00587-2},
  abstract = {Parallel processing of large spatial datasets over distributed systems has become a core part of modern data analytic systems like Apache Hadoop and Apache Spark. The general-purpose design of these systems does not natively account for the data's spatial attributes and results in poor scalability, accuracy, or prolonged runtimes. Spatial extensions remedy the problem and introduce spatial data recognition and operations. At the core of a spatial extension, a locality-preserving spatial partitioner determines how to spatially group the dataset's objects into smaller chunks using the distributed system's available resources. Existing spatial extensions rely on data sampling and often mismanage non-spatial data by either overlooking their memory requirements or excluding them entirely. This work discusses the various challenges that face spatial data partitioning and proposes a novel spatial partitioner for effectively processing spatial queries over large spatial datasets. For evaluation, the proposed partitioner is integrated with the well-known k-Nearest Neighbor (\$\$k\$\$NN) spatial join query. Several experiments evaluate the proposal using real-world datasets. Our approach differs from existing proposals by (1) accounting for the dataset's unique spatial traits without sampling, (2) considering the computational overhead required to handle non-spatial data, (3) minimizing partition shuffles, (4) computing the optimal utilization of the available resources, and (5) achieving accurate results. This contributes to the problem of spatial data partitioning through (1) providing a comprehensive discussion of the problems facing spatial data partitioning and processing, (2) the development of a novel spatial partitioning technique for in-memory distributed processing, (3) an effective, built-in, load-balancing methodology that reduces spatial query skews, and (4) a Spark-based implementation of the proposed work with an accurate \$\$k\$\$NN spatial join query. Experimental tests show up to \$\$1.48\$\$times improvement in runtime as well as the accuracy of results.},
  keywords = {\\(k\\)NN query,All \\(k\\)NN query,Big data,Distributed computing,Indexing,Load balancing,NoSQL,Parallel processing,Partitioning,Spark,Spatial data,Spatial query,Technique},
  file = {/Users/tobias/Zotero/storage/FCKLQ8VE/Zeidan and Vo - 2022 - Efficient spatial data partitioning for distribute.pdf}
}

@misc{zeilerVisualizingUnderstandingConvolutional2013,
  title = {Visualizing and {{Understanding Convolutional Networks}}},
  author = {Zeiler, Matthew D. and Fergus, Rob},
  year = {2013},
  month = nov,
  number = {arXiv:1311.2901},
  eprint = {1311.2901},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  abstract = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark (Krizhevsky et al., 2012). However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we address both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al. on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/tobias/Zotero/storage/EDEZWFGH/Zeiler and Fergus - 2013 - Visualizing and Understanding Convolutional Networ.pdf}
}

@article{zhaiOptimalInstanceSubset2022,
  title = {Optimal Instance Subset Selection from Big Data Using Genetic Algorithm and Open Source Framework},
  author = {Zhai, Junhai and Song, Dandan},
  year = {2022},
  month = jul,
  journal = {Journal of Big Data},
  volume = {9},
  number = {1},
  pages = {87},
  issn = {2196-1115},
  doi = {10.1186/s40537-022-00640-0},
  abstract = {Data is accumulating at an incredible rate, and the era of big data has arrived. Big data brings great challenges to traditional machine learning algorithms, it is difficult for learning tasks in big data scenario to be completed on stand-alone. Data reduction is an effective way to solve this problem. Data reduction includes attribute reduction and instance reduction. In this study, we focus on instance reduction also called instance selection, and view the instance selection as an optimal instance subset selection problem. Inspired by the ideas of cross validation and divide and conquer, we defined a novel criterion called combined information entropy with respect to a set of classifiers to measure the importance of an instance subset, the criterion uses multiple independent classifiers trained on different subsets to measure the optimality of an instance subset. Based on the criterion, we proposed an approach which uses genetic algorithm and open source framework to select optimal instance subset from big data. The proposed algorithm is implemented on two open source big data platforms Hadoop and Spark, the conducted experiments on four~artificial data sets demonstrate the feasibility of the proposed algorithm and visualize the distribution of selected instances, and the conducted experiments on four~real data sets compared with three closely related methods on test accuracy and compression ratio demonstrate the effectiveness of the proposed algorithm. Furthermore, the two implementations on Hadoop and Spark are also experimentally compared. The experimental results show that the proposed algorithm provides excellent performance and outperforms the three methods.},
  keywords = {Big data,Cross-selection,Genetic algorithm,Instance selection,Open source platforms},
  file = {/Users/tobias/Zotero/storage/9KGGUZ7R/Zhai and Song - 2022 - Optimal instance subset selection from big data us.pdf}
}

@article{zhangDiveDeepLearning,
  title = {Dive into {{Deep Learning}}},
  author = {Zhang, Aston and Lipton, Zachary C and Li, Mu and Smola, Alexander J},
  pages = {1038},
  langid = {english},
  file = {/Users/tobias/Zotero/storage/P82WRGE8/Zhang et al. - Dive into Deep Learning.pdf}
}

@incollection{zhengAveragedOneDependenceEstimators2017,
  title = {Averaged {{One-Dependence Estimators}}},
  booktitle = {Encyclopedia of {{Machine Learning}} and {{Data Mining}}},
  author = {Zheng, Fei and Webb, Geoffrey I.},
  editor = {Sammut, Claude and Webb, Geoffrey I.},
  year = {2017},
  pages = {85--87},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4899-7687-1_48},
  isbn = {978-1-4899-7685-7 978-1-4899-7687-1},
  langid = {english}
}

@misc{zotero-825,
  howpublished = {https://www.deeplearningbook.org/contents/TOC.html},
  file = {/Users/tobias/Zotero/storage/7MUQQQB7/TOC.html}
=======
>>>>>>> master
}
